25/05/08 16:54:39.159 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/conf/hive-site.xml
25/05/08 16:54:39.573 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.5.5
25/05/08 16:54:39.574 nioEventLoopGroup-2-2 INFO SparkContext: OS info Windows 11, 10.0, amd64
25/05/08 16:54:39.575 nioEventLoopGroup-2-2 INFO SparkContext: Java version 1.8.0_441
25/05/08 16:54:39.622 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/05/08 16:54:39.808 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/05/08 16:54:39.920 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
25/05/08 16:54:39.921 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
25/05/08 16:54:39.922 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
25/05/08 16:54:39.924 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
25/05/08 16:54:39.994 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/05/08 16:54:40.034 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
25/05/08 16:54:40.037 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/05/08 16:54:40.221 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: Owner
25/05/08 16:54:40.222 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: Owner
25/05/08 16:54:40.224 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
25/05/08 16:54:40.225 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
25/05/08 16:54:40.226 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Owner; groups with view permissions: EMPTY; users with modify permissions: Owner; groups with modify permissions: EMPTY
25/05/08 16:54:40.472 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 56956.
25/05/08 16:54:40.541 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
25/05/08 16:54:40.634 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
25/05/08 16:54:40.708 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/05/08 16:54:40.709 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/05/08 16:54:40.715 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/05/08 16:54:40.774 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\blockmgr-df232763-dd12-479e-9703-db8a42a3ef4d
25/05/08 16:54:40.815 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
25/05/08 16:54:40.851 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
25/05/08 16:54:40.856 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/local]. Please check your configured local directories.
25/05/08 16:54:41.222 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 127.0.0.1:4040 for SparkUI
25/05/08 16:54:41.432 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/05/08 16:54:41.526 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/Owner/AppData/Local/R/win-library/4.4/sparklyr/java/sparklyr-3.5-2.12.jar at spark://127.0.0.1:56956/jars/sparklyr-3.5-2.12.jar with timestamp 1746737679555
25/05/08 16:54:41.692 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host 127.0.0.1
25/05/08 16:54:41.693 nioEventLoopGroup-2-2 INFO Executor: OS info Windows 11, 10.0, amd64
25/05/08 16:54:41.694 nioEventLoopGroup-2-2 INFO Executor: Java version 1.8.0_441
25/05/08 16:54:41.710 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/05/08 16:54:41.711 nioEventLoopGroup-2-2 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@e65f5b4 for default.
25/05/08 16:54:41.737 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://127.0.0.1:56956/jars/sparklyr-3.5-2.12.jar with timestamp 1746737679555
25/05/08 16:54:41.829 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:56956 after 37 ms (0 ms spent in bootstraps)
25/05/08 16:54:41.839 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://127.0.0.1:56956/jars/sparklyr-3.5-2.12.jar to C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-bab6b77e-6aec-4d8c-a846-ffee7bfb3a0b\userFiles-f20a1ed9-1249-4e09-a42b-16a7199ba111\fetchFileTemp368751079409444828.tmp
25/05/08 16:54:42.071 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/local/spark-bab6b77e-6aec-4d8c-a846-ffee7bfb3a0b/userFiles-f20a1ed9-1249-4e09-a42b-16a7199ba111/sparklyr-3.5-2.12.jar to class loader default
25/05/08 16:54:42.115 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57008.
25/05/08 16:54:42.117 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on 127.0.0.1:57008
25/05/08 16:54:42.120 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/05/08 16:54:42.140 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 57008, None)
25/05/08 16:54:42.150 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:57008 with 912.3 MiB RAM, BlockManagerId(driver, 127.0.0.1, 57008, None)
25/05/08 16:54:42.157 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 57008, None)
25/05/08 16:54:42.161 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 57008, None)
25/05/08 16:54:42.790 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
25/05/08 16:54:42.810 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/hive'.
25/05/08 16:54:53.181 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/05/08 16:54:53.794 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/hive
25/05/08 16:54:54.223 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
25/05/08 16:54:54.225 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
25/05/08 16:54:54.227 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
25/05/08 16:54:54.335 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
25/05/08 16:54:54.625 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
25/05/08 16:54:54.629 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
25/05/08 16:54:56.972 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
25/05/08 16:54:59.921 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
25/05/08 16:54:59.927 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
25/05/08 16:55:00.066 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
25/05/08 16:55:00.066 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@10.0.0.88
25/05/08 16:55:00.117 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
25/05/08 16:55:00.463 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
25/05/08 16:55:00.468 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
25/05/08 16:55:00.551 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
25/05/08 16:55:00.803 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/08 16:55:00.808 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/08 16:55:00.848 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
25/05/08 16:55:00.848 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: global_temp	
25/05/08 16:55:00.850 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
25/05/08 16:55:00.851 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/08 16:55:00.851 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/08 16:55:00.854 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/08 16:55:00.854 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/08 16:55:00.858 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/08 16:55:00.859 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/08 16:55:01.590 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/08 16:55:01.591 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/08 16:55:01.593 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/08 16:55:01.593 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/08 16:55:01.596 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/08 16:55:01.596 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/08 22:53:17.944 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1219)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:48)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
25/05/08 22:53:21.021 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
25/05/09 02:59:09.152 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1219)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:48)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
25/05/09 02:59:19.169 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1219)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:48)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
25/05/09 02:59:29.178 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1219)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:48)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
25/05/09 02:59:39.191 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1219)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:48)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
25/05/09 02:59:49.203 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1219)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:48)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
25/05/09 02:59:52.249 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
25/05/09 02:59:52.251 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
25/05/09 02:59:52.252 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
25/05/09 02:59:52.253 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
25/05/09 02:59:52.254 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
25/05/10 10:15:27.577 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1219)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:48)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
25/05/10 10:15:37.588 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1219)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:48)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
25/05/10 10:15:47.606 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1219)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:48)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
25/05/10 10:15:57.623 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1219)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:48)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
25/05/10 10:16:00.661 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
25/05/10 10:16:00.661 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
25/05/10 10:16:00.662 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
25/05/10 10:16:00.664 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
25/05/10 14:22:50.047 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 14:22:50.048 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 14:22:50.054 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 14:22:50.054 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 14:22:50.056 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 14:22:50.056 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 14:22:51.065 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 313.774 ms
25/05/10 14:22:51.272 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 14:22:51.286 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0.013065 s
25/05/10 14:23:59.511 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 14:23:59.512 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 14:23:59.516 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 14:23:59.517 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 14:23:59.521 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 14:23:59.523 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 14:23:59.649 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 14:23:59.651 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0.000457 s
25/05/10 14:46:31.436 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 14:46:31.440 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 14:46:31.464 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 14:46:31.464 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 14:46:31.467 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 14:46:31.467 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 14:46:31.569 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 14:46:31.572 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0.001664 s
25/05/10 14:50:45.356 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
25/05/10 14:50:45.360 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/05/10 14:50:45.442 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
25/05/10 14:50:45.510 dispatcher-event-loop-6 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/05/10 14:50:45.560 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
25/05/10 14:50:45.561 shutdown-hook-0 INFO BlockManager: BlockManager stopped
25/05/10 14:50:45.604 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
25/05/10 14:50:45.619 dispatcher-event-loop-1 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/05/10 14:50:45.639 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
25/05/10 14:50:45.640 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
25/05/10 14:50:45.642 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\Owner\AppData\Local\Temp\spark-5961c3a9-a416-46ed-84d5-06a550368e60
25/05/10 14:50:45.646 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-bab6b77e-6aec-4d8c-a846-ffee7bfb3a0b
25/05/10 14:52:40.636 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
25/05/10 14:52:40.650 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\Owner\AppData\Local\Temp\spark-2a8c1515-2cd2-4682-858f-9d4d1c1d4945
25/05/10 14:54:43.463 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/conf/hive-site.xml
25/05/10 14:54:43.685 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.5.5
25/05/10 14:54:43.685 nioEventLoopGroup-2-2 INFO SparkContext: OS info Windows 11, 10.0, amd64
25/05/10 14:54:43.686 nioEventLoopGroup-2-2 INFO SparkContext: Java version 1.8.0_451
25/05/10 14:54:43.709 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/05/10 14:54:43.814 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/05/10 14:54:43.878 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
25/05/10 14:54:43.878 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
25/05/10 14:54:43.878 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
25/05/10 14:54:43.879 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
25/05/10 14:54:43.914 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/05/10 14:54:43.927 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
25/05/10 14:54:43.928 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/05/10 14:54:44.018 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: Owner
25/05/10 14:54:44.019 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: Owner
25/05/10 14:54:44.019 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
25/05/10 14:54:44.020 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
25/05/10 14:54:44.020 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Owner; groups with view permissions: EMPTY; users with modify permissions: Owner; groups with modify permissions: EMPTY
25/05/10 14:54:44.135 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 62414.
25/05/10 14:54:44.179 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
25/05/10 14:54:44.238 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
25/05/10 14:54:44.275 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/05/10 14:54:44.276 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/05/10 14:54:44.279 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/05/10 14:54:44.326 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\blockmgr-5af2298f-7707-4fba-ba2c-7a3840355ab5
25/05/10 14:54:44.356 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
25/05/10 14:54:44.381 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
25/05/10 14:54:44.385 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/local]. Please check your configured local directories.
25/05/10 14:54:44.622 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 127.0.0.1:4040 for SparkUI
25/05/10 14:54:44.735 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/05/10 14:54:44.791 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/Owner/AppData/Local/R/win-library/4.4/sparklyr/java/sparklyr-3.5-2.12.jar at spark://127.0.0.1:62414/jars/sparklyr-3.5-2.12.jar with timestamp 1746903283674
25/05/10 14:54:44.881 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host 127.0.0.1
25/05/10 14:54:44.881 nioEventLoopGroup-2-2 INFO Executor: OS info Windows 11, 10.0, amd64
25/05/10 14:54:44.881 nioEventLoopGroup-2-2 INFO Executor: Java version 1.8.0_451
25/05/10 14:54:44.889 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/05/10 14:54:44.890 nioEventLoopGroup-2-2 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4dcb97e1 for default.
25/05/10 14:54:44.905 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://127.0.0.1:62414/jars/sparklyr-3.5-2.12.jar with timestamp 1746903283674
25/05/10 14:54:44.963 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:62414 after 22 ms (0 ms spent in bootstraps)
25/05/10 14:54:44.971 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://127.0.0.1:62414/jars/sparklyr-3.5-2.12.jar to C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-99673085-3b4f-4f84-b6bb-5030e52d1192\userFiles-031184a8-b586-472f-9f9e-435ec7b21424\fetchFileTemp635734820626443986.tmp
25/05/10 14:54:45.103 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/local/spark-99673085-3b4f-4f84-b6bb-5030e52d1192/userFiles-031184a8-b586-472f-9f9e-435ec7b21424/sparklyr-3.5-2.12.jar to class loader default
25/05/10 14:54:45.131 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62467.
25/05/10 14:54:45.132 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on 127.0.0.1:62467
25/05/10 14:54:45.135 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/05/10 14:54:45.146 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 62467, None)
25/05/10 14:54:45.151 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:62467 with 912.3 MiB RAM, BlockManagerId(driver, 127.0.0.1, 62467, None)
25/05/10 14:54:45.155 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 62467, None)
25/05/10 14:54:45.157 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 62467, None)
25/05/10 14:54:45.559 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
25/05/10 14:54:45.571 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/hive'.
25/05/10 14:54:49.933 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/05/10 14:54:50.313 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/hive
25/05/10 14:54:50.529 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
25/05/10 14:54:50.529 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
25/05/10 14:54:50.529 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
25/05/10 14:54:50.591 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
25/05/10 14:54:50.777 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
25/05/10 14:54:50.779 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
25/05/10 14:54:51.999 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
25/05/10 14:54:53.522 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
25/05/10 14:54:53.524 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
25/05/10 14:54:53.594 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
25/05/10 14:54:53.594 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@10.0.0.88
25/05/10 14:54:53.620 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
25/05/10 14:54:53.782 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
25/05/10 14:54:53.784 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
25/05/10 14:54:53.831 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
25/05/10 14:54:53.961 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 14:54:53.964 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 14:54:53.986 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
25/05/10 14:54:53.986 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: global_temp	
25/05/10 14:54:53.987 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
25/05/10 14:54:53.988 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 14:54:53.989 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 14:54:53.991 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 14:54:53.992 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 14:54:53.994 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 14:54:53.994 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 14:54:54.424 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 14:54:54.425 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 14:54:54.428 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 14:54:54.428 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 14:54:54.430 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 14:54:54.430 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 14:55:04.149 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 14:55:04.149 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 14:55:04.151 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 14:55:04.151 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 14:55:04.152 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 14:55:04.153 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 14:55:04.902 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 276.3171 ms
25/05/10 14:55:05.076 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 14:55:05.085 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0.008823 s
25/05/10 14:58:11.950 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 14:58:11.953 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 14:58:11.974 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 14:58:11.974 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 14:58:11.978 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 14:58:11.978 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 14:58:12.090 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 14:58:12.091 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0.000578 s
25/05/10 15:00:28.533 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:00:28.539 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:00:28.557 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:00:28.557 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:00:28.562 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 15:00:28.562 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 15:00:28.728 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 15:00:28.730 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0.000564 s
25/05/10 15:00:33.407 nioEventLoopGroup-2-2 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
25/05/10 15:00:35.796 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.4546 ms
25/05/10 15:00:35.854 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 15:00:35.882 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
25/05/10 15:00:35.886 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
25/05/10 15:00:35.886 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 15:00:35.888 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 15:00:35.894 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[13] at collect at utils.scala:26), which has no missing parents
25/05/10 15:00:36.022 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 84.6 KiB, free 912.2 MiB)
25/05/10 15:00:36.532 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 912.2 MiB)
25/05/10 15:00:36.538 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:62467 (size: 15.1 KiB, free: 912.3 MiB)
25/05/10 15:00:36.549 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
25/05/10 15:00:36.576 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[13] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 15:00:36.579 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/05/10 15:00:36.654 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 15:00:36.675 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/05/10 15:00:37.252 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 209.7752 ms
25/05/10 15:00:37.601 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 210.3463 ms
25/05/10 15:00:37.649 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1524 bytes result sent to driver
25/05/10 15:00:37.664 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1021 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 15:00:37.666 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/05/10 15:00:37.696 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 1.776 s
25/05/10 15:00:37.699 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 15:00:37.699 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/05/10 15:00:37.700 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 1.846174 s
25/05/10 15:00:38.058 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 256.5325 ms
25/05/10 15:00:42.449 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:62467 in memory (size: 15.1 KiB, free: 912.3 MiB)
25/05/10 15:00:42.654 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 15:00:42.655 dag-scheduler-event-loop INFO DAGScheduler: Got job 4 (collect at utils.scala:26) with 1 output partitions
25/05/10 15:00:42.656 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
25/05/10 15:00:42.656 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 15:00:42.656 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 15:00:42.658 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[16] at collect at utils.scala:26), which has no missing parents
25/05/10 15:00:42.663 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 84.6 KiB, free 912.2 MiB)
25/05/10 15:00:42.666 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 912.2 MiB)
25/05/10 15:00:42.667 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:62467 (size: 15.1 KiB, free: 912.3 MiB)
25/05/10 15:00:42.668 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
25/05/10 15:00:42.669 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[16] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 15:00:42.669 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/05/10 15:00:42.671 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 15:00:42.672 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
25/05/10 15:00:42.740 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1481 bytes result sent to driver
25/05/10 15:00:42.744 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 72 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 15:00:42.744 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/05/10 15:00:42.745 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0.086 s
25/05/10 15:00:42.745 dag-scheduler-event-loop INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 15:00:42.745 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/05/10 15:00:42.746 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 4 finished: collect at utils.scala:26, took 0.090418 s
25/05/10 15:00:52.058 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:00:52.058 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:00:52.060 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:00:52.061 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:00:52.062 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 15:00:52.062 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 15:00:52.179 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 60.6019 ms
25/05/10 15:00:52.219 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.8309 ms
25/05/10 15:00:52.241 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 12.2443 ms
25/05/10 15:01:07.865 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:01:07.866 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:01:07.873 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:01:07.874 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:01:07.876 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 15:01:07.877 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 15:01:07.919 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:62467 in memory (size: 15.1 KiB, free: 912.3 MiB)
25/05/10 15:01:08.683 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:01:08.684 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:01:08.685 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:01:08.686 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:01:08.687 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 15:01:08.687 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 15:02:02.276 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:02:02.276 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:02:02.279 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:02:02.279 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:02:02.281 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 15:02:02.281 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 15:03:04.322 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:03:04.322 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:03:04.323 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:03:04.324 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:03:04.326 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 15:03:04.326 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 15:03:13.149 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:03:13.150 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:03:13.151 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:03:13.151 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:03:13.153 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 15:03:13.153 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 15:03:13.209 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 15:03:13.210 dag-scheduler-event-loop INFO DAGScheduler: Got job 5 (collect at utils.scala:26) with 1 output partitions
25/05/10 15:03:13.210 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
25/05/10 15:03:13.210 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 15:03:13.211 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 15:03:13.212 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[19] at collect at utils.scala:26), which has no missing parents
25/05/10 15:03:13.217 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.5 KiB, free 912.3 MiB)
25/05/10 15:03:13.220 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.3 MiB)
25/05/10 15:03:13.221 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:62467 (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 15:03:13.222 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
25/05/10 15:03:13.222 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[19] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 15:03:13.222 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/05/10 15:03:13.225 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9420 bytes) 
25/05/10 15:03:13.227 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
25/05/10 15:03:13.240 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 8.5217 ms
25/05/10 15:03:13.244 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1476 bytes result sent to driver
25/05/10 15:03:13.248 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 25 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 15:03:13.249 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/05/10 15:03:13.250 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 0.036 s
25/05/10 15:03:13.250 dag-scheduler-event-loop INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 15:03:13.251 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/05/10 15:03:13.251 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 5 finished: collect at utils.scala:26, took 0.041246 s
25/05/10 15:03:13.258 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.8395 ms
25/05/10 15:08:47.004 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:08:47.010 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:08:47.031 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:08:47.031 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:08:47.034 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 15:08:47.034 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 15:08:47.147 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:08:47.147 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:08:47.149 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:08:47.149 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:08:47.151 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 15:08:47.151 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 15:11:46.255 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:11:46.256 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:11:46.269 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_table : db=default tbl=lo_spark
25/05/10 15:11:46.269 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_table : db=default tbl=lo_spark	
25/05/10 15:15:14.233 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
25/05/10 15:15:14.236 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/05/10 15:15:14.351 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
25/05/10 15:15:14.446 dispatcher-event-loop-3 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/05/10 15:15:14.522 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
25/05/10 15:15:14.523 shutdown-hook-0 INFO BlockManager: BlockManager stopped
25/05/10 15:15:14.533 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
25/05/10 15:15:14.546 dispatcher-event-loop-11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/05/10 15:15:14.571 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-99673085-3b4f-4f84-b6bb-5030e52d1192\userFiles-031184a8-b586-472f-9f9e-435ec7b21424
java.io.IOException: Failed to delete: C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-99673085-3b4f-4f84-b6bb-5030e52d1192\userFiles-031184a8-b586-472f-9f9e-435ec7b21424\sparklyr-3.5-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:147)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:130)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:90)
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1126)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2305)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2305)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2211)
	at org.apache.spark.SparkContext.$anonfun$new$34(SparkContext.scala:681)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
25/05/10 15:15:14.581 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
25/05/10 15:15:14.583 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
25/05/10 15:15:14.584 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-99673085-3b4f-4f84-b6bb-5030e52d1192
25/05/10 15:15:14.590 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-99673085-3b4f-4f84-b6bb-5030e52d1192
java.io.IOException: Failed to delete: C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-99673085-3b4f-4f84-b6bb-5030e52d1192\userFiles-031184a8-b586-472f-9f9e-435ec7b21424\sparklyr-3.5-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:147)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:130)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:130)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:90)
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1126)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
25/05/10 15:15:14.592 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\Owner\AppData\Local\Temp\spark-b514799a-1171-4a3f-8c1e-655f03ce45cb
25/05/10 15:15:14.596 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-99673085-3b4f-4f84-b6bb-5030e52d1192\userFiles-031184a8-b586-472f-9f9e-435ec7b21424
25/05/10 15:15:14.601 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-99673085-3b4f-4f84-b6bb-5030e52d1192\userFiles-031184a8-b586-472f-9f9e-435ec7b21424
java.io.IOException: Failed to delete: C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-99673085-3b4f-4f84-b6bb-5030e52d1192\userFiles-031184a8-b586-472f-9f9e-435ec7b21424\sparklyr-3.5-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:147)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:130)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:90)
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1126)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
25/05/10 15:17:09.700 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/conf/hive-site.xml
25/05/10 15:17:09.926 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.5.5
25/05/10 15:17:09.927 nioEventLoopGroup-2-2 INFO SparkContext: OS info Windows 11, 10.0, amd64
25/05/10 15:17:09.927 nioEventLoopGroup-2-2 INFO SparkContext: Java version 1.8.0_451
25/05/10 15:17:09.957 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/05/10 15:17:10.061 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/05/10 15:17:10.134 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
25/05/10 15:17:10.135 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
25/05/10 15:17:10.135 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
25/05/10 15:17:10.136 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
25/05/10 15:17:10.171 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 8192, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/05/10 15:17:10.183 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
25/05/10 15:17:10.185 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/05/10 15:17:10.278 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: Owner
25/05/10 15:17:10.278 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: Owner
25/05/10 15:17:10.278 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
25/05/10 15:17:10.279 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
25/05/10 15:17:10.279 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Owner; groups with view permissions: EMPTY; users with modify permissions: Owner; groups with modify permissions: EMPTY
25/05/10 15:17:10.408 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 63544.
25/05/10 15:17:10.454 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
25/05/10 15:17:10.510 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
25/05/10 15:17:10.549 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/05/10 15:17:10.550 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/05/10 15:17:10.554 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/05/10 15:17:10.591 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\blockmgr-6ac91192-c637-467d-902c-3db276c08fbb
25/05/10 15:17:10.617 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
25/05/10 15:17:10.640 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
25/05/10 15:17:10.644 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/local]. Please check your configured local directories.
25/05/10 15:17:10.866 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 127.0.0.1:4040 for SparkUI
25/05/10 15:17:10.976 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/05/10 15:17:11.027 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/Owner/AppData/Local/R/win-library/4.4/sparklyr/java/sparklyr-3.5-2.12.jar at spark://127.0.0.1:63544/jars/sparklyr-3.5-2.12.jar with timestamp 1746904629917
25/05/10 15:17:11.129 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host 127.0.0.1
25/05/10 15:17:11.129 nioEventLoopGroup-2-2 INFO Executor: OS info Windows 11, 10.0, amd64
25/05/10 15:17:11.129 nioEventLoopGroup-2-2 INFO Executor: Java version 1.8.0_451
25/05/10 15:17:11.138 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/05/10 15:17:11.138 nioEventLoopGroup-2-2 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@792b1f3c for default.
25/05/10 15:17:11.162 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://127.0.0.1:63544/jars/sparklyr-3.5-2.12.jar with timestamp 1746904629917
25/05/10 15:17:11.218 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:63544 after 21 ms (0 ms spent in bootstraps)
25/05/10 15:17:11.225 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://127.0.0.1:63544/jars/sparklyr-3.5-2.12.jar to C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-2da54ed1-303c-405e-ac6f-68fdbda8994f\userFiles-5db0f540-a213-4759-b52f-fe9dc8725486\fetchFileTemp7834755901112098736.tmp
25/05/10 15:17:11.347 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/local/spark-2da54ed1-303c-405e-ac6f-68fdbda8994f/userFiles-5db0f540-a213-4759-b52f-fe9dc8725486/sparklyr-3.5-2.12.jar to class loader default
25/05/10 15:17:11.376 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63596.
25/05/10 15:17:11.376 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on 127.0.0.1:63596
25/05/10 15:17:11.378 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/05/10 15:17:11.390 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 63596, None)
25/05/10 15:17:11.396 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:63596 with 912.3 MiB RAM, BlockManagerId(driver, 127.0.0.1, 63596, None)
25/05/10 15:17:11.400 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 63596, None)
25/05/10 15:17:11.402 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 63596, None)
25/05/10 15:17:11.865 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
25/05/10 15:17:11.874 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/hive'.
25/05/10 15:17:16.244 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/05/10 15:17:16.663 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/hive
25/05/10 15:17:16.880 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
25/05/10 15:17:16.880 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
25/05/10 15:17:16.880 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
25/05/10 15:17:16.976 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
25/05/10 15:17:17.208 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
25/05/10 15:17:17.210 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
25/05/10 15:17:18.441 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
25/05/10 15:17:20.121 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
25/05/10 15:17:20.123 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
25/05/10 15:17:20.189 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
25/05/10 15:17:20.190 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@10.0.0.88
25/05/10 15:17:20.219 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
25/05/10 15:17:20.381 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
25/05/10 15:17:20.383 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
25/05/10 15:17:20.430 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
25/05/10 15:17:20.553 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:17:20.556 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:17:20.577 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
25/05/10 15:17:20.577 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: global_temp	
25/05/10 15:17:20.578 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
25/05/10 15:17:20.578 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:17:20.578 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:17:20.580 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:17:20.581 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:17:20.582 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 15:17:20.582 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 15:17:21.098 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:17:21.099 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:17:21.101 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:17:21.102 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:17:21.105 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 15:17:21.105 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 15:17:42.721 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:17:42.722 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:17:42.725 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:17:42.726 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:17:42.729 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 15:17:42.729 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 15:17:43.514 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 299.3291 ms
25/05/10 15:17:43.779 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 15:17:43.790 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0.010585 s
25/05/10 15:50:42.230 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/conf/hive-site.xml
25/05/10 15:50:42.449 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.5.5
25/05/10 15:50:42.450 nioEventLoopGroup-2-2 INFO SparkContext: OS info Windows 11, 10.0, amd64
25/05/10 15:50:42.450 nioEventLoopGroup-2-2 INFO SparkContext: Java version 1.8.0_451
25/05/10 15:50:42.486 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/05/10 15:50:42.592 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/05/10 15:50:42.655 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
25/05/10 15:50:42.656 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
25/05/10 15:50:42.656 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
25/05/10 15:50:42.656 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
25/05/10 15:50:42.690 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 8192, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/05/10 15:50:42.707 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
25/05/10 15:50:42.708 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/05/10 15:50:42.800 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: Owner
25/05/10 15:50:42.801 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: Owner
25/05/10 15:50:42.802 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
25/05/10 15:50:42.802 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
25/05/10 15:50:42.803 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Owner; groups with view permissions: EMPTY; users with modify permissions: Owner; groups with modify permissions: EMPTY
25/05/10 15:50:42.926 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 65280.
25/05/10 15:50:42.963 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
25/05/10 15:50:43.007 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
25/05/10 15:50:43.038 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/05/10 15:50:43.038 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/05/10 15:50:43.042 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/05/10 15:50:43.080 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\blockmgr-ec743bda-7a38-43b2-93e6-6d8afc9f2650
25/05/10 15:50:43.104 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
25/05/10 15:50:43.124 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
25/05/10 15:50:43.128 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/local]. Please check your configured local directories.
25/05/10 15:50:43.311 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 127.0.0.1:4040 for SparkUI
25/05/10 15:50:43.411 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/05/10 15:50:43.473 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/Owner/AppData/Local/R/win-library/4.4/sparklyr/java/sparklyr-3.5-2.12.jar at spark://127.0.0.1:65280/jars/sparklyr-3.5-2.12.jar with timestamp 1746906642440
25/05/10 15:50:43.596 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host 127.0.0.1
25/05/10 15:50:43.596 nioEventLoopGroup-2-2 INFO Executor: OS info Windows 11, 10.0, amd64
25/05/10 15:50:43.596 nioEventLoopGroup-2-2 INFO Executor: Java version 1.8.0_451
25/05/10 15:50:43.604 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/05/10 15:50:43.605 nioEventLoopGroup-2-2 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@552ca5ff for default.
25/05/10 15:50:43.619 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://127.0.0.1:65280/jars/sparklyr-3.5-2.12.jar with timestamp 1746906642440
25/05/10 15:50:43.671 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:65280 after 20 ms (0 ms spent in bootstraps)
25/05/10 15:50:43.678 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://127.0.0.1:65280/jars/sparklyr-3.5-2.12.jar to C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-9be3e51d-cf9e-44df-b93c-9d6d89bc1db7\userFiles-8f56890c-11da-4b60-946a-3838a2d4405c\fetchFileTemp9071497721391349889.tmp
25/05/10 15:50:43.789 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/local/spark-9be3e51d-cf9e-44df-b93c-9d6d89bc1db7/userFiles-8f56890c-11da-4b60-946a-3838a2d4405c/sparklyr-3.5-2.12.jar to class loader default
25/05/10 15:50:43.820 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65332.
25/05/10 15:50:43.821 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on 127.0.0.1:65332
25/05/10 15:50:43.824 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/05/10 15:50:43.840 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 65332, None)
25/05/10 15:50:43.848 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:65332 with 912.3 MiB RAM, BlockManagerId(driver, 127.0.0.1, 65332, None)
25/05/10 15:50:43.856 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 65332, None)
25/05/10 15:50:43.859 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 65332, None)
25/05/10 15:50:44.223 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
25/05/10 15:50:44.236 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/hive'.
25/05/10 15:50:48.602 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/05/10 15:50:48.994 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/hive
25/05/10 15:50:49.229 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
25/05/10 15:50:49.230 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
25/05/10 15:50:49.230 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
25/05/10 15:50:49.295 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
25/05/10 15:50:49.481 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
25/05/10 15:50:49.483 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
25/05/10 15:50:50.676 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
25/05/10 15:50:52.188 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
25/05/10 15:50:52.190 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
25/05/10 15:50:52.263 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
25/05/10 15:50:52.263 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@10.0.0.88
25/05/10 15:50:52.294 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
25/05/10 15:50:52.459 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
25/05/10 15:50:52.460 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
25/05/10 15:50:52.507 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
25/05/10 15:50:52.631 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:50:52.633 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:50:52.659 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
25/05/10 15:50:52.659 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: global_temp	
25/05/10 15:50:52.660 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
25/05/10 15:50:52.660 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:50:52.661 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:50:52.662 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:50:52.662 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:50:52.663 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 15:50:52.663 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 15:51:37.291 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:51:37.292 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:51:37.293 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:51:37.293 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:51:37.295 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 15:51:37.295 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 15:51:38.025 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 257.4973 ms
25/05/10 15:51:38.183 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 15:51:38.193 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0.008978 s
25/05/10 15:51:38.874 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.9994 ms
25/05/10 15:51:38.894 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 15:51:38.912 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
25/05/10 15:51:38.913 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
25/05/10 15:51:38.913 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 15:51:38.914 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 15:51:38.918 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26), which has no missing parents
25/05/10 15:51:38.997 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KiB, free 912.3 MiB)
25/05/10 15:51:39.114 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.3 MiB)
25/05/10 15:51:39.117 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:65332 (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 15:51:39.120 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
25/05/10 15:51:39.141 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 15:51:39.142 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/05/10 15:51:39.198 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 15:51:39.213 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/05/10 15:51:39.646 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 161.2322 ms
25/05/10 15:51:39.674 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1499 bytes result sent to driver
25/05/10 15:51:39.686 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 509 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 15:51:39.689 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/05/10 15:51:39.698 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0.764 s
25/05/10 15:51:39.702 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 15:51:39.702 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/05/10 15:51:39.703 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0.808364 s
25/05/10 15:51:39.761 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 27.3869 ms
25/05/10 15:51:40.008 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 15:51:40.010 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
25/05/10 15:51:40.010 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
25/05/10 15:51:40.010 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 15:51:40.010 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 15:51:40.011 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26), which has no missing parents
25/05/10 15:51:40.015 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.9 KiB, free 912.3 MiB)
25/05/10 15:51:40.017 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.3 MiB)
25/05/10 15:51:40.017 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:65332 (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 15:51:40.017 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
25/05/10 15:51:40.018 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 15:51:40.018 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/05/10 15:51:40.019 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 15:51:40.020 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
25/05/10 15:51:40.027 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1370 bytes result sent to driver
25/05/10 15:51:40.029 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 10 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 15:51:40.030 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/05/10 15:51:40.031 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0.017 s
25/05/10 15:51:40.031 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 15:51:40.031 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/05/10 15:51:40.032 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0.023178 s
25/05/10 15:51:46.135 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:51:46.136 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:51:46.141 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:51:46.142 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:51:46.144 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 15:51:46.144 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 15:51:46.247 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 54.6187 ms
25/05/10 15:51:46.272 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.6139 ms
25/05/10 15:51:46.290 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.3549 ms
25/05/10 15:51:52.558 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:51:52.558 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:51:52.559 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:51:52.560 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:51:52.562 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 15:51:52.562 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 15:52:22.033 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:52:22.034 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:52:22.035 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:52:22.035 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:52:22.038 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 15:52:22.038 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 15:52:22.116 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 15:52:22.118 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
25/05/10 15:52:22.118 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
25/05/10 15:52:22.119 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 15:52:22.119 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 15:52:22.121 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at collect at utils.scala:26), which has no missing parents
25/05/10 15:52:22.126 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.5 KiB, free 912.3 MiB)
25/05/10 15:52:22.131 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.3 MiB)
25/05/10 15:52:22.132 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:65332 (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 15:52:22.133 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
25/05/10 15:52:22.134 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 15:52:22.134 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/05/10 15:52:22.137 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9420 bytes) 
25/05/10 15:52:22.138 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
25/05/10 15:52:22.146 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 5.4129 ms
25/05/10 15:52:22.149 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1476 bytes result sent to driver
25/05/10 15:52:22.151 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 17 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 15:52:22.152 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/05/10 15:52:22.152 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 0.029 s
25/05/10 15:52:22.154 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 15:52:22.154 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/05/10 15:52:22.154 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 0.037477 s
25/05/10 15:52:22.161 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.9728 ms
25/05/10 15:53:58.686 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:53:58.694 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:53:58.746 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:53:58.746 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:53:58.749 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 15:53:58.749 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 15:54:27.087 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:65332 in memory (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 15:54:27.093 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 306.3438 ms
25/05/10 15:54:27.101 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:65332 in memory (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 15:54:27.110 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:65332 in memory (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 15:54:27.199 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 13 (collect at utils.scala:26) as input to shuffle 0
25/05/10 15:54:27.206 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 4 (collect at utils.scala:26) with 1 output partitions
25/05/10 15:54:27.206 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 3 (collect at utils.scala:26)
25/05/10 15:54:27.207 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 15:54:27.208 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 15:54:27.210 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[13] at collect at utils.scala:26), which has no missing parents
25/05/10 15:54:27.229 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 35.2 KiB, free 912.3 MiB)
25/05/10 15:54:27.235 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 16.1 KiB, free 912.2 MiB)
25/05/10 15:54:27.235 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:65332 (size: 16.1 KiB, free: 912.3 MiB)
25/05/10 15:54:27.236 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
25/05/10 15:54:27.238 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[13] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 15:54:27.238 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/05/10 15:54:27.248 dispatcher-event-loop-10 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 729655 bytes) 
25/05/10 15:54:27.256 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
25/05/10 15:54:27.380 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 57.5363 ms
25/05/10 15:54:27.410 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 17.098 ms
25/05/10 15:54:27.448 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 9.0926 ms
25/05/10 15:54:27.468 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 7.8442 ms
25/05/10 15:54:27.480 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 5.673 ms
25/05/10 15:54:27.581 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2254 bytes result sent to driver
25/05/10 15:54:27.585 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 346 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 15:54:27.585 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/05/10 15:54:27.588 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:26) finished in 0.374 s
25/05/10 15:54:27.589 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
25/05/10 15:54:27.589 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
25/05/10 15:54:27.590 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
25/05/10 15:54:27.590 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
25/05/10 15:54:27.616 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/05/10 15:54:27.644 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/05/10 15:54:27.667 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 14.0752 ms
25/05/10 15:54:27.709 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 15:54:27.710 dag-scheduler-event-loop INFO DAGScheduler: Got job 5 (collect at utils.scala:26) with 1 output partitions
25/05/10 15:54:27.710 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:26)
25/05/10 15:54:27.710 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/05/10 15:54:27.711 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 15:54:27.712 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[16] at collect at utils.scala:26), which has no missing parents
25/05/10 15:54:27.728 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 37.9 KiB, free 912.2 MiB)
25/05/10 15:54:27.731 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 912.2 MiB)
25/05/10 15:54:27.733 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:65332 (size: 17.2 KiB, free: 912.3 MiB)
25/05/10 15:54:27.734 dag-scheduler-event-loop INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
25/05/10 15:54:27.735 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[16] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 15:54:27.735 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/05/10 15:54:27.740 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 9176 bytes) 
25/05/10 15:54:27.741 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO Executor: Running task 0.0 in stage 5.0 (TID 4)
25/05/10 15:54:27.810 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO ShuffleBlockFetcherIterator: Getting 1 (5.2 KiB) non-empty blocks including 1 (5.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/10 15:54:27.815 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 24 ms
25/05/10 15:54:27.841 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO CodeGenerator: Code generated in 18.032 ms
25/05/10 15:54:27.878 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO Executor: Finished task 0.0 in stage 5.0 (TID 4). 8966 bytes result sent to driver
25/05/10 15:54:27.881 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 142 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 15:54:27.881 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/05/10 15:54:27.882 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 5 (collect at utils.scala:26) finished in 0.157 s
25/05/10 15:54:27.882 dag-scheduler-event-loop INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 15:54:27.882 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/05/10 15:54:27.882 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 5 finished: collect at utils.scala:26, took 0.172779 s
25/05/10 15:54:27.896 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.0431 ms
25/05/10 15:55:41.226 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:55:41.226 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:55:41.233 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:55:41.233 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:55:41.234 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 15:55:41.234 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 15:55:41.297 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 15:55:41.298 dag-scheduler-event-loop INFO DAGScheduler: Got job 6 (collect at utils.scala:26) with 1 output partitions
25/05/10 15:55:41.298 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:26)
25/05/10 15:55:41.298 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 15:55:41.298 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 15:55:41.300 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[19] at collect at utils.scala:26), which has no missing parents
25/05/10 15:55:41.301 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.5 KiB, free 912.2 MiB)
25/05/10 15:55:41.310 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.2 MiB)
25/05/10 15:55:41.311 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:65332 (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 15:55:41.312 dag-scheduler-event-loop INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
25/05/10 15:55:41.313 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[19] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 15:55:41.313 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/05/10 15:55:41.314 dispatcher-event-loop-11 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9420 bytes) 
25/05/10 15:55:41.315 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO Executor: Running task 0.0 in stage 6.0 (TID 5)
25/05/10 15:55:41.322 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO Executor: Finished task 0.0 in stage 6.0 (TID 5). 1476 bytes result sent to driver
25/05/10 15:55:41.323 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 10 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 15:55:41.323 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/05/10 15:55:41.324 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 6 (collect at utils.scala:26) finished in 0.024 s
25/05/10 15:55:41.324 dag-scheduler-event-loop INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 15:55:41.324 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/05/10 15:55:41.324 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 6 finished: collect at utils.scala:26, took 0.026756 s
25/05/10 15:55:46.687 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:65332 in memory (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 15:55:46.693 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:65332 in memory (size: 17.2 KiB, free: 912.3 MiB)
25/05/10 15:55:46.717 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:65332 in memory (size: 16.1 KiB, free: 912.3 MiB)
25/05/10 15:55:52.659 nioEventLoopGroup-2-2 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
25/05/10 15:55:54.511 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.2667 ms
25/05/10 15:55:54.530 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 15:55:54.530 dag-scheduler-event-loop INFO DAGScheduler: Got job 7 (collect at utils.scala:26) with 1 output partitions
25/05/10 15:55:54.531 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:26)
25/05/10 15:55:54.531 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 15:55:54.531 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 15:55:54.532 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[23] at collect at utils.scala:26), which has no missing parents
25/05/10 15:55:54.535 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 84.6 KiB, free 912.2 MiB)
25/05/10 15:55:54.537 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 912.2 MiB)
25/05/10 15:55:54.538 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:65332 (size: 15.1 KiB, free: 912.3 MiB)
25/05/10 15:55:54.540 dag-scheduler-event-loop INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
25/05/10 15:55:54.540 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 15:55:54.540 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/05/10 15:55:54.541 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 6) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 15:55:54.542 Executor task launch worker for task 0.0 in stage 7.0 (TID 6) INFO Executor: Running task 0.0 in stage 7.0 (TID 6)
25/05/10 15:55:54.562 Executor task launch worker for task 0.0 in stage 7.0 (TID 6) INFO CodeGenerator: Code generated in 5.3371 ms
25/05/10 15:55:54.709 Executor task launch worker for task 0.0 in stage 7.0 (TID 6) INFO CodeGenerator: Code generated in 82.6977 ms
25/05/10 15:55:54.714 Executor task launch worker for task 0.0 in stage 7.0 (TID 6) INFO Executor: Finished task 0.0 in stage 7.0 (TID 6). 1438 bytes result sent to driver
25/05/10 15:55:54.716 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 6) in 175 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 15:55:54.716 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/05/10 15:55:54.717 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 7 (collect at utils.scala:26) finished in 0.184 s
25/05/10 15:55:54.718 dag-scheduler-event-loop INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 15:55:54.718 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/05/10 15:55:54.718 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 7 finished: collect at utils.scala:26, took 0.188080 s
25/05/10 15:55:54.937 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 160.1253 ms
25/05/10 15:55:59.230 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 15:55:59.232 dag-scheduler-event-loop INFO DAGScheduler: Got job 8 (collect at utils.scala:26) with 1 output partitions
25/05/10 15:55:59.232 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:26)
25/05/10 15:55:59.232 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 15:55:59.233 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 15:55:59.234 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[26] at collect at utils.scala:26), which has no missing parents
25/05/10 15:55:59.238 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 84.6 KiB, free 912.1 MiB)
25/05/10 15:55:59.240 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 912.1 MiB)
25/05/10 15:55:59.241 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:65332 (size: 15.1 KiB, free: 912.3 MiB)
25/05/10 15:55:59.241 dag-scheduler-event-loop INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585
25/05/10 15:55:59.241 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[26] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 15:55:59.243 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/05/10 15:55:59.244 dispatcher-event-loop-8 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 7) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 15:55:59.244 Executor task launch worker for task 0.0 in stage 8.0 (TID 7) INFO Executor: Running task 0.0 in stage 8.0 (TID 7)
25/05/10 15:55:59.299 Executor task launch worker for task 0.0 in stage 8.0 (TID 7) INFO Executor: Finished task 0.0 in stage 8.0 (TID 7). 1438 bytes result sent to driver
25/05/10 15:55:59.300 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 7) in 56 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 15:55:59.300 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/05/10 15:55:59.301 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 8 (collect at utils.scala:26) finished in 0.066 s
25/05/10 15:55:59.301 dag-scheduler-event-loop INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 15:55:59.301 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/05/10 15:55:59.301 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 8 finished: collect at utils.scala:26, took 0.071260 s
25/05/10 15:56:13.906 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:56:13.906 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:56:13.910 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 15:56:13.910 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 15:56:13.913 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 15:56:13.913 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 16:20:45.145 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:65332 in memory (size: 15.1 KiB, free: 912.3 MiB)
25/05/10 16:20:45.151 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:65332 in memory (size: 15.1 KiB, free: 912.3 MiB)
25/05/10 16:52:25.080 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
25/05/10 16:52:25.082 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/05/10 16:52:25.130 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
25/05/10 16:52:25.168 dispatcher-event-loop-1 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/05/10 16:52:25.221 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
25/05/10 16:52:25.221 shutdown-hook-0 INFO BlockManager: BlockManager stopped
25/05/10 16:52:25.226 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
25/05/10 16:52:25.231 dispatcher-event-loop-6 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/05/10 16:52:25.241 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-9be3e51d-cf9e-44df-b93c-9d6d89bc1db7\userFiles-8f56890c-11da-4b60-946a-3838a2d4405c
java.io.IOException: Failed to delete: C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-9be3e51d-cf9e-44df-b93c-9d6d89bc1db7\userFiles-8f56890c-11da-4b60-946a-3838a2d4405c\sparklyr-3.5-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:147)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:130)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:90)
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1126)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2305)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2305)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2211)
	at org.apache.spark.SparkContext.$anonfun$new$34(SparkContext.scala:681)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
25/05/10 16:52:25.244 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
25/05/10 16:52:25.244 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
25/05/10 16:52:25.245 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-9be3e51d-cf9e-44df-b93c-9d6d89bc1db7
25/05/10 16:52:25.247 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-9be3e51d-cf9e-44df-b93c-9d6d89bc1db7
java.io.IOException: Failed to delete: C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-9be3e51d-cf9e-44df-b93c-9d6d89bc1db7\userFiles-8f56890c-11da-4b60-946a-3838a2d4405c\sparklyr-3.5-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:147)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:130)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:130)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:90)
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1126)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
25/05/10 16:52:25.248 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\Owner\AppData\Local\Temp\spark-a201182d-1a0d-48bf-8261-a9ce2b74d53d
25/05/10 16:52:25.250 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-9be3e51d-cf9e-44df-b93c-9d6d89bc1db7\userFiles-8f56890c-11da-4b60-946a-3838a2d4405c
25/05/10 16:52:25.252 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-9be3e51d-cf9e-44df-b93c-9d6d89bc1db7\userFiles-8f56890c-11da-4b60-946a-3838a2d4405c
java.io.IOException: Failed to delete: C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-9be3e51d-cf9e-44df-b93c-9d6d89bc1db7\userFiles-8f56890c-11da-4b60-946a-3838a2d4405c\sparklyr-3.5-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:147)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:130)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:90)
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1126)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
25/05/10 16:52:44.189 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/conf/hive-site.xml
25/05/10 16:52:44.510 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.5.5
25/05/10 16:52:44.511 nioEventLoopGroup-2-2 INFO SparkContext: OS info Windows 11, 10.0, amd64
25/05/10 16:52:44.512 nioEventLoopGroup-2-2 INFO SparkContext: Java version 1.8.0_451
25/05/10 16:52:44.542 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/05/10 16:52:44.655 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/05/10 16:52:44.744 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
25/05/10 16:52:44.744 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
25/05/10 16:52:44.745 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
25/05/10 16:52:44.745 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
25/05/10 16:52:44.780 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 8192, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/05/10 16:52:44.802 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
25/05/10 16:52:44.803 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/05/10 16:52:44.898 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: Owner
25/05/10 16:52:44.899 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: Owner
25/05/10 16:52:44.899 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
25/05/10 16:52:44.899 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
25/05/10 16:52:44.900 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Owner; groups with view permissions: EMPTY; users with modify permissions: Owner; groups with modify permissions: EMPTY
25/05/10 16:52:45.022 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 52036.
25/05/10 16:52:45.061 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
25/05/10 16:52:45.110 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
25/05/10 16:52:45.141 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/05/10 16:52:45.141 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/05/10 16:52:45.144 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/05/10 16:52:45.187 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\blockmgr-02339aad-aa6a-4c8a-89ea-ed6797d7fd50
25/05/10 16:52:45.209 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
25/05/10 16:52:45.229 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
25/05/10 16:52:45.232 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/local]. Please check your configured local directories.
25/05/10 16:52:45.448 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 127.0.0.1:4040 for SparkUI
25/05/10 16:52:45.557 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/05/10 16:52:45.611 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/Owner/AppData/Local/R/win-library/4.4/sparklyr/java/sparklyr-3.5-2.12.jar at spark://127.0.0.1:52036/jars/sparklyr-3.5-2.12.jar with timestamp 1746910364498
25/05/10 16:52:45.706 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host 127.0.0.1
25/05/10 16:52:45.707 nioEventLoopGroup-2-2 INFO Executor: OS info Windows 11, 10.0, amd64
25/05/10 16:52:45.707 nioEventLoopGroup-2-2 INFO Executor: Java version 1.8.0_451
25/05/10 16:52:45.715 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/05/10 16:52:45.715 nioEventLoopGroup-2-2 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@7029a709 for default.
25/05/10 16:52:45.742 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://127.0.0.1:52036/jars/sparklyr-3.5-2.12.jar with timestamp 1746910364498
25/05/10 16:52:45.801 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:52036 after 23 ms (0 ms spent in bootstraps)
25/05/10 16:52:45.807 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://127.0.0.1:52036/jars/sparklyr-3.5-2.12.jar to C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-3ef10e2b-63f1-45a3-a45a-7d02df269a73\userFiles-5fc69666-3017-4aeb-b755-d2ca557eb144\fetchFileTemp2519541611515937803.tmp
25/05/10 16:52:45.975 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/local/spark-3ef10e2b-63f1-45a3-a45a-7d02df269a73/userFiles-5fc69666-3017-4aeb-b755-d2ca557eb144/sparklyr-3.5-2.12.jar to class loader default
25/05/10 16:52:46.019 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52088.
25/05/10 16:52:46.019 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on 127.0.0.1:52088
25/05/10 16:52:46.022 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/05/10 16:52:46.032 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 52088, None)
25/05/10 16:52:46.037 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:52088 with 912.3 MiB RAM, BlockManagerId(driver, 127.0.0.1, 52088, None)
25/05/10 16:52:46.044 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 52088, None)
25/05/10 16:52:46.047 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 52088, None)
25/05/10 16:52:46.474 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
25/05/10 16:52:46.484 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/hive'.
25/05/10 16:52:50.891 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/05/10 16:52:51.245 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/hive
25/05/10 16:52:51.454 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
25/05/10 16:52:51.455 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
25/05/10 16:52:51.455 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
25/05/10 16:52:51.525 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
25/05/10 16:52:51.719 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
25/05/10 16:52:51.720 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
25/05/10 16:52:52.899 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
25/05/10 16:52:54.451 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
25/05/10 16:52:54.454 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
25/05/10 16:52:54.526 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
25/05/10 16:52:54.527 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@10.0.0.88
25/05/10 16:52:54.554 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
25/05/10 16:52:54.721 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
25/05/10 16:52:54.724 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
25/05/10 16:52:54.773 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
25/05/10 16:52:54.890 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 16:52:54.892 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 16:52:54.913 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
25/05/10 16:52:54.913 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: global_temp	
25/05/10 16:52:54.914 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
25/05/10 16:52:54.915 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 16:52:54.915 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 16:52:54.917 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 16:52:54.917 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 16:52:54.919 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 16:52:54.919 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 16:53:17.559 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 16:53:17.559 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 16:53:17.561 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 16:53:17.561 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 16:53:17.562 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 16:53:17.563 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 16:53:18.319 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 253.2008 ms
25/05/10 16:53:18.523 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 16:53:18.536 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0.012388 s
25/05/10 16:53:19.263 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 10.3066 ms
25/05/10 16:53:19.282 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 16:53:19.305 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
25/05/10 16:53:19.306 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
25/05/10 16:53:19.306 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 16:53:19.307 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 16:53:19.311 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26), which has no missing parents
25/05/10 16:53:19.378 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KiB, free 912.3 MiB)
25/05/10 16:53:19.494 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.3 MiB)
25/05/10 16:53:19.499 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:52088 (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 16:53:19.506 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
25/05/10 16:53:19.534 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 16:53:19.535 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/05/10 16:53:19.597 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 16:53:19.614 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/05/10 16:53:20.008 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 131.222 ms
25/05/10 16:53:20.037 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1542 bytes result sent to driver
25/05/10 16:53:20.049 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 476 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 16:53:20.052 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/05/10 16:53:20.060 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0.732 s
25/05/10 16:53:20.063 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 16:53:20.063 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/05/10 16:53:20.064 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0.780788 s
25/05/10 16:53:20.127 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 33.1497 ms
25/05/10 16:53:20.393 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 16:53:20.394 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
25/05/10 16:53:20.394 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
25/05/10 16:53:20.394 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 16:53:20.395 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 16:53:20.396 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26), which has no missing parents
25/05/10 16:53:20.400 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.9 KiB, free 912.3 MiB)
25/05/10 16:53:20.404 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.3 MiB)
25/05/10 16:53:20.404 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:52088 (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 16:53:20.405 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
25/05/10 16:53:20.406 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 16:53:20.406 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/05/10 16:53:20.407 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 16:53:20.408 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
25/05/10 16:53:20.417 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1370 bytes result sent to driver
25/05/10 16:53:20.422 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 15 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 16:53:20.423 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/05/10 16:53:20.425 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0.026 s
25/05/10 16:53:20.425 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 16:53:20.426 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/05/10 16:53:20.427 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0.032245 s
25/05/10 16:53:20.615 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 16:53:20.615 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 16:53:20.619 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 16:53:20.619 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 16:53:20.622 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 16:53:20.622 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 16:53:20.747 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 76.602 ms
25/05/10 16:53:20.775 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.8667 ms
25/05/10 16:53:20.792 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.2595 ms
25/05/10 16:53:24.872 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 16:53:24.872 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 16:53:24.874 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 16:53:24.874 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 16:53:24.875 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 16:53:24.875 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 16:53:24.935 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 16:53:24.936 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
25/05/10 16:53:24.936 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
25/05/10 16:53:24.937 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 16:53:24.937 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 16:53:24.938 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at collect at utils.scala:26), which has no missing parents
25/05/10 16:53:24.942 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.5 KiB, free 912.3 MiB)
25/05/10 16:53:24.946 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.3 MiB)
25/05/10 16:53:24.948 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:52088 (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 16:53:24.948 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
25/05/10 16:53:24.949 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 16:53:24.949 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/05/10 16:53:24.951 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9380 bytes) 
25/05/10 16:53:24.952 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
25/05/10 16:53:24.961 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 6.0367 ms
25/05/10 16:53:24.963 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1393 bytes result sent to driver
25/05/10 16:53:24.965 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 15 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 16:53:24.965 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/05/10 16:53:24.965 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 0.025 s
25/05/10 16:53:24.966 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 16:53:24.966 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/05/10 16:53:24.966 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 0.030877 s
25/05/10 16:53:24.973 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.4289 ms
25/05/10 16:53:25.843 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:52088 in memory (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 16:53:25.851 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:52088 in memory (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 16:53:25.856 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:52088 in memory (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 16:53:27.038 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.6681 ms
25/05/10 16:53:27.046 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 16:53:27.047 dag-scheduler-event-loop INFO DAGScheduler: Got job 4 (collect at utils.scala:26) with 1 output partitions
25/05/10 16:53:27.048 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:26)
25/05/10 16:53:27.048 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 16:53:27.048 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 16:53:27.049 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[14] at collect at utils.scala:26), which has no missing parents
25/05/10 16:53:27.052 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.7 KiB, free 912.3 MiB)
25/05/10 16:53:27.055 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.3 MiB)
25/05/10 16:53:27.056 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:52088 (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 16:53:27.057 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
25/05/10 16:53:27.057 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 16:53:27.057 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/05/10 16:53:27.059 dispatcher-event-loop-10 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 16:53:27.060 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
25/05/10 16:53:27.076 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 11.7593 ms
25/05/10 16:53:27.081 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1413 bytes result sent to driver
25/05/10 16:53:27.084 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 25 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 16:53:27.084 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/05/10 16:53:27.085 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 3 (collect at utils.scala:26) finished in 0.035 s
25/05/10 16:53:27.086 dag-scheduler-event-loop INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 16:53:27.086 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/05/10 16:53:27.086 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 4 finished: collect at utils.scala:26, took 0.039974 s
25/05/10 16:53:27.102 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 10.4608 ms
25/05/10 16:53:27.293 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 16:53:27.294 dag-scheduler-event-loop INFO DAGScheduler: Got job 5 (collect at utils.scala:26) with 1 output partitions
25/05/10 16:53:27.294 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:26)
25/05/10 16:53:27.294 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 16:53:27.294 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 16:53:27.295 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[16] at collect at utils.scala:26), which has no missing parents
25/05/10 16:53:27.299 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.7 KiB, free 912.3 MiB)
25/05/10 16:53:27.301 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.3 MiB)
25/05/10 16:53:27.301 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:52088 (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 16:53:27.302 dag-scheduler-event-loop INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
25/05/10 16:53:27.302 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 16:53:27.302 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/05/10 16:53:27.304 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 16:53:27.304 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
25/05/10 16:53:27.309 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1370 bytes result sent to driver
25/05/10 16:53:27.310 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 16:53:27.311 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/05/10 16:53:27.311 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 4 (collect at utils.scala:26) finished in 0.014 s
25/05/10 16:53:27.312 dag-scheduler-event-loop INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 16:53:27.312 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/05/10 16:53:27.312 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 5 finished: collect at utils.scala:26, took 0.019131 s
25/05/10 16:53:27.543 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 16:53:27.543 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 16:53:27.546 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 16:53:27.546 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 16:53:27.549 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 16:53:27.550 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 16:53:40.080 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 12.3899 ms
25/05/10 16:53:40.125 dag-scheduler-event-loop INFO DAGScheduler: Got job 6 (collect at utils.scala:26) with 1 output partitions
25/05/10 16:53:40.125 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:26)
25/05/10 16:53:40.125 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 16:53:40.128 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 16:53:40.129 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 5 (*(1) Scan ExistingRDD[ProvinceState#288,CountryRegion#289,Lat#290,Long#291,Date#292,Confirmed_COVID_Cases#293,Days#294]
 MapPartitionsRDD[19] at collect at utils.scala:26), which has no missing parents
25/05/10 16:53:40.150 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 12.1 KiB, free 912.3 MiB)
25/05/10 16:53:40.153 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 912.3 MiB)
25/05/10 16:53:40.154 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:52088 (size: 5.8 KiB, free: 912.3 MiB)
25/05/10 16:53:40.154 dag-scheduler-event-loop INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
25/05/10 16:53:40.155 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (*(1) Scan ExistingRDD[ProvinceState#288,CountryRegion#289,Lat#290,Long#291,Date#292,Confirmed_COVID_Cases#293,Days#294]
 MapPartitionsRDD[19] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 16:53:40.155 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/05/10 16:53:40.379 dispatcher-event-loop-8 WARN TaskSetManager: Stage 5 contains a task of very large size (29945 KiB). The maximum recommended task size is 1000 KiB.
25/05/10 16:53:40.379 dispatcher-event-loop-8 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 30664575 bytes) 
25/05/10 16:53:40.380 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
25/05/10 16:53:40.569 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:52088 in memory (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 16:53:40.575 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:52088 in memory (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 16:53:40.647 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO CodeGenerator: Code generated in 9.2787 ms
25/05/10 16:53:41.063 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO MemoryStore: Block rdd_19_0 stored as values in memory (estimated size 11.3 MiB, free 901.0 MiB)
25/05/10 16:53:41.064 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_19_0 in memory on 127.0.0.1:52088 (size: 11.3 MiB, free: 901.0 MiB)
25/05/10 16:53:41.083 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: 1 block locks were not released by task 0.0 in stage 5.0 (TID 5)
[rdd_19_0]
25/05/10 16:53:41.086 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1359 bytes result sent to driver
25/05/10 16:53:41.088 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 932 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 16:53:41.088 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/05/10 16:53:41.089 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 5 (collect at utils.scala:26) finished in 0.959 s
25/05/10 16:53:41.089 dag-scheduler-event-loop INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 16:53:41.089 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/05/10 16:53:41.128 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 16:53:41.130 dag-scheduler-event-loop INFO DAGScheduler: Got job 7 (collect at utils.scala:26) with 1 output partitions
25/05/10 16:53:41.130 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:26)
25/05/10 16:53:41.130 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 16:53:41.134 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 16:53:41.135 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[23] at collect at utils.scala:26), which has no missing parents
25/05/10 16:53:41.143 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.8 KiB, free 901.0 MiB)
25/05/10 16:53:41.146 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 901.0 MiB)
25/05/10 16:53:41.147 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:52088 (size: 6.7 KiB, free: 901.0 MiB)
25/05/10 16:53:41.148 dag-scheduler-event-loop INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
25/05/10 16:53:41.149 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 16:53:41.149 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/05/10 16:53:41.269 dispatcher-event-loop-11 WARN TaskSetManager: Stage 6 contains a task of very large size (29945 KiB). The maximum recommended task size is 1000 KiB.
25/05/10 16:53:41.270 dispatcher-event-loop-11 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 30664575 bytes) 
25/05/10 16:53:41.270 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
25/05/10 16:53:41.325 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO BlockManager: Found block rdd_19_0 locally
25/05/10 16:53:41.337 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO CodeGenerator: Code generated in 4.3461 ms
25/05/10 16:53:41.373 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO CodeGenerator: Code generated in 26.9478 ms
25/05/10 16:53:41.382 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: 1 block locks were not released by task 0.0 in stage 6.0 (TID 6)
[rdd_19_0]
25/05/10 16:53:41.383 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1784 bytes result sent to driver
25/05/10 16:53:41.384 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 230 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 16:53:41.384 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/05/10 16:53:41.385 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 6 (collect at utils.scala:26) finished in 0.249 s
25/05/10 16:53:41.386 dag-scheduler-event-loop INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 16:53:41.386 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/05/10 16:53:41.386 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 7 finished: collect at utils.scala:26, took 0.258297 s
25/05/10 16:53:41.416 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 22.8926 ms
25/05/10 16:59:36.937 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.3472 ms
25/05/10 16:59:36.946 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 16:59:36.947 dag-scheduler-event-loop INFO DAGScheduler: Got job 8 (collect at utils.scala:26) with 1 output partitions
25/05/10 16:59:36.947 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:26)
25/05/10 16:59:36.947 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 16:59:36.947 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 16:59:36.949 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[25] at collect at utils.scala:26), which has no missing parents
25/05/10 16:59:36.951 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 10.8 KiB, free 901.0 MiB)
25/05/10 16:59:36.954 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 901.0 MiB)
25/05/10 16:59:36.956 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:52088 (size: 4.6 KiB, free: 901.0 MiB)
25/05/10 16:59:36.957 dag-scheduler-event-loop INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585
25/05/10 16:59:36.957 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[25] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 16:59:36.958 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/05/10 16:59:37.082 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:52088 in memory (size: 6.7 KiB, free: 901.0 MiB)
25/05/10 16:59:37.145 dispatcher-event-loop-4 WARN TaskSetManager: Stage 7 contains a task of very large size (29945 KiB). The maximum recommended task size is 1000 KiB.
25/05/10 16:59:37.145 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 30664575 bytes) 
25/05/10 16:59:37.147 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
25/05/10 16:59:37.260 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO CodeGenerator: Code generated in 19.7927 ms
25/05/10 16:59:37.458 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 266001 bytes result sent to driver
25/05/10 16:59:37.460 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 501 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 16:59:37.461 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/05/10 16:59:37.462 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 7 (collect at utils.scala:26) finished in 0.511 s
25/05/10 16:59:37.462 dag-scheduler-event-loop INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 16:59:37.462 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/05/10 16:59:37.463 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 8 finished: collect at utils.scala:26, took 0.516374 s
25/05/10 17:02:14.836 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:02:14.838 dag-scheduler-event-loop INFO DAGScheduler: Got job 9 (collect at utils.scala:26) with 1 output partitions
25/05/10 17:02:14.838 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:26)
25/05/10 17:02:14.838 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:02:14.838 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:02:14.840 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[27] at collect at utils.scala:26), which has no missing parents
25/05/10 17:02:14.843 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 10.8 KiB, free 901.0 MiB)
25/05/10 17:02:14.845 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 901.0 MiB)
25/05/10 17:02:14.847 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:52088 (size: 4.6 KiB, free: 901.0 MiB)
25/05/10 17:02:14.847 dag-scheduler-event-loop INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585
25/05/10 17:02:14.848 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[27] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 17:02:14.848 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/05/10 17:02:14.949 dispatcher-event-loop-6 WARN TaskSetManager: Stage 8 contains a task of very large size (29945 KiB). The maximum recommended task size is 1000 KiB.
25/05/10 17:02:14.949 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 30664575 bytes) 
25/05/10 17:02:14.951 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
25/05/10 17:02:15.013 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 265958 bytes result sent to driver
25/05/10 17:02:15.015 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 167 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 17:02:15.015 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/05/10 17:02:15.015 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 8 (collect at utils.scala:26) finished in 0.174 s
25/05/10 17:02:15.015 dag-scheduler-event-loop INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:02:15.015 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/05/10 17:02:15.016 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 9 finished: collect at utils.scala:26, took 0.179009 s
25/05/10 17:03:17.453 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:03:17.454 dag-scheduler-event-loop INFO DAGScheduler: Got job 10 (collect at utils.scala:26) with 1 output partitions
25/05/10 17:03:17.455 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:26)
25/05/10 17:03:17.455 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:03:17.455 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:03:17.456 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[29] at collect at utils.scala:26), which has no missing parents
25/05/10 17:03:17.458 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 10.8 KiB, free 901.0 MiB)
25/05/10 17:03:17.461 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 901.0 MiB)
25/05/10 17:03:17.461 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:52088 (size: 4.6 KiB, free: 901.0 MiB)
25/05/10 17:03:17.462 dag-scheduler-event-loop INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585
25/05/10 17:03:17.463 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[29] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 17:03:17.463 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/05/10 17:03:17.506 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:52088 in memory (size: 4.6 KiB, free: 901.0 MiB)
25/05/10 17:03:17.574 dispatcher-event-loop-11 WARN TaskSetManager: Stage 9 contains a task of very large size (29945 KiB). The maximum recommended task size is 1000 KiB.
25/05/10 17:03:17.575 dispatcher-event-loop-11 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 30664575 bytes) 
25/05/10 17:03:17.576 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
25/05/10 17:03:17.680 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 266001 bytes result sent to driver
25/05/10 17:03:17.681 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 217 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 17:03:17.681 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/05/10 17:03:17.682 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 9 (collect at utils.scala:26) finished in 0.224 s
25/05/10 17:03:17.682 dag-scheduler-event-loop INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:03:17.682 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/05/10 17:03:17.682 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 10 finished: collect at utils.scala:26, took 0.228589 s
25/05/10 17:03:32.081 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:03:32.083 dag-scheduler-event-loop INFO DAGScheduler: Got job 11 (collect at utils.scala:26) with 1 output partitions
25/05/10 17:03:32.083 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:26)
25/05/10 17:03:32.083 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:03:32.083 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:03:32.085 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[31] at collect at utils.scala:26), which has no missing parents
25/05/10 17:03:32.087 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 10.8 KiB, free 901.0 MiB)
25/05/10 17:03:32.089 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 901.0 MiB)
25/05/10 17:03:32.090 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:52088 (size: 4.6 KiB, free: 901.0 MiB)
25/05/10 17:03:32.090 dag-scheduler-event-loop INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585
25/05/10 17:03:32.091 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[31] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 17:03:32.091 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/05/10 17:03:32.184 dispatcher-event-loop-1 WARN TaskSetManager: Stage 10 contains a task of very large size (29945 KiB). The maximum recommended task size is 1000 KiB.
25/05/10 17:03:32.184 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 30664575 bytes) 
25/05/10 17:03:32.185 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
25/05/10 17:03:32.259 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 266001 bytes result sent to driver
25/05/10 17:03:32.260 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 167 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 17:03:32.260 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/05/10 17:03:32.260 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 10 (collect at utils.scala:26) finished in 0.175 s
25/05/10 17:03:32.260 dag-scheduler-event-loop INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:03:32.260 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
25/05/10 17:03:32.260 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 11 finished: collect at utils.scala:26, took 0.178008 s
25/05/10 17:03:46.495 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:03:46.496 dag-scheduler-event-loop INFO DAGScheduler: Got job 12 (collect at utils.scala:26) with 1 output partitions
25/05/10 17:03:46.497 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:26)
25/05/10 17:03:46.497 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:03:46.497 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:03:46.498 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[33] at collect at utils.scala:26), which has no missing parents
25/05/10 17:03:46.500 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 10.8 KiB, free 900.9 MiB)
25/05/10 17:03:46.502 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 900.9 MiB)
25/05/10 17:03:46.503 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:52088 (size: 4.6 KiB, free: 901.0 MiB)
25/05/10 17:03:46.503 dag-scheduler-event-loop INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585
25/05/10 17:03:46.504 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[33] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 17:03:46.504 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/05/10 17:03:46.538 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:52088 in memory (size: 4.6 KiB, free: 901.0 MiB)
25/05/10 17:03:46.602 dispatcher-event-loop-8 WARN TaskSetManager: Stage 11 contains a task of very large size (29945 KiB). The maximum recommended task size is 1000 KiB.
25/05/10 17:03:46.602 dispatcher-event-loop-8 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 30664575 bytes) 
25/05/10 17:03:46.602 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
25/05/10 17:03:46.673 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 266001 bytes result sent to driver
25/05/10 17:03:46.674 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 169 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 17:03:46.675 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/05/10 17:03:46.675 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 11 (collect at utils.scala:26) finished in 0.176 s
25/05/10 17:03:46.675 dag-scheduler-event-loop INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:03:46.675 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/05/10 17:03:46.676 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 12 finished: collect at utils.scala:26, took 0.179619 s
25/05/10 17:04:01.133 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:04:01.134 dag-scheduler-event-loop INFO DAGScheduler: Got job 13 (collect at utils.scala:26) with 1 output partitions
25/05/10 17:04:01.134 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:26)
25/05/10 17:04:01.134 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:04:01.134 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:04:01.135 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[35] at collect at utils.scala:26), which has no missing parents
25/05/10 17:04:01.138 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 10.8 KiB, free 900.9 MiB)
25/05/10 17:04:01.139 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 900.9 MiB)
25/05/10 17:04:01.140 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:52088 (size: 4.6 KiB, free: 901.0 MiB)
25/05/10 17:04:01.141 dag-scheduler-event-loop INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585
25/05/10 17:04:01.141 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[35] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 17:04:01.141 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
25/05/10 17:04:01.236 dispatcher-event-loop-9 WARN TaskSetManager: Stage 12 contains a task of very large size (29945 KiB). The maximum recommended task size is 1000 KiB.
25/05/10 17:04:01.236 dispatcher-event-loop-9 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 30664575 bytes) 
25/05/10 17:04:01.237 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
25/05/10 17:04:01.320 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 266001 bytes result sent to driver
25/05/10 17:04:01.322 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 180 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 17:04:01.322 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
25/05/10 17:04:01.323 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 12 (collect at utils.scala:26) finished in 0.187 s
25/05/10 17:04:01.323 dag-scheduler-event-loop INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:04:01.323 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
25/05/10 17:04:01.324 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 13 finished: collect at utils.scala:26, took 0.190519 s
25/05/10 17:09:15.658 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:09:15.659 dag-scheduler-event-loop INFO DAGScheduler: Got job 14 (collect at utils.scala:26) with 1 output partitions
25/05/10 17:09:15.659 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:26)
25/05/10 17:09:15.659 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:09:15.660 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:09:15.663 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[37] at collect at utils.scala:26), which has no missing parents
25/05/10 17:09:15.667 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 10.8 KiB, free 900.9 MiB)
25/05/10 17:09:15.671 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 900.9 MiB)
25/05/10 17:09:15.674 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:52088 (size: 4.6 KiB, free: 901.0 MiB)
25/05/10 17:09:15.674 dag-scheduler-event-loop INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585
25/05/10 17:09:15.675 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[37] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 17:09:15.675 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
25/05/10 17:09:15.736 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:52088 in memory (size: 4.6 KiB, free: 901.0 MiB)
25/05/10 17:09:15.857 dispatcher-event-loop-11 WARN TaskSetManager: Stage 13 contains a task of very large size (29945 KiB). The maximum recommended task size is 1000 KiB.
25/05/10 17:09:15.857 dispatcher-event-loop-11 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 30664575 bytes) 
25/05/10 17:09:15.858 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
25/05/10 17:09:15.928 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 266001 bytes result sent to driver
25/05/10 17:09:15.930 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 253 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 17:09:15.930 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
25/05/10 17:09:15.932 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 13 (collect at utils.scala:26) finished in 0.268 s
25/05/10 17:09:15.932 dag-scheduler-event-loop INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:09:15.933 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
25/05/10 17:09:15.933 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 14 finished: collect at utils.scala:26, took 0.274642 s
25/05/10 17:09:30.602 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:09:30.603 dag-scheduler-event-loop INFO DAGScheduler: Got job 15 (collect at utils.scala:26) with 1 output partitions
25/05/10 17:09:30.603 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:26)
25/05/10 17:09:30.603 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:09:30.603 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:09:30.604 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[39] at collect at utils.scala:26), which has no missing parents
25/05/10 17:09:30.607 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 10.8 KiB, free 900.9 MiB)
25/05/10 17:09:30.610 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 900.9 MiB)
25/05/10 17:09:30.611 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:52088 (size: 4.6 KiB, free: 901.0 MiB)
25/05/10 17:09:30.611 dag-scheduler-event-loop INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585
25/05/10 17:09:30.611 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[39] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 17:09:30.611 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
25/05/10 17:09:30.736 dispatcher-event-loop-0 WARN TaskSetManager: Stage 14 contains a task of very large size (29945 KiB). The maximum recommended task size is 1000 KiB.
25/05/10 17:09:30.737 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 30664575 bytes) 
25/05/10 17:09:30.737 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
25/05/10 17:09:30.818 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 266001 bytes result sent to driver
25/05/10 17:09:30.819 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 207 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 17:09:30.819 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
25/05/10 17:09:30.820 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 14 (collect at utils.scala:26) finished in 0.215 s
25/05/10 17:09:30.820 dag-scheduler-event-loop INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:09:30.820 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
25/05/10 17:09:30.820 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 15 finished: collect at utils.scala:26, took 0.218437 s
25/05/10 17:09:51.605 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
25/05/10 17:09:51.607 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/05/10 17:09:51.647 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
25/05/10 17:09:51.679 dispatcher-event-loop-7 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/05/10 17:09:51.736 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
25/05/10 17:09:51.737 shutdown-hook-0 INFO BlockManager: BlockManager stopped
25/05/10 17:09:51.741 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
25/05/10 17:09:51.745 dispatcher-event-loop-10 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/05/10 17:09:51.752 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-3ef10e2b-63f1-45a3-a45a-7d02df269a73\userFiles-5fc69666-3017-4aeb-b755-d2ca557eb144
java.io.IOException: Failed to delete: C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-3ef10e2b-63f1-45a3-a45a-7d02df269a73\userFiles-5fc69666-3017-4aeb-b755-d2ca557eb144\sparklyr-3.5-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:147)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:130)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:90)
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1126)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2305)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2305)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2211)
	at org.apache.spark.SparkContext.$anonfun$new$34(SparkContext.scala:681)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
25/05/10 17:09:51.754 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
25/05/10 17:09:51.754 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
25/05/10 17:09:51.754 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\Owner\AppData\Local\Temp\spark-b1659f10-05c5-4731-8de6-ef97ae782633
25/05/10 17:09:51.756 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-3ef10e2b-63f1-45a3-a45a-7d02df269a73
25/05/10 17:09:51.758 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-3ef10e2b-63f1-45a3-a45a-7d02df269a73
java.io.IOException: Failed to delete: C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-3ef10e2b-63f1-45a3-a45a-7d02df269a73\userFiles-5fc69666-3017-4aeb-b755-d2ca557eb144\sparklyr-3.5-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:147)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:130)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:130)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:90)
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1126)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
25/05/10 17:09:51.758 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-3ef10e2b-63f1-45a3-a45a-7d02df269a73\userFiles-5fc69666-3017-4aeb-b755-d2ca557eb144
25/05/10 17:09:51.760 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-3ef10e2b-63f1-45a3-a45a-7d02df269a73\userFiles-5fc69666-3017-4aeb-b755-d2ca557eb144
java.io.IOException: Failed to delete: C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-3ef10e2b-63f1-45a3-a45a-7d02df269a73\userFiles-5fc69666-3017-4aeb-b755-d2ca557eb144\sparklyr-3.5-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:147)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:130)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:90)
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1126)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
25/05/10 17:11:49.244 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/conf/hive-site.xml
25/05/10 17:11:49.464 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.5.5
25/05/10 17:11:49.464 nioEventLoopGroup-2-2 INFO SparkContext: OS info Windows 11, 10.0, amd64
25/05/10 17:11:49.464 nioEventLoopGroup-2-2 INFO SparkContext: Java version 1.8.0_451
25/05/10 17:11:49.488 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/05/10 17:11:49.584 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/05/10 17:11:49.643 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
25/05/10 17:11:49.644 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
25/05/10 17:11:49.644 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
25/05/10 17:11:49.644 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
25/05/10 17:11:49.675 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 8192, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/05/10 17:11:49.687 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
25/05/10 17:11:49.688 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/05/10 17:11:49.778 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: Owner
25/05/10 17:11:49.780 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: Owner
25/05/10 17:11:49.781 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
25/05/10 17:11:49.781 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
25/05/10 17:11:49.782 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Owner; groups with view permissions: EMPTY; users with modify permissions: Owner; groups with modify permissions: EMPTY
25/05/10 17:11:49.909 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 53455.
25/05/10 17:11:49.948 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
25/05/10 17:11:49.993 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
25/05/10 17:11:50.027 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/05/10 17:11:50.027 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/05/10 17:11:50.030 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/05/10 17:11:50.068 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\blockmgr-848c6a98-017a-48de-9c5f-31db1a73d30f
25/05/10 17:11:50.091 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
25/05/10 17:11:50.111 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
25/05/10 17:11:50.114 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/local]. Please check your configured local directories.
25/05/10 17:11:50.313 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 127.0.0.1:4040 for SparkUI
25/05/10 17:11:50.424 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/05/10 17:11:50.475 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/Owner/AppData/Local/R/win-library/4.4/sparklyr/java/sparklyr-3.5-2.12.jar at spark://127.0.0.1:53455/jars/sparklyr-3.5-2.12.jar with timestamp 1746911509454
25/05/10 17:11:50.566 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host 127.0.0.1
25/05/10 17:11:50.567 nioEventLoopGroup-2-2 INFO Executor: OS info Windows 11, 10.0, amd64
25/05/10 17:11:50.567 nioEventLoopGroup-2-2 INFO Executor: Java version 1.8.0_451
25/05/10 17:11:50.575 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/05/10 17:11:50.576 nioEventLoopGroup-2-2 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4caae392 for default.
25/05/10 17:11:50.589 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://127.0.0.1:53455/jars/sparklyr-3.5-2.12.jar with timestamp 1746911509454
25/05/10 17:11:50.647 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:53455 after 24 ms (0 ms spent in bootstraps)
25/05/10 17:11:50.657 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://127.0.0.1:53455/jars/sparklyr-3.5-2.12.jar to C:\Users\Owner\AppData\Local\spark\spark-3.5.5-bin-hadoop3\tmp\local\spark-4fb14a2c-1f75-4ccc-95ed-f3f28fd557ee\userFiles-ee117cd9-fa8f-4670-bd39-4366ee60a925\fetchFileTemp8042676886671698048.tmp
25/05/10 17:11:50.799 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/local/spark-4fb14a2c-1f75-4ccc-95ed-f3f28fd557ee/userFiles-ee117cd9-fa8f-4670-bd39-4366ee60a925/sparklyr-3.5-2.12.jar to class loader default
25/05/10 17:11:50.822 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53507.
25/05/10 17:11:50.823 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on 127.0.0.1:53507
25/05/10 17:11:50.824 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/05/10 17:11:50.834 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 53507, None)
25/05/10 17:11:50.840 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:53507 with 912.3 MiB RAM, BlockManagerId(driver, 127.0.0.1, 53507, None)
25/05/10 17:11:50.843 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 53507, None)
25/05/10 17:11:50.845 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 53507, None)
25/05/10 17:11:51.225 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
25/05/10 17:11:51.234 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/hive'.
25/05/10 17:11:55.463 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/05/10 17:11:55.831 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/Owner/AppData/Local/spark/spark-3.5.5-bin-hadoop3/tmp/hive
25/05/10 17:11:56.089 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
25/05/10 17:11:56.090 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
25/05/10 17:11:56.091 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
25/05/10 17:11:56.166 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
25/05/10 17:11:56.347 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
25/05/10 17:11:56.348 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
25/05/10 17:11:57.624 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
25/05/10 17:11:59.041 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
25/05/10 17:11:59.044 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
25/05/10 17:11:59.118 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
25/05/10 17:11:59.118 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@10.0.0.88
25/05/10 17:11:59.143 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
25/05/10 17:11:59.312 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
25/05/10 17:11:59.314 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
25/05/10 17:11:59.354 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
25/05/10 17:11:59.464 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 17:11:59.466 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 17:11:59.485 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
25/05/10 17:11:59.486 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: global_temp	
25/05/10 17:11:59.486 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
25/05/10 17:11:59.487 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 17:11:59.487 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 17:11:59.489 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 17:11:59.489 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 17:11:59.490 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 17:11:59.490 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 17:12:05.845 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 17:12:05.846 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 17:12:05.850 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 17:12:05.850 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 17:12:05.853 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 17:12:05.854 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 17:12:06.711 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 249.4268 ms
25/05/10 17:12:06.862 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:12:06.873 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0.009760 s
25/05/10 17:12:07.532 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 19.3073 ms
25/05/10 17:12:07.555 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:12:07.573 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
25/05/10 17:12:07.574 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
25/05/10 17:12:07.574 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:12:07.575 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:12:07.578 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26), which has no missing parents
25/05/10 17:12:07.647 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KiB, free 912.3 MiB)
25/05/10 17:12:07.795 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.3 MiB)
25/05/10 17:12:07.799 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 17:12:07.807 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
25/05/10 17:12:07.836 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 17:12:07.837 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/05/10 17:12:07.905 dispatcher-event-loop-10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 17:12:07.920 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/05/10 17:12:08.470 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 204.8767 ms
25/05/10 17:12:08.501 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1542 bytes result sent to driver
25/05/10 17:12:08.526 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 640 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 17:12:08.529 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/05/10 17:12:08.538 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0.947 s
25/05/10 17:12:08.543 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:12:08.544 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/05/10 17:12:08.545 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0.988817 s
25/05/10 17:12:08.606 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 30.2232 ms
25/05/10 17:12:08.836 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:12:08.837 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
25/05/10 17:12:08.837 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
25/05/10 17:12:08.837 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:12:08.837 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:12:08.839 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26), which has no missing parents
25/05/10 17:12:08.841 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.9 KiB, free 912.3 MiB)
25/05/10 17:12:08.843 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.3 MiB)
25/05/10 17:12:08.843 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 17:12:08.844 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
25/05/10 17:12:08.844 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 17:12:08.844 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/05/10 17:12:08.846 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 17:12:08.846 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
25/05/10 17:12:08.853 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1370 bytes result sent to driver
25/05/10 17:12:08.856 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 11 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 17:12:08.856 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/05/10 17:12:08.857 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0.017 s
25/05/10 17:12:08.858 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:12:08.858 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/05/10 17:12:08.858 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0.022099 s
25/05/10 17:12:09.016 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 17:12:09.016 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 17:12:09.021 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 17:12:09.022 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 17:12:09.026 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 17:12:09.027 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 17:12:09.126 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 59.8333 ms
25/05/10 17:12:09.153 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.1467 ms
25/05/10 17:12:09.172 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 10.5604 ms
25/05/10 17:12:13.011 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 17:12:13.011 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 17:12:13.014 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 17:12:13.014 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 17:12:13.015 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 17:12:13.016 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 17:12:13.120 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:12:13.121 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
25/05/10 17:12:13.121 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
25/05/10 17:12:13.121 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:12:13.122 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:12:13.123 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at collect at utils.scala:26), which has no missing parents
25/05/10 17:12:13.127 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.5 KiB, free 912.3 MiB)
25/05/10 17:12:13.130 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.3 MiB)
25/05/10 17:12:13.133 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 17:12:13.134 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
25/05/10 17:12:13.135 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 17:12:13.135 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/05/10 17:12:13.139 dispatcher-event-loop-8 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9380 bytes) 
25/05/10 17:12:13.140 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
25/05/10 17:12:13.148 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 5.2284 ms
25/05/10 17:12:13.151 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1393 bytes result sent to driver
25/05/10 17:12:13.153 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 17 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 17:12:13.153 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/05/10 17:12:13.154 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 0.029 s
25/05/10 17:12:13.155 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:12:13.155 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/05/10 17:12:13.155 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 0.034974 s
25/05/10 17:12:13.162 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.3667 ms
25/05/10 17:12:14.953 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 17:12:14.962 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 17:12:14.968 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 17:12:16.036 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.3104 ms
25/05/10 17:12:16.047 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:12:16.048 dag-scheduler-event-loop INFO DAGScheduler: Got job 4 (collect at utils.scala:26) with 1 output partitions
25/05/10 17:12:16.049 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:26)
25/05/10 17:12:16.049 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:12:16.049 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:12:16.051 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[14] at collect at utils.scala:26), which has no missing parents
25/05/10 17:12:16.054 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.7 KiB, free 912.3 MiB)
25/05/10 17:12:16.057 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.3 MiB)
25/05/10 17:12:16.058 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 17:12:16.059 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
25/05/10 17:12:16.060 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 17:12:16.060 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/05/10 17:12:16.062 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 17:12:16.063 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
25/05/10 17:12:16.078 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 11.2212 ms
25/05/10 17:12:16.083 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1413 bytes result sent to driver
25/05/10 17:12:16.086 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 25 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 17:12:16.086 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/05/10 17:12:16.087 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 3 (collect at utils.scala:26) finished in 0.035 s
25/05/10 17:12:16.088 dag-scheduler-event-loop INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:12:16.088 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/05/10 17:12:16.088 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 4 finished: collect at utils.scala:26, took 0.040990 s
25/05/10 17:12:16.098 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.2946 ms
25/05/10 17:12:16.239 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:12:16.239 dag-scheduler-event-loop INFO DAGScheduler: Got job 5 (collect at utils.scala:26) with 1 output partitions
25/05/10 17:12:16.240 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:26)
25/05/10 17:12:16.240 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:12:16.240 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:12:16.241 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[16] at collect at utils.scala:26), which has no missing parents
25/05/10 17:12:16.242 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.7 KiB, free 912.3 MiB)
25/05/10 17:12:16.244 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.3 MiB)
25/05/10 17:12:16.245 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 17:12:16.245 dag-scheduler-event-loop INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
25/05/10 17:12:16.246 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 17:12:16.246 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/05/10 17:12:16.246 dispatcher-event-loop-11 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 17:12:16.247 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
25/05/10 17:12:16.253 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1413 bytes result sent to driver
25/05/10 17:12:16.254 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 8 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 17:12:16.255 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/05/10 17:12:16.255 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 4 (collect at utils.scala:26) finished in 0.014 s
25/05/10 17:12:16.255 dag-scheduler-event-loop INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:12:16.255 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/05/10 17:12:16.256 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 5 finished: collect at utils.scala:26, took 0.016667 s
25/05/10 17:12:16.372 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 17:12:16.373 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 17:12:16.376 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 17:12:16.376 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 17:12:16.377 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 17:12:16.378 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 17:13:13.699 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 15.6158 ms
25/05/10 17:13:13.727 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:13:13.729 dag-scheduler-event-loop INFO DAGScheduler: Got job 6 (collect at utils.scala:26) with 1 output partitions
25/05/10 17:13:13.729 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:26)
25/05/10 17:13:13.729 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:13:13.729 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:13:13.732 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[18] at collect at utils.scala:26), which has no missing parents
25/05/10 17:13:13.735 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.8 KiB, free 912.3 MiB)
25/05/10 17:13:13.738 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 912.3 MiB)
25/05/10 17:13:13.740 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:53507 (size: 4.6 KiB, free: 912.3 MiB)
25/05/10 17:13:13.741 dag-scheduler-event-loop INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
25/05/10 17:13:13.742 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[18] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 17:13:13.742 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/05/10 17:13:14.011 dispatcher-event-loop-6 WARN TaskSetManager: Stage 5 contains a task of very large size (29945 KiB). The maximum recommended task size is 1000 KiB.
25/05/10 17:13:14.012 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 30664575 bytes) 
25/05/10 17:13:14.012 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
25/05/10 17:13:14.233 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO CodeGenerator: Code generated in 18.1241 ms
25/05/10 17:13:14.306 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 266001 bytes result sent to driver
25/05/10 17:13:14.308 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 564 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 17:13:14.309 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/05/10 17:13:14.310 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 5 (collect at utils.scala:26) finished in 0.576 s
25/05/10 17:13:14.310 dag-scheduler-event-loop INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:13:14.310 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/05/10 17:13:14.310 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 6 finished: collect at utils.scala:26, took 0.582905 s
25/05/10 17:13:14.350 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 19.4825 ms
25/05/10 17:13:14.533 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:53507 in memory (size: 4.6 KiB, free: 912.3 MiB)
25/05/10 17:13:14.538 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 17:13:14.542 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 912.3 MiB)
25/05/10 17:14:07.097 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.3123 ms
25/05/10 17:14:07.108 dag-scheduler-event-loop INFO DAGScheduler: Got job 7 (collect at utils.scala:26) with 1 output partitions
25/05/10 17:14:07.108 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:26)
25/05/10 17:14:07.108 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:14:07.112 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:14:07.113 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 6 (*(1) Scan ExistingRDD[UID#27,iso2#28,iso3#29,code3#30,FIPS#31,Admin2#32,Province_State#33,Country_Region#34,Lat#35,Long_#36,Combined_Key#37,Population#38]
 MapPartitionsRDD[21] at collect at utils.scala:26), which has no missing parents
25/05/10 17:14:07.136 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 13.8 KiB, free 912.3 MiB)
25/05/10 17:14:07.138 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 912.3 MiB)
25/05/10 17:14:07.139 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:53507 (size: 6.2 KiB, free: 912.3 MiB)
25/05/10 17:14:07.139 dag-scheduler-event-loop INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
25/05/10 17:14:07.139 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (*(1) Scan ExistingRDD[UID#27,iso2#28,iso3#29,code3#30,FIPS#31,Admin2#32,Province_State#33,Country_Region#34,Lat#35,Long_#36,Combined_Key#37,Population#38]
 MapPartitionsRDD[21] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 17:14:07.140 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/05/10 17:14:07.143 dispatcher-event-loop-9 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 712914 bytes) 
25/05/10 17:14:07.144 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
25/05/10 17:14:07.168 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO CodeGenerator: Code generated in 11.569 ms
25/05/10 17:14:07.318 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO MemoryStore: Block rdd_21_0 stored as values in memory (estimated size 256.4 KiB, free 912.0 MiB)
25/05/10 17:14:07.319 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_21_0 in memory on 127.0.0.1:53507 (size: 256.4 KiB, free: 912.0 MiB)
25/05/10 17:14:07.339 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: 1 block locks were not released by task 0.0 in stage 6.0 (TID 6)
[rdd_21_0]
25/05/10 17:14:07.341 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1273 bytes result sent to driver
25/05/10 17:14:07.341 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 201 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 17:14:07.342 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/05/10 17:14:07.342 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 6 (collect at utils.scala:26) finished in 0.228 s
25/05/10 17:14:07.342 dag-scheduler-event-loop INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:14:07.342 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/05/10 17:14:07.371 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:14:07.372 dag-scheduler-event-loop INFO DAGScheduler: Got job 8 (collect at utils.scala:26) with 1 output partitions
25/05/10 17:14:07.372 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:26)
25/05/10 17:14:07.373 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:14:07.378 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:14:07.379 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[25] at collect at utils.scala:26), which has no missing parents
25/05/10 17:14:07.392 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 16.9 KiB, free 912.0 MiB)
25/05/10 17:14:07.394 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 912.0 MiB)
25/05/10 17:14:07.396 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:53507 (size: 7.2 KiB, free: 912.0 MiB)
25/05/10 17:14:07.397 dag-scheduler-event-loop INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585
25/05/10 17:14:07.398 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[25] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 17:14:07.398 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/05/10 17:14:07.408 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 712914 bytes) 
25/05/10 17:14:07.409 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
25/05/10 17:14:07.422 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO BlockManager: Found block rdd_21_0 locally
25/05/10 17:14:07.437 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO CodeGenerator: Code generated in 6.59 ms
25/05/10 17:14:07.489 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO CodeGenerator: Code generated in 37.2747 ms
25/05/10 17:14:07.503 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: 1 block locks were not released by task 0.0 in stage 7.0 (TID 7)
[rdd_21_0]
25/05/10 17:14:07.505 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2117 bytes result sent to driver
25/05/10 17:14:07.506 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 103 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 17:14:07.507 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/05/10 17:14:07.507 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 7 (collect at utils.scala:26) finished in 0.127 s
25/05/10 17:14:07.507 dag-scheduler-event-loop INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:14:07.507 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/05/10 17:14:07.508 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 8 finished: collect at utils.scala:26, took 0.136524 s
25/05/10 17:14:07.528 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 15.9222 ms
25/05/10 17:15:36.416 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.5875 ms
25/05/10 17:15:36.424 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:15:36.425 dag-scheduler-event-loop INFO DAGScheduler: Got job 9 (collect at utils.scala:26) with 1 output partitions
25/05/10 17:15:36.425 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:26)
25/05/10 17:15:36.425 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:15:36.426 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:15:36.427 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[27] at collect at utils.scala:26), which has no missing parents
25/05/10 17:15:36.429 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 10.2 KiB, free 912.0 MiB)
25/05/10 17:15:36.433 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 912.0 MiB)
25/05/10 17:15:36.435 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:53507 (size: 4.5 KiB, free: 912.0 MiB)
25/05/10 17:15:36.436 dag-scheduler-event-loop INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585
25/05/10 17:15:36.436 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[27] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 17:15:36.437 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/05/10 17:15:36.441 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 712914 bytes) 
25/05/10 17:15:36.443 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
25/05/10 17:15:36.465 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO CodeGenerator: Code generated in 14.8771 ms
25/05/10 17:15:36.475 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 267110 bytes result sent to driver
25/05/10 17:15:36.476 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 38 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 17:15:36.476 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/05/10 17:15:36.477 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 8 (collect at utils.scala:26) finished in 0.049 s
25/05/10 17:15:36.477 dag-scheduler-event-loop INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:15:36.477 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/05/10 17:15:36.477 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 9 finished: collect at utils.scala:26, took 0.052613 s
25/05/10 17:20:09.802 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 17:20:09.803 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 17:20:09.805 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 17:20:09.806 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 17:20:09.807 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 17:20:09.807 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 17:20:09.888 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:20:09.889 dag-scheduler-event-loop INFO DAGScheduler: Got job 10 (collect at utils.scala:26) with 2 output partitions
25/05/10 17:20:09.890 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:26)
25/05/10 17:20:09.890 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:20:09.890 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:20:09.892 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[30] at collect at utils.scala:26), which has no missing parents
25/05/10 17:20:09.896 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.5 KiB, free 912.0 MiB)
25/05/10 17:20:09.901 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.0 MiB)
25/05/10 17:20:09.902 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 912.0 MiB)
25/05/10 17:20:09.903 dag-scheduler-event-loop INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585
25/05/10 17:20:09.903 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 9 (MapPartitionsRDD[30] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1))
25/05/10 17:20:09.904 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 9.0 with 2 tasks resource profile 0
25/05/10 17:20:09.905 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9380 bytes) 
25/05/10 17:20:09.905 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 10) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 9380 bytes) 
25/05/10 17:20:09.907 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
25/05/10 17:20:09.908 Executor task launch worker for task 1.0 in stage 9.0 (TID 10) INFO Executor: Running task 1.0 in stage 9.0 (TID 10)
25/05/10 17:20:09.913 Executor task launch worker for task 1.0 in stage 9.0 (TID 10) INFO Executor: Finished task 1.0 in stage 9.0 (TID 10). 1393 bytes result sent to driver
25/05/10 17:20:09.914 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1393 bytes result sent to driver
25/05/10 17:20:09.914 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 10) in 9 ms on 127.0.0.1 (executor driver) (1/2)
25/05/10 17:20:09.916 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 11 ms on 127.0.0.1 (executor driver) (2/2)
25/05/10 17:20:09.916 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/05/10 17:20:09.917 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 9 (collect at utils.scala:26) finished in 0.024 s
25/05/10 17:20:09.917 dag-scheduler-event-loop INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:20:09.917 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/05/10 17:20:09.919 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 10 finished: collect at utils.scala:26, took 0.029767 s
25/05/10 17:20:21.327 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 17:20:21.327 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 17:20:21.331 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 17:20:21.332 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 17:20:21.335 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 17:20:21.335 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 17:20:21.432 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:20:21.433 dag-scheduler-event-loop INFO DAGScheduler: Got job 11 (collect at utils.scala:26) with 2 output partitions
25/05/10 17:20:21.434 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:26)
25/05/10 17:20:21.434 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:20:21.434 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:20:21.436 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[33] at collect at utils.scala:26), which has no missing parents
25/05/10 17:20:21.440 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.5 KiB, free 912.0 MiB)
25/05/10 17:20:21.442 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.0 MiB)
25/05/10 17:20:21.443 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 912.0 MiB)
25/05/10 17:20:21.444 dag-scheduler-event-loop INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585
25/05/10 17:20:21.444 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[33] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1))
25/05/10 17:20:21.444 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 10.0 with 2 tasks resource profile 0
25/05/10 17:20:21.445 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 11) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9380 bytes) 
25/05/10 17:20:21.445 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 12) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 9380 bytes) 
25/05/10 17:20:21.446 Executor task launch worker for task 0.0 in stage 10.0 (TID 11) INFO Executor: Running task 0.0 in stage 10.0 (TID 11)
25/05/10 17:20:21.446 Executor task launch worker for task 1.0 in stage 10.0 (TID 12) INFO Executor: Running task 1.0 in stage 10.0 (TID 12)
25/05/10 17:20:21.449 Executor task launch worker for task 1.0 in stage 10.0 (TID 12) INFO Executor: Finished task 1.0 in stage 10.0 (TID 12). 1350 bytes result sent to driver
25/05/10 17:20:21.449 Executor task launch worker for task 0.0 in stage 10.0 (TID 11) INFO Executor: Finished task 0.0 in stage 10.0 (TID 11). 1350 bytes result sent to driver
25/05/10 17:20:21.450 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 12) in 5 ms on 127.0.0.1 (executor driver) (1/2)
25/05/10 17:20:21.451 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 11) in 6 ms on 127.0.0.1 (executor driver) (2/2)
25/05/10 17:20:21.451 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/05/10 17:20:21.451 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 10 (collect at utils.scala:26) finished in 0.014 s
25/05/10 17:20:21.452 dag-scheduler-event-loop INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:20:21.452 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
25/05/10 17:20:21.453 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 11 finished: collect at utils.scala:26, took 0.021000 s
25/05/10 17:20:21.726 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:20:21.727 dag-scheduler-event-loop INFO DAGScheduler: Got job 12 (collect at utils.scala:26) with 1 output partitions
25/05/10 17:20:21.727 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:26)
25/05/10 17:20:21.727 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:20:21.727 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:20:21.728 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[36] at collect at utils.scala:26), which has no missing parents
25/05/10 17:20:21.731 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.9 KiB, free 912.0 MiB)
25/05/10 17:20:21.733 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 912.0 MiB)
25/05/10 17:20:21.735 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 912.0 MiB)
25/05/10 17:20:21.736 dag-scheduler-event-loop INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585
25/05/10 17:20:21.736 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[36] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 17:20:21.736 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/05/10 17:20:21.737 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 13) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 17:20:21.737 Executor task launch worker for task 0.0 in stage 11.0 (TID 13) INFO Executor: Running task 0.0 in stage 11.0 (TID 13)
25/05/10 17:20:21.741 Executor task launch worker for task 0.0 in stage 11.0 (TID 13) INFO Executor: Finished task 0.0 in stage 11.0 (TID 13). 1370 bytes result sent to driver
25/05/10 17:20:21.742 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 13) in 5 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 17:20:21.742 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/05/10 17:20:21.743 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 11 (collect at utils.scala:26) finished in 0.013 s
25/05/10 17:20:21.743 dag-scheduler-event-loop INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:20:21.743 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/05/10 17:20:21.743 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 12 finished: collect at utils.scala:26, took 0.017380 s
25/05/10 17:20:21.887 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:20:21.888 dag-scheduler-event-loop INFO DAGScheduler: Got job 13 (collect at utils.scala:26) with 1 output partitions
25/05/10 17:20:21.888 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:26)
25/05/10 17:20:21.888 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:20:21.889 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:20:21.890 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[38] at collect at utils.scala:26), which has no missing parents
25/05/10 17:20:21.892 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.9 KiB, free 912.0 MiB)
25/05/10 17:20:21.894 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 911.9 MiB)
25/05/10 17:20:21.894 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 912.0 MiB)
25/05/10 17:20:21.895 dag-scheduler-event-loop INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585
25/05/10 17:20:21.895 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[38] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 17:20:21.895 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
25/05/10 17:20:21.896 dispatcher-event-loop-9 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 14) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 17:20:21.897 Executor task launch worker for task 0.0 in stage 12.0 (TID 14) INFO Executor: Running task 0.0 in stage 12.0 (TID 14)
25/05/10 17:20:21.899 Executor task launch worker for task 0.0 in stage 12.0 (TID 14) INFO Executor: Finished task 0.0 in stage 12.0 (TID 14). 1327 bytes result sent to driver
25/05/10 17:20:21.900 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 14) in 4 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 17:20:21.900 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
25/05/10 17:20:21.900 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 12 (collect at utils.scala:26) finished in 0.009 s
25/05/10 17:20:21.900 dag-scheduler-event-loop INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:20:21.900 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
25/05/10 17:20:21.900 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 13 finished: collect at utils.scala:26, took 0.013455 s
25/05/10 17:20:22.028 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 17:20:22.029 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 17:20:22.032 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 17:20:22.033 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 17:20:22.035 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 17:20:22.035 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 17:20:30.873 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:20:30.874 dag-scheduler-event-loop INFO DAGScheduler: Got job 14 (collect at utils.scala:26) with 1 output partitions
25/05/10 17:20:30.874 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:26)
25/05/10 17:20:30.874 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:20:30.874 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:20:30.875 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[40] at collect at utils.scala:26), which has no missing parents
25/05/10 17:20:30.878 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 10.2 KiB, free 911.9 MiB)
25/05/10 17:20:30.880 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 911.9 MiB)
25/05/10 17:20:30.881 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:53507 (size: 4.5 KiB, free: 912.0 MiB)
25/05/10 17:20:30.881 dag-scheduler-event-loop INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585
25/05/10 17:20:30.882 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[40] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 17:20:30.882 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
25/05/10 17:20:30.885 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 15) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 712914 bytes) 
25/05/10 17:20:30.886 Executor task launch worker for task 0.0 in stage 13.0 (TID 15) INFO Executor: Running task 0.0 in stage 13.0 (TID 15)
25/05/10 17:20:30.910 Executor task launch worker for task 0.0 in stage 13.0 (TID 15) INFO Executor: Finished task 0.0 in stage 13.0 (TID 15). 267153 bytes result sent to driver
25/05/10 17:20:30.912 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 15) in 29 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 17:20:30.912 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
25/05/10 17:20:30.913 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 13 (collect at utils.scala:26) finished in 0.037 s
25/05/10 17:20:30.913 dag-scheduler-event-loop INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:20:30.913 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
25/05/10 17:20:30.914 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 14 finished: collect at utils.scala:26, took 0.040596 s
25/05/10 17:39:17.659 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 17:39:17.661 dag-scheduler-event-loop INFO DAGScheduler: Got job 15 (collect at utils.scala:26) with 1 output partitions
25/05/10 17:39:17.661 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:26)
25/05/10 17:39:17.661 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 17:39:17.661 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 17:39:17.663 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[42] at collect at utils.scala:26), which has no missing parents
25/05/10 17:39:17.666 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 10.8 KiB, free 911.9 MiB)
25/05/10 17:39:17.672 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 911.9 MiB)
25/05/10 17:39:17.673 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:53507 (size: 4.6 KiB, free: 912.0 MiB)
25/05/10 17:39:17.674 dag-scheduler-event-loop INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585
25/05/10 17:39:17.674 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[42] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 17:39:17.674 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
25/05/10 17:39:17.809 dispatcher-event-loop-6 WARN TaskSetManager: Stage 14 contains a task of very large size (29945 KiB). The maximum recommended task size is 1000 KiB.
25/05/10 17:39:17.810 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 16) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 30664575 bytes) 
25/05/10 17:39:17.811 Executor task launch worker for task 0.0 in stage 14.0 (TID 16) INFO Executor: Running task 0.0 in stage 14.0 (TID 16)
25/05/10 17:39:17.869 Executor task launch worker for task 0.0 in stage 14.0 (TID 16) INFO Executor: Finished task 0.0 in stage 14.0 (TID 16). 249058 bytes result sent to driver
25/05/10 17:39:17.871 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 16) in 195 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 17:39:17.871 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
25/05/10 17:39:17.871 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 14 (collect at utils.scala:26) finished in 0.207 s
25/05/10 17:39:17.871 dag-scheduler-event-loop INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 17:39:17.871 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
25/05/10 17:39:17.871 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 15 finished: collect at utils.scala:26, took 0.211053 s
25/05/10 17:41:51.473 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 912.0 MiB)
25/05/10 17:41:51.476 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 912.0 MiB)
25/05/10 17:41:51.478 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:53507 in memory (size: 4.5 KiB, free: 912.0 MiB)
25/05/10 17:41:51.480 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:53507 in memory (size: 7.2 KiB, free: 912.0 MiB)
25/05/10 17:41:51.484 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 912.0 MiB)
25/05/10 17:41:51.488 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:53507 in memory (size: 4.5 KiB, free: 912.0 MiB)
25/05/10 17:41:51.491 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:53507 in memory (size: 4.6 KiB, free: 912.0 MiB)
25/05/10 17:41:51.496 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 912.0 MiB)
25/05/10 17:41:51.499 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:53507 in memory (size: 6.2 KiB, free: 912.0 MiB)
25/05/10 18:17:37.706 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 18:17:37.708 dag-scheduler-event-loop INFO DAGScheduler: Got job 16 (collect at utils.scala:26) with 1 output partitions
25/05/10 18:17:37.708 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:26)
25/05/10 18:17:37.708 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 18:17:37.709 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 18:17:37.710 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[44] at collect at utils.scala:26), which has no missing parents
25/05/10 18:17:37.713 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 10.8 KiB, free 912.0 MiB)
25/05/10 18:17:37.717 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 912.0 MiB)
25/05/10 18:17:37.718 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:53507 (size: 4.6 KiB, free: 912.0 MiB)
25/05/10 18:17:37.718 dag-scheduler-event-loop INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1585
25/05/10 18:17:37.725 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[44] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 18:17:37.725 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
25/05/10 18:17:37.905 dispatcher-event-loop-1 WARN TaskSetManager: Stage 15 contains a task of very large size (29945 KiB). The maximum recommended task size is 1000 KiB.
25/05/10 18:17:37.905 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 17) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 30664575 bytes) 
25/05/10 18:17:37.906 Executor task launch worker for task 0.0 in stage 15.0 (TID 17) INFO Executor: Running task 0.0 in stage 15.0 (TID 17)
25/05/10 18:17:38.065 Executor task launch worker for task 0.0 in stage 15.0 (TID 17) INFO Executor: Finished task 0.0 in stage 15.0 (TID 17). 266044 bytes result sent to driver
25/05/10 18:17:38.066 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 17) in 339 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 18:17:38.066 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
25/05/10 18:17:38.067 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 15 (collect at utils.scala:26) finished in 0.356 s
25/05/10 18:17:38.067 dag-scheduler-event-loop INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 18:17:38.067 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
25/05/10 18:17:38.067 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 16 finished: collect at utils.scala:26, took 0.359999 s
25/05/10 18:41:51.686 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:53507 in memory (size: 4.6 KiB, free: 912.0 MiB)
25/05/10 20:41:17.778 dag-scheduler-event-loop INFO DAGScheduler: Got job 17 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:41:17.779 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:26)
25/05/10 20:41:17.779 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:41:17.781 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:41:17.783 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 16 (*(1) Scan ExistingRDD[UID#837,iso2#838,iso3#839,code3#840,FIPS#841,Admin2#842,Province_State#843,Country_Region#844,Lat#845,Long_#846,Combined_Key#847,Population#848]
 MapPartitionsRDD[47] at collect at utils.scala:26), which has no missing parents
25/05/10 20:41:17.818 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 13.8 KiB, free 912.0 MiB)
25/05/10 20:41:17.823 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 912.0 MiB)
25/05/10 20:41:17.823 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:53507 (size: 6.2 KiB, free: 912.0 MiB)
25/05/10 20:41:17.824 dag-scheduler-event-loop INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1585
25/05/10 20:41:17.831 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (*(1) Scan ExistingRDD[UID#837,iso2#838,iso3#839,code3#840,FIPS#841,Admin2#842,Province_State#843,Country_Region#844,Lat#845,Long_#846,Combined_Key#847,Population#848]
 MapPartitionsRDD[47] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:41:17.832 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
25/05/10 20:41:17.845 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 18) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 712914 bytes) 
25/05/10 20:41:17.850 Executor task launch worker for task 0.0 in stage 16.0 (TID 18) INFO Executor: Running task 0.0 in stage 16.0 (TID 18)
25/05/10 20:41:17.923 Executor task launch worker for task 0.0 in stage 16.0 (TID 18) INFO MemoryStore: Block rdd_47_0 stored as values in memory (estimated size 256.4 KiB, free 911.8 MiB)
25/05/10 20:41:17.923 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_47_0 in memory on 127.0.0.1:53507 (size: 256.4 KiB, free: 911.8 MiB)
25/05/10 20:41:17.924 Executor task launch worker for task 0.0 in stage 16.0 (TID 18) INFO Executor: 1 block locks were not released by task 0.0 in stage 16.0 (TID 18)
[rdd_47_0]
25/05/10 20:41:17.929 Executor task launch worker for task 0.0 in stage 16.0 (TID 18) INFO Executor: Finished task 0.0 in stage 16.0 (TID 18). 1316 bytes result sent to driver
25/05/10 20:41:17.930 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 18) in 97 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:41:17.931 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
25/05/10 20:41:17.931 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 16 (collect at utils.scala:26) finished in 0.147 s
25/05/10 20:41:17.932 dag-scheduler-event-loop INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:41:17.932 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
25/05/10 20:41:17.953 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:41:17.954 dag-scheduler-event-loop INFO DAGScheduler: Got job 18 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:41:17.954 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:26)
25/05/10 20:41:17.954 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:41:17.956 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:41:17.957 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[51] at collect at utils.scala:26), which has no missing parents
25/05/10 20:41:17.971 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 17.0 KiB, free 911.8 MiB)
25/05/10 20:41:17.975 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 911.8 MiB)
25/05/10 20:41:17.977 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:53507 (size: 7.3 KiB, free: 911.8 MiB)
25/05/10 20:41:17.977 dag-scheduler-event-loop INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1585
25/05/10 20:41:17.978 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[51] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:41:17.978 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
25/05/10 20:41:17.985 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 19) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 712914 bytes) 
25/05/10 20:41:17.986 Executor task launch worker for task 0.0 in stage 17.0 (TID 19) INFO Executor: Running task 0.0 in stage 17.0 (TID 19)
25/05/10 20:41:17.993 Executor task launch worker for task 0.0 in stage 17.0 (TID 19) INFO BlockManager: Found block rdd_47_0 locally
25/05/10 20:41:18.009 Executor task launch worker for task 0.0 in stage 17.0 (TID 19) INFO Executor: 1 block locks were not released by task 0.0 in stage 17.0 (TID 19)
[rdd_47_0]
25/05/10 20:41:18.014 Executor task launch worker for task 0.0 in stage 17.0 (TID 19) INFO Executor: Finished task 0.0 in stage 17.0 (TID 19). 65545 bytes result sent to driver
25/05/10 20:41:18.015 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 19) in 36 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:41:18.016 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
25/05/10 20:41:18.016 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 17 (collect at utils.scala:26) finished in 0.059 s
25/05/10 20:41:18.016 dag-scheduler-event-loop INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:41:18.016 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
25/05/10 20:41:18.016 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 18 finished: collect at utils.scala:26, took 0.063842 s
25/05/10 20:41:51.312 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:53507 in memory (size: 7.3 KiB, free: 911.8 MiB)
25/05/10 20:41:51.315 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:53507 in memory (size: 6.2 KiB, free: 911.8 MiB)
25/05/10 20:42:16.783 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 20:42:16.783 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 20:42:16.794 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 20:42:16.795 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 20:42:16.799 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 20:42:16.799 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 20:42:16.898 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:42:16.899 dag-scheduler-event-loop INFO DAGScheduler: Got job 19 (collect at utils.scala:26) with 2 output partitions
25/05/10 20:42:16.899 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:26)
25/05/10 20:42:16.899 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:42:16.899 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:42:16.900 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[54] at collect at utils.scala:26), which has no missing parents
25/05/10 20:42:16.902 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 7.5 KiB, free 911.8 MiB)
25/05/10 20:42:16.905 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 911.8 MiB)
25/05/10 20:42:16.905 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.8 MiB)
25/05/10 20:42:16.906 dag-scheduler-event-loop INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1585
25/05/10 20:42:16.907 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 18 (MapPartitionsRDD[54] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1))
25/05/10 20:42:16.907 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 18.0 with 2 tasks resource profile 0
25/05/10 20:42:16.908 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 20) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9380 bytes) 
25/05/10 20:42:16.909 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 21) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 9380 bytes) 
25/05/10 20:42:16.910 Executor task launch worker for task 0.0 in stage 18.0 (TID 20) INFO Executor: Running task 0.0 in stage 18.0 (TID 20)
25/05/10 20:42:16.911 Executor task launch worker for task 1.0 in stage 18.0 (TID 21) INFO Executor: Running task 1.0 in stage 18.0 (TID 21)
25/05/10 20:42:16.915 Executor task launch worker for task 0.0 in stage 18.0 (TID 20) INFO Executor: Finished task 0.0 in stage 18.0 (TID 20). 1393 bytes result sent to driver
25/05/10 20:42:16.919 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 20) in 11 ms on 127.0.0.1 (executor driver) (1/2)
25/05/10 20:42:16.921 Executor task launch worker for task 1.0 in stage 18.0 (TID 21) INFO Executor: Finished task 1.0 in stage 18.0 (TID 21). 1393 bytes result sent to driver
25/05/10 20:42:16.923 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 21) in 14 ms on 127.0.0.1 (executor driver) (2/2)
25/05/10 20:42:16.923 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
25/05/10 20:42:16.923 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 18 (collect at utils.scala:26) finished in 0.022 s
25/05/10 20:42:16.923 dag-scheduler-event-loop INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:42:16.923 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
25/05/10 20:42:16.925 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 19 finished: collect at utils.scala:26, took 0.026718 s
25/05/10 20:42:17.138 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 12.9249 ms
25/05/10 20:42:17.147 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:42:17.148 dag-scheduler-event-loop INFO DAGScheduler: Got job 20 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:42:17.148 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:26)
25/05/10 20:42:17.148 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:42:17.148 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:42:17.149 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[57] at collect at utils.scala:26), which has no missing parents
25/05/10 20:42:17.151 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 7.6 KiB, free 911.8 MiB)
25/05/10 20:42:17.154 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 911.8 MiB)
25/05/10 20:42:17.155 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.8 MiB)
25/05/10 20:42:17.155 dag-scheduler-event-loop INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1585
25/05/10 20:42:17.157 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[57] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:42:17.157 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
25/05/10 20:42:17.160 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 22) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:42:17.160 Executor task launch worker for task 0.0 in stage 19.0 (TID 22) INFO Executor: Running task 0.0 in stage 19.0 (TID 22)
25/05/10 20:42:17.171 Executor task launch worker for task 0.0 in stage 19.0 (TID 22) INFO CodeGenerator: Code generated in 8.5504 ms
25/05/10 20:42:17.175 Executor task launch worker for task 0.0 in stage 19.0 (TID 22) INFO Executor: Finished task 0.0 in stage 19.0 (TID 22). 1413 bytes result sent to driver
25/05/10 20:42:17.176 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 22) in 18 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:42:17.177 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
25/05/10 20:42:17.177 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 19 (collect at utils.scala:26) finished in 0.027 s
25/05/10 20:42:17.177 dag-scheduler-event-loop INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:42:17.177 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
25/05/10 20:42:17.177 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 20 finished: collect at utils.scala:26, took 0.029877 s
25/05/10 20:42:17.186 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.7675 ms
25/05/10 20:42:17.304 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:42:17.305 dag-scheduler-event-loop INFO DAGScheduler: Got job 21 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:42:17.305 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 20 (collect at utils.scala:26)
25/05/10 20:42:17.305 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:42:17.305 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:42:17.307 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[59] at collect at utils.scala:26), which has no missing parents
25/05/10 20:42:17.308 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.6 KiB, free 911.8 MiB)
25/05/10 20:42:17.312 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 911.8 MiB)
25/05/10 20:42:17.313 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.8 MiB)
25/05/10 20:42:17.314 dag-scheduler-event-loop INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1585
25/05/10 20:42:17.314 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[59] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:42:17.314 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
25/05/10 20:42:17.315 dispatcher-event-loop-10 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 23) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:42:17.316 Executor task launch worker for task 0.0 in stage 20.0 (TID 23) INFO Executor: Running task 0.0 in stage 20.0 (TID 23)
25/05/10 20:42:17.321 Executor task launch worker for task 0.0 in stage 20.0 (TID 23) INFO Executor: Finished task 0.0 in stage 20.0 (TID 23). 1370 bytes result sent to driver
25/05/10 20:42:17.322 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 23) in 7 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:42:17.322 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
25/05/10 20:42:17.322 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 20 (collect at utils.scala:26) finished in 0.015 s
25/05/10 20:42:17.322 dag-scheduler-event-loop INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:42:17.322 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
25/05/10 20:42:17.322 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 21 finished: collect at utils.scala:26, took 0.018539 s
25/05/10 20:42:17.449 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 20:42:17.450 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 20:42:17.453 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 20:42:17.453 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 20:42:17.454 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 20:42:17.455 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 20:42:46.979 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 11.2476 ms
25/05/10 20:42:46.989 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:42:46.990 dag-scheduler-event-loop INFO DAGScheduler: Got job 22 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:42:46.990 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:26)
25/05/10 20:42:46.990 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:42:46.990 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:42:46.991 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[61] at collect at utils.scala:26), which has no missing parents
25/05/10 20:42:46.993 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 9.1 KiB, free 911.8 MiB)
25/05/10 20:42:46.997 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 911.8 MiB)
25/05/10 20:42:46.998 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:53507 (size: 4.3 KiB, free: 911.8 MiB)
25/05/10 20:42:46.998 dag-scheduler-event-loop INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1585
25/05/10 20:42:46.998 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[61] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:42:46.998 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
25/05/10 20:42:47.002 dispatcher-event-loop-8 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 24) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 464229 bytes) 
25/05/10 20:42:47.002 Executor task launch worker for task 0.0 in stage 21.0 (TID 24) INFO Executor: Running task 0.0 in stage 21.0 (TID 24)
25/05/10 20:42:47.028 Executor task launch worker for task 0.0 in stage 21.0 (TID 24) INFO CodeGenerator: Code generated in 20.3178 ms
25/05/10 20:42:47.045 Executor task launch worker for task 0.0 in stage 21.0 (TID 24) INFO Executor: Finished task 0.0 in stage 21.0 (TID 24). 170278 bytes result sent to driver
25/05/10 20:42:47.047 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 24) in 48 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:42:47.047 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
25/05/10 20:42:47.048 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 21 (collect at utils.scala:26) finished in 0.056 s
25/05/10 20:42:47.048 dag-scheduler-event-loop INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:42:47.048 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
25/05/10 20:42:47.048 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 22 finished: collect at utils.scala:26, took 0.059716 s
25/05/10 20:42:47.085 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 31.5558 ms
25/05/10 20:44:22.399 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:44:22.401 dag-scheduler-event-loop INFO DAGScheduler: Got job 23 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:44:22.401 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:26)
25/05/10 20:44:22.401 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:44:22.401 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:44:22.402 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[63] at collect at utils.scala:26), which has no missing parents
25/05/10 20:44:22.403 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 9.1 KiB, free 911.7 MiB)
25/05/10 20:44:22.407 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 911.7 MiB)
25/05/10 20:44:22.408 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:53507 (size: 4.3 KiB, free: 911.8 MiB)
25/05/10 20:44:22.408 dag-scheduler-event-loop INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1585
25/05/10 20:44:22.409 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[63] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:44:22.409 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
25/05/10 20:44:22.411 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 25) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 464229 bytes) 
25/05/10 20:44:22.413 Executor task launch worker for task 0.0 in stage 22.0 (TID 25) INFO Executor: Running task 0.0 in stage 22.0 (TID 25)
25/05/10 20:44:22.425 Executor task launch worker for task 0.0 in stage 22.0 (TID 25) INFO Executor: Finished task 0.0 in stage 22.0 (TID 25). 170278 bytes result sent to driver
25/05/10 20:44:22.426 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 25) in 17 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:44:22.427 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
25/05/10 20:44:22.427 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 22 (collect at utils.scala:26) finished in 0.024 s
25/05/10 20:44:22.427 dag-scheduler-event-loop INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:44:22.427 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
25/05/10 20:44:22.428 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 23 finished: collect at utils.scala:26, took 0.027335 s
25/05/10 20:44:27.054 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 20:44:27.054 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 20:44:27.056 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 20:44:27.056 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 20:44:27.057 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 20:44:27.057 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 20:44:27.140 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:44:27.141 dag-scheduler-event-loop INFO DAGScheduler: Got job 24 (collect at utils.scala:26) with 3 output partitions
25/05/10 20:44:27.141 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:26)
25/05/10 20:44:27.141 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:44:27.141 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:44:27.142 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[66] at collect at utils.scala:26), which has no missing parents
25/05/10 20:44:27.144 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 7.5 KiB, free 911.7 MiB)
25/05/10 20:44:27.150 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 911.7 MiB)
25/05/10 20:44:27.151 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.8 MiB)
25/05/10 20:44:27.151 dag-scheduler-event-loop INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1585
25/05/10 20:44:27.152 dag-scheduler-event-loop INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 23 (MapPartitionsRDD[66] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2))
25/05/10 20:44:27.152 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 23.0 with 3 tasks resource profile 0
25/05/10 20:44:27.153 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 26) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9380 bytes) 
25/05/10 20:44:27.153 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 27) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 9380 bytes) 
25/05/10 20:44:27.154 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 28) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 9380 bytes) 
25/05/10 20:44:27.155 Executor task launch worker for task 0.0 in stage 23.0 (TID 26) INFO Executor: Running task 0.0 in stage 23.0 (TID 26)
25/05/10 20:44:27.156 Executor task launch worker for task 1.0 in stage 23.0 (TID 27) INFO Executor: Running task 1.0 in stage 23.0 (TID 27)
25/05/10 20:44:27.156 Executor task launch worker for task 2.0 in stage 23.0 (TID 28) INFO Executor: Running task 2.0 in stage 23.0 (TID 28)
25/05/10 20:44:27.164 Executor task launch worker for task 2.0 in stage 23.0 (TID 28) INFO Executor: Finished task 2.0 in stage 23.0 (TID 28). 1436 bytes result sent to driver
25/05/10 20:44:27.164 Executor task launch worker for task 0.0 in stage 23.0 (TID 26) INFO Executor: Finished task 0.0 in stage 23.0 (TID 26). 1479 bytes result sent to driver
25/05/10 20:44:27.166 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 28) in 12 ms on 127.0.0.1 (executor driver) (1/3)
25/05/10 20:44:27.166 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 26) in 13 ms on 127.0.0.1 (executor driver) (2/3)
25/05/10 20:44:27.167 Executor task launch worker for task 1.0 in stage 23.0 (TID 27) INFO Executor: Finished task 1.0 in stage 23.0 (TID 27). 1436 bytes result sent to driver
25/05/10 20:44:27.168 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 27) in 15 ms on 127.0.0.1 (executor driver) (3/3)
25/05/10 20:44:27.168 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
25/05/10 20:44:27.169 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 23 (collect at utils.scala:26) finished in 0.026 s
25/05/10 20:44:27.169 dag-scheduler-event-loop INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:44:27.170 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
25/05/10 20:44:27.170 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 24 finished: collect at utils.scala:26, took 0.029332 s
25/05/10 20:44:27.373 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:44:27.374 dag-scheduler-event-loop INFO DAGScheduler: Got job 25 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:44:27.374 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:26)
25/05/10 20:44:27.374 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:44:27.374 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:44:27.375 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[69] at collect at utils.scala:26), which has no missing parents
25/05/10 20:44:27.376 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 7.7 KiB, free 911.7 MiB)
25/05/10 20:44:27.381 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 911.7 MiB)
25/05/10 20:44:27.382 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.8 MiB)
25/05/10 20:44:27.382 dag-scheduler-event-loop INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1585
25/05/10 20:44:27.382 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[69] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:44:27.382 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
25/05/10 20:44:27.383 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 29) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:44:27.383 Executor task launch worker for task 0.0 in stage 24.0 (TID 29) INFO Executor: Running task 0.0 in stage 24.0 (TID 29)
25/05/10 20:44:27.389 Executor task launch worker for task 0.0 in stage 24.0 (TID 29) INFO Executor: Finished task 0.0 in stage 24.0 (TID 29). 1413 bytes result sent to driver
25/05/10 20:44:27.390 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 29) in 7 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:44:27.390 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
25/05/10 20:44:27.390 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 24 (collect at utils.scala:26) finished in 0.014 s
25/05/10 20:44:27.390 dag-scheduler-event-loop INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:44:27.390 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
25/05/10 20:44:27.391 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 25 finished: collect at utils.scala:26, took 0.016837 s
25/05/10 20:44:27.520 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:44:27.522 dag-scheduler-event-loop INFO DAGScheduler: Got job 26 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:44:27.522 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:26)
25/05/10 20:44:27.522 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:44:27.522 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:44:27.522 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[71] at collect at utils.scala:26), which has no missing parents
25/05/10 20:44:27.524 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 7.7 KiB, free 911.7 MiB)
25/05/10 20:44:27.530 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 911.7 MiB)
25/05/10 20:44:27.531 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.8 MiB)
25/05/10 20:44:27.531 dag-scheduler-event-loop INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1585
25/05/10 20:44:27.532 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[71] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:44:27.532 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
25/05/10 20:44:27.533 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 30) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:44:27.533 Executor task launch worker for task 0.0 in stage 25.0 (TID 30) INFO Executor: Running task 0.0 in stage 25.0 (TID 30)
25/05/10 20:44:27.537 Executor task launch worker for task 0.0 in stage 25.0 (TID 30) INFO Executor: Finished task 0.0 in stage 25.0 (TID 30). 1370 bytes result sent to driver
25/05/10 20:44:27.537 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 30) in 5 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:44:27.538 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
25/05/10 20:44:27.538 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 25 (collect at utils.scala:26) finished in 0.015 s
25/05/10 20:44:27.538 dag-scheduler-event-loop INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:44:27.538 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
25/05/10 20:44:27.538 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 26 finished: collect at utils.scala:26, took 0.017361 s
25/05/10 20:44:28.508 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.4621 ms
25/05/10 20:44:28.520 dag-scheduler-event-loop INFO DAGScheduler: Got job 27 (collect at StringIndexer.scala:204) with 1 output partitions
25/05/10 20:44:28.520 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 26 (collect at StringIndexer.scala:204)
25/05/10 20:44:28.520 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:44:28.521 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:44:28.521 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 26 (*(1) Scan ExistingRDD[CountryRegion#1682,Population#1683,Date#1684,Days#1685,Total_Cases#1686,Rate_of_Cases#1687,Log_Cases#1688]
 MapPartitionsRDD[74] at collect at StringIndexer.scala:204), which has no missing parents
25/05/10 20:44:28.528 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 12.2 KiB, free 911.7 MiB)
25/05/10 20:44:28.537 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 911.7 MiB)
25/05/10 20:44:28.539 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:53507 (size: 5.8 KiB, free: 911.8 MiB)
25/05/10 20:44:28.540 dag-scheduler-event-loop INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1585
25/05/10 20:44:28.541 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (*(1) Scan ExistingRDD[CountryRegion#1682,Population#1683,Date#1684,Days#1685,Total_Cases#1686,Rate_of_Cases#1687,Log_Cases#1688]
 MapPartitionsRDD[74] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
25/05/10 20:44:28.541 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0
25/05/10 20:44:28.546 dispatcher-event-loop-9 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 31) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509949 bytes) 
25/05/10 20:44:28.546 Executor task launch worker for task 0.0 in stage 26.0 (TID 31) INFO Executor: Running task 0.0 in stage 26.0 (TID 31)
25/05/10 20:44:28.572 Executor task launch worker for task 0.0 in stage 26.0 (TID 31) INFO CodeGenerator: Code generated in 17.472 ms
25/05/10 20:44:28.623 Executor task launch worker for task 0.0 in stage 26.0 (TID 31) INFO MemoryStore: Block rdd_74_0 stored as values in memory (estimated size 185.1 KiB, free 911.5 MiB)
25/05/10 20:44:28.625 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_74_0 in memory on 127.0.0.1:53507 (size: 185.1 KiB, free: 911.6 MiB)
25/05/10 20:44:28.626 Executor task launch worker for task 0.0 in stage 26.0 (TID 31) INFO Executor: 1 block locks were not released by task 0.0 in stage 26.0 (TID 31)
[rdd_74_0]
25/05/10 20:44:28.630 Executor task launch worker for task 0.0 in stage 26.0 (TID 31) INFO Executor: Finished task 0.0 in stage 26.0 (TID 31). 1316 bytes result sent to driver
25/05/10 20:44:28.632 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 31) in 90 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:44:28.632 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
25/05/10 20:44:28.633 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 26 (collect at StringIndexer.scala:204) finished in 0.110 s
25/05/10 20:44:28.633 dag-scheduler-event-loop INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:44:28.633 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
25/05/10 20:44:28.694 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 79 (collect at StringIndexer.scala:204) as input to shuffle 0
25/05/10 20:44:28.702 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 28 (collect at StringIndexer.scala:204) with 1 output partitions
25/05/10 20:44:28.702 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 27 (collect at StringIndexer.scala:204)
25/05/10 20:44:28.703 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:44:28.704 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:44:28.707 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[79] at collect at StringIndexer.scala:204), which has no missing parents
25/05/10 20:44:28.762 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 30.4 KiB, free 911.5 MiB)
25/05/10 20:44:28.767 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 13.6 KiB, free 911.5 MiB)
25/05/10 20:44:28.767 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:53507 (size: 13.6 KiB, free: 911.6 MiB)
25/05/10 20:44:28.768 dag-scheduler-event-loop INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1585
25/05/10 20:44:28.769 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[79] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
25/05/10 20:44:28.769 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
25/05/10 20:44:28.773 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 32) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509938 bytes) 
25/05/10 20:44:28.774 Executor task launch worker for task 0.0 in stage 27.0 (TID 32) INFO Executor: Running task 0.0 in stage 27.0 (TID 32)
25/05/10 20:44:28.811 Executor task launch worker for task 0.0 in stage 27.0 (TID 32) INFO BlockManager: Found block rdd_74_0 locally
25/05/10 20:44:28.828 Executor task launch worker for task 0.0 in stage 27.0 (TID 32) INFO CodeGenerator: Code generated in 16.9505 ms
25/05/10 20:44:28.864 Executor task launch worker for task 0.0 in stage 27.0 (TID 32) INFO CodeGenerator: Code generated in 4.683 ms
25/05/10 20:44:28.876 Executor task launch worker for task 0.0 in stage 27.0 (TID 32) INFO CodeGenerator: Code generated in 4.8051 ms
25/05/10 20:44:28.884 Executor task launch worker for task 0.0 in stage 27.0 (TID 32) INFO CodeGenerator: Code generated in 4.8137 ms
25/05/10 20:44:28.898 Executor task launch worker for task 0.0 in stage 27.0 (TID 32) INFO CodeGenerator: Code generated in 5.3448 ms
25/05/10 20:44:28.979 Executor task launch worker for task 0.0 in stage 27.0 (TID 32) INFO CodeGenerator: Code generated in 17.1188 ms
25/05/10 20:44:29.374 Executor task launch worker for task 0.0 in stage 27.0 (TID 32) INFO Executor: Finished task 0.0 in stage 27.0 (TID 32). 2312 bytes result sent to driver
25/05/10 20:44:29.375 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 32) in 605 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:44:29.375 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
25/05/10 20:44:29.376 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 27 (collect at StringIndexer.scala:204) finished in 0.665 s
25/05/10 20:44:29.377 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
25/05/10 20:44:29.377 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
25/05/10 20:44:29.378 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
25/05/10 20:44:29.378 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
25/05/10 20:44:29.435 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
25/05/10 20:44:29.436 dag-scheduler-event-loop INFO DAGScheduler: Got job 29 (collect at StringIndexer.scala:204) with 1 output partitions
25/05/10 20:44:29.436 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 29 (collect at StringIndexer.scala:204)
25/05/10 20:44:29.436 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
25/05/10 20:44:29.436 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:44:29.438 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[82] at collect at StringIndexer.scala:204), which has no missing parents
25/05/10 20:44:29.449 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 35.7 KiB, free 911.4 MiB)
25/05/10 20:44:29.454 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 911.4 MiB)
25/05/10 20:44:29.456 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:53507 (size: 16.3 KiB, free: 911.6 MiB)
25/05/10 20:44:29.456 dag-scheduler-event-loop INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1585
25/05/10 20:44:29.457 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[82] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
25/05/10 20:44:29.457 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
25/05/10 20:44:29.462 dispatcher-event-loop-8 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 33) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 9176 bytes) 
25/05/10 20:44:29.463 Executor task launch worker for task 0.0 in stage 29.0 (TID 33) INFO Executor: Running task 0.0 in stage 29.0 (TID 33)
25/05/10 20:44:29.517 Executor task launch worker for task 0.0 in stage 29.0 (TID 33) INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/10 20:44:29.519 Executor task launch worker for task 0.0 in stage 29.0 (TID 33) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
25/05/10 20:44:29.555 Executor task launch worker for task 0.0 in stage 29.0 (TID 33) INFO CodeGenerator: Code generated in 10.9772 ms
25/05/10 20:44:29.635 Executor task launch worker for task 0.0 in stage 29.0 (TID 33) INFO Executor: Finished task 0.0 in stage 29.0 (TID 33). 4985 bytes result sent to driver
25/05/10 20:44:29.636 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 33) in 176 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:44:29.637 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
25/05/10 20:44:29.637 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 29 (collect at StringIndexer.scala:204) finished in 0.193 s
25/05/10 20:44:29.638 dag-scheduler-event-loop INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:44:29.638 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
25/05/10 20:44:29.638 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 29 finished: collect at StringIndexer.scala:204, took 0.203242 s
25/05/10 20:44:29.650 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.6512 ms
25/05/10 20:44:29.779 nioEventLoopGroup-2-2 INFO Instrumentation: [ec6b03a5] training finished
25/05/10 20:44:29.887 nioEventLoopGroup-2-2 INFO Instrumentation: [4403d982] training finished
25/05/10 20:44:29.899 nioEventLoopGroup-2-2 INFO Instrumentation: [669e52ca] Stage class: LinearRegression
25/05/10 20:44:29.900 nioEventLoopGroup-2-2 INFO Instrumentation: [669e52ca] Stage uid: linear_regression__bda410d6_d4e3_4131_96c8_4dd8c0ebf4f6
25/05/10 20:44:30.082 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 35.8791 ms
25/05/10 20:44:30.159 nioEventLoopGroup-2-2 INFO Instrumentation: [669e52ca] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
25/05/10 20:44:30.186 nioEventLoopGroup-2-2 INFO Instrumentation: [669e52ca] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
25/05/10 20:44:30.197 nioEventLoopGroup-2-2 INFO Instrumentation: [669e52ca] {"numFeatures":6}
25/05/10 20:44:30.395 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 44.0333 ms
25/05/10 20:44:30.436 nioEventLoopGroup-2-2 WARN Instrumentation: [669e52ca] regParam is zero, which might cause numerical instability and overfitting.
25/05/10 20:44:30.467 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
25/05/10 20:44:30.468 dag-scheduler-event-loop INFO DAGScheduler: Got job 30 (treeAggregate at WeightedLeastSquares.scala:107) with 1 output partitions
25/05/10 20:44:30.468 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 30 (treeAggregate at WeightedLeastSquares.scala:107)
25/05/10 20:44:30.468 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:44:30.472 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:44:30.473 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[98] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
25/05/10 20:44:30.541 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 80.1 KiB, free 911.3 MiB)
25/05/10 20:44:30.547 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 911.3 MiB)
25/05/10 20:44:30.548 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:53507 (size: 31.1 KiB, free: 911.5 MiB)
25/05/10 20:44:30.549 dag-scheduler-event-loop INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1585
25/05/10 20:44:30.549 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[98] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0))
25/05/10 20:44:30.549 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
25/05/10 20:44:30.554 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 34) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509949 bytes) 
25/05/10 20:44:30.555 Executor task launch worker for task 0.0 in stage 30.0 (TID 34) INFO Executor: Running task 0.0 in stage 30.0 (TID 34)
25/05/10 20:44:30.701 Executor task launch worker for task 0.0 in stage 30.0 (TID 34) INFO BlockManager: Found block rdd_74_0 locally
25/05/10 20:44:30.717 Executor task launch worker for task 0.0 in stage 30.0 (TID 34) INFO CodeGenerator: Code generated in 14.4288 ms
25/05/10 20:44:30.784 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.5 MiB)
25/05/10 20:44:30.794 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.5 MiB)
25/05/10 20:44:30.796 Executor task launch worker for task 0.0 in stage 30.0 (TID 34) INFO CodeGenerator: Code generated in 75.1317 ms
25/05/10 20:44:30.799 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.5 MiB)
25/05/10 20:44:30.803 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:53507 in memory (size: 4.3 KiB, free: 911.5 MiB)
25/05/10 20:44:30.807 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.5 MiB)
25/05/10 20:44:30.811 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:53507 in memory (size: 5.8 KiB, free: 911.5 MiB)
25/05/10 20:44:30.813 Executor task launch worker for task 0.0 in stage 30.0 (TID 34) INFO CodeGenerator: Code generated in 9.7319 ms
25/05/10 20:44:30.815 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.6 MiB)
25/05/10 20:44:30.820 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:53507 in memory (size: 4.3 KiB, free: 911.6 MiB)
25/05/10 20:44:30.821 Executor task launch worker for task 0.0 in stage 30.0 (TID 34) INFO CodeGenerator: Code generated in 5.2558 ms
25/05/10 20:44:30.825 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.6 MiB)
25/05/10 20:44:30.829 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:53507 in memory (size: 16.3 KiB, free: 911.6 MiB)
25/05/10 20:44:30.832 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:53507 in memory (size: 13.6 KiB, free: 911.6 MiB)
25/05/10 20:44:30.837 Executor task launch worker for task 0.0 in stage 30.0 (TID 34) INFO CodeGenerator: Code generated in 7.6854 ms
25/05/10 20:44:30.857 Executor task launch worker for task 0.0 in stage 30.0 (TID 34) ERROR Executor: Exception in task 0.0 in stage 30.0 (TID 34)
java.lang.RuntimeException: Labels MUST NOT be Null or NaN
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)
	at scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:260)
	at scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:260)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1431)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$4(RDD.scala:1264)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$6(RDD.scala:1265)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
25/05/10 20:44:30.870 task-result-getter-2 WARN TaskSetManager: Lost task 0.0 in stage 30.0 (TID 34) (127.0.0.1 executor driver): java.lang.RuntimeException: Labels MUST NOT be Null or NaN
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)
	at scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:260)
	at scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:260)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1431)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$4(RDD.scala:1264)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$6(RDD.scala:1265)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

25/05/10 20:44:30.871 task-result-getter-2 ERROR TaskSetManager: Task 0 in stage 30.0 failed 1 times; aborting job
25/05/10 20:44:30.873 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
25/05/10 20:44:30.875 dag-scheduler-event-loop INFO TaskSchedulerImpl: Cancelling stage 30
25/05/10 20:44:30.875 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage cancelled: Job aborted due to stage failure: Task 0 in stage 30.0 failed 1 times, most recent failure: Lost task 0.0 in stage 30.0 (TID 34) (127.0.0.1 executor driver): java.lang.RuntimeException: Labels MUST NOT be Null or NaN
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)
	at scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:260)
	at scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:260)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1431)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$4(RDD.scala:1264)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$6(RDD.scala:1265)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

Driver stacktrace:
25/05/10 20:44:30.875 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 30 (treeAggregate at WeightedLeastSquares.scala:107) failed in 0.401 s due to Job aborted due to stage failure: Task 0 in stage 30.0 failed 1 times, most recent failure: Lost task 0.0 in stage 30.0 (TID 34) (127.0.0.1 executor driver): java.lang.RuntimeException: Labels MUST NOT be Null or NaN
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)
	at scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:260)
	at scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:260)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1431)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$4(RDD.scala:1264)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$6(RDD.scala:1265)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

Driver stacktrace:
25/05/10 20:44:30.877 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 30 failed: treeAggregate at WeightedLeastSquares.scala:107, took 0.409952 s
25/05/10 20:44:30.878 nioEventLoopGroup-2-2 ERROR Instrumentation: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 30.0 failed 1 times, most recent failure: Lost task 0.0 in stage 30.0 (TID 34) (127.0.0.1 executor driver): java.lang.RuntimeException: Labels MUST NOT be Null or NaN
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)
	at scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:260)
	at scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:260)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1431)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$4(RDD.scala:1264)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$6(RDD.scala:1265)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2488)
	at org.apache.spark.rdd.RDD.$anonfun$fold$1(RDD.scala:1202)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:410)
	at org.apache.spark.rdd.RDD.fold(RDD.scala:1196)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$2(RDD.scala:1289)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:410)
	at org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1256)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$1(RDD.scala:1242)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:410)
	at org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1242)
	at org.apache.spark.ml.optim.WeightedLeastSquares.fit(WeightedLeastSquares.scala:107)
	at org.apache.spark.ml.regression.LinearRegression.trainWithNormal(LinearRegression.scala:456)
	at org.apache.spark.ml.regression.LinearRegression.$anonfun$train$1(LinearRegression.scala:354)
	at org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)
	at org.apache.spark.ml.regression.LinearRegression.train(LinearRegression.scala:329)
	at org.apache.spark.ml.regression.LinearRegression.train(LinearRegression.scala:186)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:114)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:78)
	at org.apache.spark.ml.Pipeline.$anonfun$fit$5(Pipeline.scala:151)
	at org.apache.spark.ml.MLEvents.withFitEvent(events.scala:130)
	at org.apache.spark.ml.MLEvents.withFitEvent$(events.scala:123)
	at org.apache.spark.ml.util.Instrumentation.withFitEvent(Instrumentation.scala:42)
	at org.apache.spark.ml.Pipeline.$anonfun$fit$4(Pipeline.scala:151)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at org.apache.spark.ml.Pipeline.$anonfun$fit$2(Pipeline.scala:147)
	at org.apache.spark.ml.MLEvents.withFitEvent(events.scala:130)
	at org.apache.spark.ml.MLEvents.withFitEvent$(events.scala:123)
	at org.apache.spark.ml.util.Instrumentation.withFitEvent(Instrumentation.scala:42)
	at org.apache.spark.ml.Pipeline.$anonfun$fit$1(Pipeline.scala:133)
	at org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)
	at org.apache.spark.ml.Pipeline.fit(Pipeline.scala:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at sparklyr.Invoke.invoke(invoke.scala:161)
	at sparklyr.StreamHandler.handleMethodCall(stream.scala:141)
	at sparklyr.StreamHandler.read(stream.scala:62)
	at sparklyr.BackendHandler.$anonfun$channelRead0$1(handler.scala:60)
	at scala.util.control.Breaks.breakable(Breaks.scala:42)
	at sparklyr.BackendHandler.channelRead0(handler.scala:41)
	at sparklyr.BackendHandler.channelRead0(handler.scala:14)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:318)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.RuntimeException: Labels MUST NOT be Null or NaN
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)
	at scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:260)
	at scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:260)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1431)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$4(RDD.scala:1264)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$6(RDD.scala:1265)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	... 1 more

25/05/10 20:44:30.879 nioEventLoopGroup-2-2 ERROR Instrumentation: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 30.0 failed 1 times, most recent failure: Lost task 0.0 in stage 30.0 (TID 34) (127.0.0.1 executor driver): java.lang.RuntimeException: Labels MUST NOT be Null or NaN
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)
	at scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:260)
	at scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:260)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1431)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$4(RDD.scala:1264)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$6(RDD.scala:1265)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2488)
	at org.apache.spark.rdd.RDD.$anonfun$fold$1(RDD.scala:1202)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:410)
	at org.apache.spark.rdd.RDD.fold(RDD.scala:1196)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$2(RDD.scala:1289)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:410)
	at org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1256)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$1(RDD.scala:1242)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:410)
	at org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1242)
	at org.apache.spark.ml.optim.WeightedLeastSquares.fit(WeightedLeastSquares.scala:107)
	at org.apache.spark.ml.regression.LinearRegression.trainWithNormal(LinearRegression.scala:456)
	at org.apache.spark.ml.regression.LinearRegression.$anonfun$train$1(LinearRegression.scala:354)
	at org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)
	at org.apache.spark.ml.regression.LinearRegression.train(LinearRegression.scala:329)
	at org.apache.spark.ml.regression.LinearRegression.train(LinearRegression.scala:186)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:114)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:78)
	at org.apache.spark.ml.Pipeline.$anonfun$fit$5(Pipeline.scala:151)
	at org.apache.spark.ml.MLEvents.withFitEvent(events.scala:130)
	at org.apache.spark.ml.MLEvents.withFitEvent$(events.scala:123)
	at org.apache.spark.ml.util.Instrumentation.withFitEvent(Instrumentation.scala:42)
	at org.apache.spark.ml.Pipeline.$anonfun$fit$4(Pipeline.scala:151)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at org.apache.spark.ml.Pipeline.$anonfun$fit$2(Pipeline.scala:147)
	at org.apache.spark.ml.MLEvents.withFitEvent(events.scala:130)
	at org.apache.spark.ml.MLEvents.withFitEvent$(events.scala:123)
	at org.apache.spark.ml.util.Instrumentation.withFitEvent(Instrumentation.scala:42)
	at org.apache.spark.ml.Pipeline.$anonfun$fit$1(Pipeline.scala:133)
	at org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)
	at org.apache.spark.ml.Pipeline.fit(Pipeline.scala:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at sparklyr.Invoke.invoke(invoke.scala:161)
	at sparklyr.StreamHandler.handleMethodCall(stream.scala:141)
	at sparklyr.StreamHandler.read(stream.scala:62)
	at sparklyr.BackendHandler.$anonfun$channelRead0$1(handler.scala:60)
	at scala.util.control.Breaks.breakable(Breaks.scala:42)
	at sparklyr.BackendHandler.channelRead0(handler.scala:41)
	at sparklyr.BackendHandler.channelRead0(handler.scala:14)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:318)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.RuntimeException: Labels MUST NOT be Null or NaN
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)
	at scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:260)
	at scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:260)
	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1431)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$4(RDD.scala:1264)
	at org.apache.spark.rdd.RDD.$anonfun$treeAggregate$6(RDD.scala:1265)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	... 1 more

25/05/10 20:44:31.152 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 20:44:31.152 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 20:44:31.155 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 20:44:31.155 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 20:44:31.157 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 20:44:31.157 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 20:45:23.063 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.4436 ms
25/05/10 20:45:23.074 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:45:23.074 dag-scheduler-event-loop INFO DAGScheduler: Got job 31 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:45:23.074 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:26)
25/05/10 20:45:23.074 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:45:23.076 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:45:23.077 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[100] at collect at utils.scala:26), which has no missing parents
25/05/10 20:45:23.079 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 9.1 KiB, free 911.5 MiB)
25/05/10 20:45:23.080 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 911.5 MiB)
25/05/10 20:45:23.081 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:53507 (size: 4.3 KiB, free: 911.6 MiB)
25/05/10 20:45:23.081 dag-scheduler-event-loop INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1585
25/05/10 20:45:23.082 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[100] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:45:23.083 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
25/05/10 20:45:23.087 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 35) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 464229 bytes) 
25/05/10 20:45:23.087 Executor task launch worker for task 0.0 in stage 31.0 (TID 35) INFO Executor: Running task 0.0 in stage 31.0 (TID 35)
25/05/10 20:45:23.097 Executor task launch worker for task 0.0 in stage 31.0 (TID 35) INFO CodeGenerator: Code generated in 6.4977 ms
25/05/10 20:45:23.110 Executor task launch worker for task 0.0 in stage 31.0 (TID 35) INFO Executor: Finished task 0.0 in stage 31.0 (TID 35). 170221 bytes result sent to driver
25/05/10 20:45:23.111 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 35) in 28 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:45:23.112 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
25/05/10 20:45:23.112 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 31 (collect at utils.scala:26) finished in 0.035 s
25/05/10 20:45:23.113 dag-scheduler-event-loop INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:45:23.113 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
25/05/10 20:45:23.113 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 31 finished: collect at utils.scala:26, took 0.038421 s
25/05/10 20:45:30.524 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 20:45:30.526 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 20:45:30.527 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 20:45:30.527 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 20:45:30.529 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 20:45:30.529 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 20:45:30.578 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:45:30.579 dag-scheduler-event-loop INFO DAGScheduler: Got job 32 (collect at utils.scala:26) with 4 output partitions
25/05/10 20:45:30.579 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:26)
25/05/10 20:45:30.579 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:45:30.579 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:45:30.581 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[103] at collect at utils.scala:26), which has no missing parents
25/05/10 20:45:30.584 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 7.5 KiB, free 911.5 MiB)
25/05/10 20:45:30.586 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 911.5 MiB)
25/05/10 20:45:30.586 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.6 MiB)
25/05/10 20:45:30.586 dag-scheduler-event-loop INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1585
25/05/10 20:45:30.587 dag-scheduler-event-loop INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 32 (MapPartitionsRDD[103] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/05/10 20:45:30.587 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 32.0 with 4 tasks resource profile 0
25/05/10 20:45:30.588 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 36) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9380 bytes) 
25/05/10 20:45:30.588 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 37) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 9380 bytes) 
25/05/10 20:45:30.588 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 2.0 in stage 32.0 (TID 38) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 9380 bytes) 
25/05/10 20:45:30.588 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 3.0 in stage 32.0 (TID 39) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 9380 bytes) 
25/05/10 20:45:30.589 Executor task launch worker for task 0.0 in stage 32.0 (TID 36) INFO Executor: Running task 0.0 in stage 32.0 (TID 36)
25/05/10 20:45:30.590 Executor task launch worker for task 1.0 in stage 32.0 (TID 37) INFO Executor: Running task 1.0 in stage 32.0 (TID 37)
25/05/10 20:45:30.590 Executor task launch worker for task 2.0 in stage 32.0 (TID 38) INFO Executor: Running task 2.0 in stage 32.0 (TID 38)
25/05/10 20:45:30.590 Executor task launch worker for task 3.0 in stage 32.0 (TID 39) INFO Executor: Running task 3.0 in stage 32.0 (TID 39)
25/05/10 20:45:30.594 Executor task launch worker for task 2.0 in stage 32.0 (TID 38) INFO Executor: Finished task 2.0 in stage 32.0 (TID 38). 1436 bytes result sent to driver
25/05/10 20:45:30.594 Executor task launch worker for task 1.0 in stage 32.0 (TID 37) INFO Executor: Finished task 1.0 in stage 32.0 (TID 37). 1432 bytes result sent to driver
25/05/10 20:45:30.594 Executor task launch worker for task 0.0 in stage 32.0 (TID 36) INFO Executor: Finished task 0.0 in stage 32.0 (TID 36). 1393 bytes result sent to driver
25/05/10 20:45:30.594 Executor task launch worker for task 3.0 in stage 32.0 (TID 39) INFO Executor: Finished task 3.0 in stage 32.0 (TID 39). 1436 bytes result sent to driver
25/05/10 20:45:30.596 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 32.0 (TID 38) in 8 ms on 127.0.0.1 (executor driver) (1/4)
25/05/10 20:45:30.597 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 37) in 9 ms on 127.0.0.1 (executor driver) (2/4)
25/05/10 20:45:30.598 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 32.0 (TID 39) in 10 ms on 127.0.0.1 (executor driver) (3/4)
25/05/10 20:45:30.598 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 36) in 10 ms on 127.0.0.1 (executor driver) (4/4)
25/05/10 20:45:30.598 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
25/05/10 20:45:30.599 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 32 (collect at utils.scala:26) finished in 0.016 s
25/05/10 20:45:30.599 dag-scheduler-event-loop INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:45:30.599 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
25/05/10 20:45:30.599 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 32 finished: collect at utils.scala:26, took 0.021581 s
25/05/10 20:45:30.758 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:45:30.759 dag-scheduler-event-loop INFO DAGScheduler: Got job 33 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:45:30.759 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 33 (collect at utils.scala:26)
25/05/10 20:45:30.759 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:45:30.759 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:45:30.761 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[106] at collect at utils.scala:26), which has no missing parents
25/05/10 20:45:30.763 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 7.7 KiB, free 911.5 MiB)
25/05/10 20:45:30.764 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 911.5 MiB)
25/05/10 20:45:30.764 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.6 MiB)
25/05/10 20:45:30.766 dag-scheduler-event-loop INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1585
25/05/10 20:45:30.766 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[106] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:45:30.766 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
25/05/10 20:45:30.767 dispatcher-event-loop-8 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 40) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:45:30.768 Executor task launch worker for task 0.0 in stage 33.0 (TID 40) INFO Executor: Running task 0.0 in stage 33.0 (TID 40)
25/05/10 20:45:30.774 Executor task launch worker for task 0.0 in stage 33.0 (TID 40) INFO Executor: Finished task 0.0 in stage 33.0 (TID 40). 1370 bytes result sent to driver
25/05/10 20:45:30.776 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 40) in 9 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:45:30.776 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
25/05/10 20:45:30.776 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 33 (collect at utils.scala:26) finished in 0.015 s
25/05/10 20:45:30.777 dag-scheduler-event-loop INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:45:30.777 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished
25/05/10 20:45:30.777 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 33 finished: collect at utils.scala:26, took 0.019351 s
25/05/10 20:45:30.897 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:45:30.898 dag-scheduler-event-loop INFO DAGScheduler: Got job 34 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:45:30.898 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:26)
25/05/10 20:45:30.898 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:45:30.898 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:45:30.899 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[108] at collect at utils.scala:26), which has no missing parents
25/05/10 20:45:30.901 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 7.7 KiB, free 911.5 MiB)
25/05/10 20:45:30.902 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 911.5 MiB)
25/05/10 20:45:30.903 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.6 MiB)
25/05/10 20:45:30.903 dag-scheduler-event-loop INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1585
25/05/10 20:45:30.904 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[108] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:45:30.904 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
25/05/10 20:45:30.905 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 41) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:45:30.905 Executor task launch worker for task 0.0 in stage 34.0 (TID 41) INFO Executor: Running task 0.0 in stage 34.0 (TID 41)
25/05/10 20:45:30.907 Executor task launch worker for task 0.0 in stage 34.0 (TID 41) INFO Executor: Finished task 0.0 in stage 34.0 (TID 41). 1327 bytes result sent to driver
25/05/10 20:45:30.908 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 41) in 4 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:45:30.908 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
25/05/10 20:45:30.908 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 34 (collect at utils.scala:26) finished in 0.008 s
25/05/10 20:45:30.908 dag-scheduler-event-loop INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:45:30.908 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
25/05/10 20:45:30.908 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 34 finished: collect at utils.scala:26, took 0.011155 s
25/05/10 20:45:31.020 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 20:45:31.020 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 20:45:31.022 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/05/10 20:45:31.022 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_database: default	
25/05/10 20:45:31.023 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/05/10 20:45:31.023 nioEventLoopGroup-2-2 INFO audit: ugi=Owner	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/05/10 20:45:34.079 dag-scheduler-event-loop INFO DAGScheduler: Got job 35 (collect at StringIndexer.scala:204) with 1 output partitions
25/05/10 20:45:34.079 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 35 (collect at StringIndexer.scala:204)
25/05/10 20:45:34.079 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:45:34.079 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:45:34.079 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 35 (*(1) Scan ExistingRDD[CountryRegion#2494,Population#2495,Date#2496,Days#2497,Total_Cases#2498,Rate_of_Cases#2499,Log_Cases#2500]
 MapPartitionsRDD[111] at collect at StringIndexer.scala:204), which has no missing parents
25/05/10 20:45:34.087 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 12.2 KiB, free 911.5 MiB)
25/05/10 20:45:34.088 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 911.4 MiB)
25/05/10 20:45:34.089 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:53507 (size: 5.8 KiB, free: 911.6 MiB)
25/05/10 20:45:34.089 dag-scheduler-event-loop INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1585
25/05/10 20:45:34.090 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (*(1) Scan ExistingRDD[CountryRegion#2494,Population#2495,Date#2496,Days#2497,Total_Cases#2498,Rate_of_Cases#2499,Log_Cases#2500]
 MapPartitionsRDD[111] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
25/05/10 20:45:34.090 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
25/05/10 20:45:34.092 dispatcher-event-loop-11 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 42) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509949 bytes) 
25/05/10 20:45:34.093 Executor task launch worker for task 0.0 in stage 35.0 (TID 42) INFO Executor: Running task 0.0 in stage 35.0 (TID 42)
25/05/10 20:45:34.106 Executor task launch worker for task 0.0 in stage 35.0 (TID 42) INFO MemoryStore: Block rdd_111_0 stored as values in memory (estimated size 185.4 KiB, free 911.3 MiB)
25/05/10 20:45:34.106 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_111_0 in memory on 127.0.0.1:53507 (size: 185.4 KiB, free: 911.4 MiB)
25/05/10 20:45:34.107 Executor task launch worker for task 0.0 in stage 35.0 (TID 42) INFO Executor: 1 block locks were not released by task 0.0 in stage 35.0 (TID 42)
[rdd_111_0]
25/05/10 20:45:34.107 Executor task launch worker for task 0.0 in stage 35.0 (TID 42) INFO Executor: Finished task 0.0 in stage 35.0 (TID 42). 1230 bytes result sent to driver
25/05/10 20:45:34.108 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 42) in 17 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:45:34.108 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
25/05/10 20:45:34.109 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 35 (collect at StringIndexer.scala:204) finished in 0.028 s
25/05/10 20:45:34.109 dag-scheduler-event-loop INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:45:34.109 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
25/05/10 20:45:34.119 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 116 (collect at StringIndexer.scala:204) as input to shuffle 1
25/05/10 20:45:34.119 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 36 (collect at StringIndexer.scala:204) with 1 output partitions
25/05/10 20:45:34.119 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 36 (collect at StringIndexer.scala:204)
25/05/10 20:45:34.119 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:45:34.120 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:45:34.120 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[116] at collect at StringIndexer.scala:204), which has no missing parents
25/05/10 20:45:34.131 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 30.4 KiB, free 911.2 MiB)
25/05/10 20:45:34.132 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 13.6 KiB, free 911.2 MiB)
25/05/10 20:45:34.133 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:53507 (size: 13.6 KiB, free: 911.4 MiB)
25/05/10 20:45:34.134 dag-scheduler-event-loop INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1585
25/05/10 20:45:34.134 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[116] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
25/05/10 20:45:34.134 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
25/05/10 20:45:34.136 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 43) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509938 bytes) 
25/05/10 20:45:34.136 Executor task launch worker for task 0.0 in stage 36.0 (TID 43) INFO Executor: Running task 0.0 in stage 36.0 (TID 43)
25/05/10 20:45:34.142 Executor task launch worker for task 0.0 in stage 36.0 (TID 43) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:45:34.210 Executor task launch worker for task 0.0 in stage 36.0 (TID 43) INFO Executor: Finished task 0.0 in stage 36.0 (TID 43). 2269 bytes result sent to driver
25/05/10 20:45:34.211 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 43) in 76 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:45:34.211 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
25/05/10 20:45:34.212 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 36 (collect at StringIndexer.scala:204) finished in 0.091 s
25/05/10 20:45:34.212 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
25/05/10 20:45:34.212 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
25/05/10 20:45:34.212 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
25/05/10 20:45:34.212 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
25/05/10 20:45:34.228 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
25/05/10 20:45:34.229 dag-scheduler-event-loop INFO DAGScheduler: Got job 37 (collect at StringIndexer.scala:204) with 1 output partitions
25/05/10 20:45:34.229 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 38 (collect at StringIndexer.scala:204)
25/05/10 20:45:34.229 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
25/05/10 20:45:34.229 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:45:34.231 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[119] at collect at StringIndexer.scala:204), which has no missing parents
25/05/10 20:45:34.233 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 35.7 KiB, free 911.2 MiB)
25/05/10 20:45:34.234 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 911.2 MiB)
25/05/10 20:45:34.234 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:53507 (size: 16.3 KiB, free: 911.4 MiB)
25/05/10 20:45:34.234 dag-scheduler-event-loop INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1585
25/05/10 20:45:34.234 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[119] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
25/05/10 20:45:34.234 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
25/05/10 20:45:34.237 dispatcher-event-loop-8 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 44) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 9176 bytes) 
25/05/10 20:45:34.237 Executor task launch worker for task 0.0 in stage 38.0 (TID 44) INFO Executor: Running task 0.0 in stage 38.0 (TID 44)
25/05/10 20:45:34.241 Executor task launch worker for task 0.0 in stage 38.0 (TID 44) INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/10 20:45:34.241 Executor task launch worker for task 0.0 in stage 38.0 (TID 44) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/10 20:45:34.261 Executor task launch worker for task 0.0 in stage 38.0 (TID 44) INFO Executor: Finished task 0.0 in stage 38.0 (TID 44). 4985 bytes result sent to driver
25/05/10 20:45:34.262 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 44) in 26 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:45:34.262 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
25/05/10 20:45:34.263 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 38 (collect at StringIndexer.scala:204) finished in 0.032 s
25/05/10 20:45:34.263 dag-scheduler-event-loop INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:45:34.263 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
25/05/10 20:45:34.264 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 37 finished: collect at StringIndexer.scala:204, took 0.035432 s
25/05/10 20:45:34.322 nioEventLoopGroup-2-2 INFO Instrumentation: [b043dd5c] training finished
25/05/10 20:45:34.364 nioEventLoopGroup-2-2 INFO Instrumentation: [a3afb89d] training finished
25/05/10 20:45:34.374 nioEventLoopGroup-2-2 INFO Instrumentation: [70366364] Stage class: LinearRegression
25/05/10 20:45:34.374 nioEventLoopGroup-2-2 INFO Instrumentation: [70366364] Stage uid: linear_regression__45c579e3_ab5d_4a22_af55_c62666265330
25/05/10 20:45:34.404 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 10.2505 ms
25/05/10 20:45:34.419 nioEventLoopGroup-2-2 INFO Instrumentation: [70366364] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
25/05/10 20:45:34.421 nioEventLoopGroup-2-2 INFO Instrumentation: [70366364] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
25/05/10 20:45:34.423 nioEventLoopGroup-2-2 INFO Instrumentation: [70366364] {"numFeatures":6}
25/05/10 20:45:34.489 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 19.2261 ms
25/05/10 20:45:34.501 nioEventLoopGroup-2-2 WARN Instrumentation: [70366364] regParam is zero, which might cause numerical instability and overfitting.
25/05/10 20:45:34.509 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
25/05/10 20:45:34.511 dag-scheduler-event-loop INFO DAGScheduler: Got job 38 (treeAggregate at WeightedLeastSquares.scala:107) with 1 output partitions
25/05/10 20:45:34.511 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 39 (treeAggregate at WeightedLeastSquares.scala:107)
25/05/10 20:45:34.511 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:45:34.511 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:45:34.513 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[135] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
25/05/10 20:45:34.544 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 80.1 KiB, free 911.1 MiB)
25/05/10 20:45:34.546 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 911.1 MiB)
25/05/10 20:45:34.546 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:53507 (size: 31.1 KiB, free: 911.3 MiB)
25/05/10 20:45:34.547 dag-scheduler-event-loop INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1585
25/05/10 20:45:34.547 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[135] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0))
25/05/10 20:45:34.547 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
25/05/10 20:45:34.551 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 45) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509949 bytes) 
25/05/10 20:45:34.552 Executor task launch worker for task 0.0 in stage 39.0 (TID 45) INFO Executor: Running task 0.0 in stage 39.0 (TID 45)
25/05/10 20:45:34.570 Executor task launch worker for task 0.0 in stage 39.0 (TID 45) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:45:34.614 Executor task launch worker for task 0.0 in stage 39.0 (TID 45) INFO CodeGenerator: Code generated in 43.1614 ms
25/05/10 20:45:34.638 Executor task launch worker for task 0.0 in stage 39.0 (TID 45) INFO CodeGenerator: Code generated in 7.8061 ms
25/05/10 20:45:34.666 Executor task launch worker for task 0.0 in stage 39.0 (TID 45) WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS
25/05/10 20:45:34.864 Executor task launch worker for task 0.0 in stage 39.0 (TID 45) INFO Executor: Finished task 0.0 in stage 39.0 (TID 45). 2170 bytes result sent to driver
25/05/10 20:45:34.865 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 45) in 316 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:45:34.865 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
25/05/10 20:45:34.866 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 39 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.352 s
25/05/10 20:45:34.866 dag-scheduler-event-loop INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:45:34.866 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
25/05/10 20:45:34.867 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 38 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.357569 s
25/05/10 20:45:34.869 nioEventLoopGroup-2-2 INFO Instrumentation: [70366364] Number of instances: 5715.
25/05/10 20:45:34.941 nioEventLoopGroup-2-2 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK
25/05/10 20:45:35.139 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 11.8912 ms
25/05/10 20:45:35.196 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
25/05/10 20:45:35.196 dag-scheduler-event-loop INFO DAGScheduler: Got job 39 (treeAggregate at Statistics.scala:58) with 1 output partitions
25/05/10 20:45:35.196 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 40 (treeAggregate at Statistics.scala:58)
25/05/10 20:45:35.196 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:45:35.197 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:45:35.198 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[145] at treeAggregate at Statistics.scala:58), which has no missing parents
25/05/10 20:45:35.210 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 69.7 KiB, free 911.0 MiB)
25/05/10 20:45:35.211 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 29.2 KiB, free 911.0 MiB)
25/05/10 20:45:35.212 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:53507 (size: 29.2 KiB, free: 911.3 MiB)
25/05/10 20:45:35.212 dag-scheduler-event-loop INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1585
25/05/10 20:45:35.212 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[145] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0))
25/05/10 20:45:35.212 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
25/05/10 20:45:35.214 dispatcher-event-loop-11 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 46) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509949 bytes) 
25/05/10 20:45:35.214 Executor task launch worker for task 0.0 in stage 40.0 (TID 46) INFO Executor: Running task 0.0 in stage 40.0 (TID 46)
25/05/10 20:45:35.246 Executor task launch worker for task 0.0 in stage 40.0 (TID 46) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:45:35.265 Executor task launch worker for task 0.0 in stage 40.0 (TID 46) INFO CodeGenerator: Code generated in 17.6583 ms
25/05/10 20:45:35.278 Executor task launch worker for task 0.0 in stage 40.0 (TID 46) INFO CodeGenerator: Code generated in 8.5079 ms
25/05/10 20:45:35.353 Executor task launch worker for task 0.0 in stage 40.0 (TID 46) INFO Executor: Finished task 0.0 in stage 40.0 (TID 46). 2775 bytes result sent to driver
25/05/10 20:45:35.354 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 46) in 141 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:45:35.354 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
25/05/10 20:45:35.355 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 40 (treeAggregate at Statistics.scala:58) finished in 0.156 s
25/05/10 20:45:35.355 dag-scheduler-event-loop INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:45:35.355 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
25/05/10 20:45:35.355 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 39 finished: treeAggregate at Statistics.scala:58, took 0.159702 s
25/05/10 20:45:35.358 nioEventLoopGroup-2-2 INFO Instrumentation: [9271eb09] training finished
25/05/10 20:45:35.593 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.4421 ms
25/05/10 20:45:35.602 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:45:35.603 dag-scheduler-event-loop INFO DAGScheduler: Got job 40 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:45:35.603 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 41 (collect at utils.scala:26)
25/05/10 20:45:35.603 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:45:35.603 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:45:35.603 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[147] at collect at utils.scala:26), which has no missing parents
25/05/10 20:45:35.605 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 7.8 KiB, free 911.0 MiB)
25/05/10 20:45:35.605 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 911.0 MiB)
25/05/10 20:45:35.606 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.3 MiB)
25/05/10 20:45:35.606 dag-scheduler-event-loop INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1585
25/05/10 20:45:35.607 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[147] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:45:35.607 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
25/05/10 20:45:35.608 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 47) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:45:35.608 Executor task launch worker for task 0.0 in stage 41.0 (TID 47) INFO Executor: Running task 0.0 in stage 41.0 (TID 47)
25/05/10 20:45:35.618 Executor task launch worker for task 0.0 in stage 41.0 (TID 47) INFO CodeGenerator: Code generated in 8.306 ms
25/05/10 20:45:35.622 Executor task launch worker for task 0.0 in stage 41.0 (TID 47) INFO Executor: Finished task 0.0 in stage 41.0 (TID 47). 1327 bytes result sent to driver
25/05/10 20:45:35.623 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 47) in 16 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:45:35.624 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
25/05/10 20:45:35.624 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 41 (collect at utils.scala:26) finished in 0.020 s
25/05/10 20:45:35.625 dag-scheduler-event-loop INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:45:35.625 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
25/05/10 20:45:35.625 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 40 finished: collect at utils.scala:26, took 0.022598 s
25/05/10 20:45:35.639 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 11.239 ms
25/05/10 20:45:35.814 nioEventLoopGroup-2-2 INFO Instrumentation: [a7f262f8] training finished
25/05/10 20:45:35.897 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 3.6823 ms
25/05/10 20:45:35.906 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:45:35.907 dag-scheduler-event-loop INFO DAGScheduler: Got job 41 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:45:35.907 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 42 (collect at utils.scala:26)
25/05/10 20:45:35.907 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:45:35.907 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:45:35.908 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[149] at collect at utils.scala:26), which has no missing parents
25/05/10 20:45:35.910 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 7.8 KiB, free 910.9 MiB)
25/05/10 20:45:35.910 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 910.9 MiB)
25/05/10 20:45:35.911 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.3 MiB)
25/05/10 20:45:35.911 dag-scheduler-event-loop INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1585
25/05/10 20:45:35.911 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[149] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:45:35.912 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
25/05/10 20:45:35.912 dispatcher-event-loop-8 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 48) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:45:35.912 Executor task launch worker for task 0.0 in stage 42.0 (TID 48) INFO Executor: Running task 0.0 in stage 42.0 (TID 48)
25/05/10 20:45:35.920 Executor task launch worker for task 0.0 in stage 42.0 (TID 48) INFO CodeGenerator: Code generated in 6.4034 ms
25/05/10 20:45:35.923 Executor task launch worker for task 0.0 in stage 42.0 (TID 48) INFO Executor: Finished task 0.0 in stage 42.0 (TID 48). 1413 bytes result sent to driver
25/05/10 20:45:35.924 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 48) in 12 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:45:35.924 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
25/05/10 20:45:35.924 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 42 (collect at utils.scala:26) finished in 0.016 s
25/05/10 20:45:35.924 dag-scheduler-event-loop INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:45:35.924 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
25/05/10 20:45:35.925 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 41 finished: collect at utils.scala:26, took 0.018556 s
25/05/10 20:45:35.934 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.795 ms
25/05/10 20:45:36.311 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:45:36.312 dag-scheduler-event-loop INFO DAGScheduler: Got job 42 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:45:36.312 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 43 (collect at utils.scala:26)
25/05/10 20:45:36.312 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:45:36.312 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:45:36.313 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[151] at collect at utils.scala:26), which has no missing parents
25/05/10 20:45:36.314 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 7.8 KiB, free 910.9 MiB)
25/05/10 20:45:36.314 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 910.9 MiB)
25/05/10 20:45:36.316 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.3 MiB)
25/05/10 20:45:36.317 dag-scheduler-event-loop INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1585
25/05/10 20:45:36.317 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[151] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:45:36.317 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0
25/05/10 20:45:36.318 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 49) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:45:36.319 Executor task launch worker for task 0.0 in stage 43.0 (TID 49) INFO Executor: Running task 0.0 in stage 43.0 (TID 49)
25/05/10 20:45:36.321 Executor task launch worker for task 0.0 in stage 43.0 (TID 49) INFO Executor: Finished task 0.0 in stage 43.0 (TID 49). 1327 bytes result sent to driver
25/05/10 20:45:36.322 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 49) in 4 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:45:36.322 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
25/05/10 20:45:36.322 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 43 (collect at utils.scala:26) finished in 0.009 s
25/05/10 20:45:36.322 dag-scheduler-event-loop INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:45:36.322 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished
25/05/10 20:45:36.322 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 42 finished: collect at utils.scala:26, took 0.010391 s
25/05/10 20:45:36.533 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.427 ms
25/05/10 20:45:36.541 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:45:36.542 dag-scheduler-event-loop INFO DAGScheduler: Got job 43 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:45:36.542 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 44 (collect at utils.scala:26)
25/05/10 20:45:36.542 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:45:36.542 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:45:36.543 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[153] at collect at utils.scala:26), which has no missing parents
25/05/10 20:45:36.544 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 7.4 KiB, free 910.9 MiB)
25/05/10 20:45:36.545 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 910.9 MiB)
25/05/10 20:45:36.545 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.3 MiB)
25/05/10 20:45:36.546 dag-scheduler-event-loop INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1585
25/05/10 20:45:36.546 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[153] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:45:36.546 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
25/05/10 20:45:36.547 dispatcher-event-loop-11 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 50) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:45:36.548 Executor task launch worker for task 0.0 in stage 44.0 (TID 50) INFO Executor: Running task 0.0 in stage 44.0 (TID 50)
25/05/10 20:45:36.554 Executor task launch worker for task 0.0 in stage 44.0 (TID 50) INFO CodeGenerator: Code generated in 3.4215 ms
25/05/10 20:45:36.556 Executor task launch worker for task 0.0 in stage 44.0 (TID 50) INFO Executor: Finished task 0.0 in stage 44.0 (TID 50). 1369 bytes result sent to driver
25/05/10 20:45:36.557 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 50) in 11 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:45:36.557 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
25/05/10 20:45:36.558 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 44 (collect at utils.scala:26) finished in 0.015 s
25/05/10 20:45:36.558 dag-scheduler-event-loop INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:45:36.558 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
25/05/10 20:45:36.558 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 43 finished: collect at utils.scala:26, took 0.016788 s
25/05/10 20:45:36.564 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.4104 ms
25/05/10 20:45:36.653 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.178 ms
25/05/10 20:45:36.660 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 158 (count at <unknown>:0) as input to shuffle 2
25/05/10 20:45:36.660 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 44 (count at <unknown>:0) with 1 output partitions
25/05/10 20:45:36.660 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 45 (count at <unknown>:0)
25/05/10 20:45:36.660 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:45:36.661 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:45:36.661 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[158] at count at <unknown>:0), which has no missing parents
25/05/10 20:45:36.666 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 19.5 KiB, free 910.9 MiB)
25/05/10 20:45:36.668 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 8.4 KiB, free 910.9 MiB)
25/05/10 20:45:36.668 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:53507 (size: 8.4 KiB, free: 911.3 MiB)
25/05/10 20:45:36.669 dag-scheduler-event-loop INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1585
25/05/10 20:45:36.670 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[158] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/05/10 20:45:36.670 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0
25/05/10 20:45:36.673 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 51) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509938 bytes) 
25/05/10 20:45:36.674 Executor task launch worker for task 0.0 in stage 45.0 (TID 51) INFO Executor: Running task 0.0 in stage 45.0 (TID 51)
25/05/10 20:45:36.684 Executor task launch worker for task 0.0 in stage 45.0 (TID 51) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:45:36.709 Executor task launch worker for task 0.0 in stage 45.0 (TID 51) INFO CodeGenerator: Code generated in 22.5898 ms
25/05/10 20:45:36.741 Executor task launch worker for task 0.0 in stage 45.0 (TID 51) INFO CodeGenerator: Code generated in 27.5845 ms
25/05/10 20:45:36.762 Executor task launch worker for task 0.0 in stage 45.0 (TID 51) INFO Executor: Finished task 0.0 in stage 45.0 (TID 51). 2166 bytes result sent to driver
25/05/10 20:45:36.763 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 51) in 93 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:45:36.763 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
25/05/10 20:45:36.764 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 45 (count at <unknown>:0) finished in 0.102 s
25/05/10 20:45:36.764 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
25/05/10 20:45:36.764 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
25/05/10 20:45:36.764 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
25/05/10 20:45:36.764 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
25/05/10 20:45:36.784 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.5386 ms
25/05/10 20:45:36.794 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at <unknown>:0
25/05/10 20:45:36.795 dag-scheduler-event-loop INFO DAGScheduler: Got job 45 (count at <unknown>:0) with 1 output partitions
25/05/10 20:45:36.795 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 47 (count at <unknown>:0)
25/05/10 20:45:36.795 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
25/05/10 20:45:36.795 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:45:36.796 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[161] at count at <unknown>:0), which has no missing parents
25/05/10 20:45:36.796 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 12.5 KiB, free 910.9 MiB)
25/05/10 20:45:36.798 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 910.9 MiB)
25/05/10 20:45:36.798 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:53507 (size: 5.9 KiB, free: 911.3 MiB)
25/05/10 20:45:36.798 dag-scheduler-event-loop INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1585
25/05/10 20:45:36.799 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[161] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/05/10 20:45:36.799 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks resource profile 0
25/05/10 20:45:36.800 dispatcher-event-loop-8 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 52) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 9176 bytes) 
25/05/10 20:45:36.801 Executor task launch worker for task 0.0 in stage 47.0 (TID 52) INFO Executor: Running task 0.0 in stage 47.0 (TID 52)
25/05/10 20:45:36.805 Executor task launch worker for task 0.0 in stage 47.0 (TID 52) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/10 20:45:36.805 Executor task launch worker for task 0.0 in stage 47.0 (TID 52) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/10 20:45:36.814 Executor task launch worker for task 0.0 in stage 47.0 (TID 52) INFO CodeGenerator: Code generated in 8.7754 ms
25/05/10 20:45:36.819 Executor task launch worker for task 0.0 in stage 47.0 (TID 52) INFO Executor: Finished task 0.0 in stage 47.0 (TID 52). 3952 bytes result sent to driver
25/05/10 20:45:36.820 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 52) in 20 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:45:36.820 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
25/05/10 20:45:36.821 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 47 (count at <unknown>:0) finished in 0.025 s
25/05/10 20:45:36.821 dag-scheduler-event-loop INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:45:36.821 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
25/05/10 20:45:36.821 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 45 finished: count at <unknown>:0, took 0.026922 s
25/05/10 20:45:36.906 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 19.0119 ms
25/05/10 20:45:36.920 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:45:36.921 dag-scheduler-event-loop INFO DAGScheduler: Got job 46 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:45:36.921 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 48 (collect at utils.scala:26)
25/05/10 20:45:36.921 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:45:36.921 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:45:36.922 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[166] at collect at utils.scala:26), which has no missing parents
25/05/10 20:45:36.925 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 61.6 KiB, free 910.8 MiB)
25/05/10 20:45:36.926 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 24.7 KiB, free 910.8 MiB)
25/05/10 20:45:36.927 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:53507 (size: 24.7 KiB, free: 911.2 MiB)
25/05/10 20:45:36.927 dag-scheduler-event-loop INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1585
25/05/10 20:45:36.928 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[166] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:45:36.928 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
25/05/10 20:45:36.931 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 53) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509949 bytes) 
25/05/10 20:45:36.932 Executor task launch worker for task 0.0 in stage 48.0 (TID 53) INFO Executor: Running task 0.0 in stage 48.0 (TID 53)
25/05/10 20:45:36.943 Executor task launch worker for task 0.0 in stage 48.0 (TID 53) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:45:36.961 Executor task launch worker for task 0.0 in stage 48.0 (TID 53) INFO CodeGenerator: Code generated in 17.3524 ms
25/05/10 20:45:37.018 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:53507 in memory (size: 4.3 KiB, free: 911.2 MiB)
25/05/10 20:45:37.023 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.3 MiB)
25/05/10 20:45:37.027 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:53507 in memory (size: 5.8 KiB, free: 911.3 MiB)
25/05/10 20:45:37.032 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.3 MiB)
25/05/10 20:45:37.036 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:53507 in memory (size: 8.4 KiB, free: 911.3 MiB)
25/05/10 20:45:37.042 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:53507 in memory (size: 29.2 KiB, free: 911.3 MiB)
25/05/10 20:45:37.046 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.3 MiB)
25/05/10 20:45:37.050 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.3 MiB)
25/05/10 20:45:37.054 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:53507 in memory (size: 31.1 KiB, free: 911.3 MiB)
25/05/10 20:45:37.059 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:53507 in memory (size: 16.3 KiB, free: 911.4 MiB)
25/05/10 20:45:37.063 Executor task launch worker for task 0.0 in stage 48.0 (TID 53) INFO Executor: Finished task 0.0 in stage 48.0 (TID 53). 54073 bytes result sent to driver
25/05/10 20:45:37.063 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.4 MiB)
25/05/10 20:45:37.064 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 53) in 135 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:45:37.064 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
25/05/10 20:45:37.065 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 48 (collect at utils.scala:26) finished in 0.143 s
25/05/10 20:45:37.065 dag-scheduler-event-loop INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:45:37.065 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
25/05/10 20:45:37.065 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 46 finished: collect at utils.scala:26, took 0.145218 s
25/05/10 20:45:37.068 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.4 MiB)
25/05/10 20:45:37.072 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:53507 in memory (size: 13.6 KiB, free: 911.4 MiB)
25/05/10 20:45:37.075 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.4 MiB)
25/05/10 20:45:37.077 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.9174 ms
25/05/10 20:45:37.080 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:53507 in memory (size: 5.9 KiB, free: 911.4 MiB)
25/05/10 20:47:22.198 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 171 (collect at StringIndexer.scala:204) as input to shuffle 3
25/05/10 20:47:22.198 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 47 (collect at StringIndexer.scala:204) with 1 output partitions
25/05/10 20:47:22.198 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 49 (collect at StringIndexer.scala:204)
25/05/10 20:47:22.198 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:47:22.198 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:22.199 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 49 (MapPartitionsRDD[171] at collect at StringIndexer.scala:204), which has no missing parents
25/05/10 20:47:22.204 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 30.6 KiB, free 911.2 MiB)
25/05/10 20:47:22.206 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 911.2 MiB)
25/05/10 20:47:22.207 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:53507 (size: 13.7 KiB, free: 911.4 MiB)
25/05/10 20:47:22.207 dag-scheduler-event-loop INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:22.208 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[171] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:22.208 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0
25/05/10 20:47:22.210 dispatcher-event-loop-9 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 54) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509938 bytes) 
25/05/10 20:47:22.213 Executor task launch worker for task 0.0 in stage 49.0 (TID 54) INFO Executor: Running task 0.0 in stage 49.0 (TID 54)
25/05/10 20:47:22.217 Executor task launch worker for task 0.0 in stage 49.0 (TID 54) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:47:22.241 Executor task launch worker for task 0.0 in stage 49.0 (TID 54) INFO Executor: Finished task 0.0 in stage 49.0 (TID 54). 2226 bytes result sent to driver
25/05/10 20:47:22.242 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 54) in 34 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:22.242 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
25/05/10 20:47:22.242 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 49 (collect at StringIndexer.scala:204) finished in 0.043 s
25/05/10 20:47:22.242 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
25/05/10 20:47:22.242 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
25/05/10 20:47:22.242 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
25/05/10 20:47:22.242 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
25/05/10 20:47:22.256 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
25/05/10 20:47:22.256 dag-scheduler-event-loop INFO DAGScheduler: Got job 48 (collect at StringIndexer.scala:204) with 1 output partitions
25/05/10 20:47:22.256 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 51 (collect at StringIndexer.scala:204)
25/05/10 20:47:22.257 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
25/05/10 20:47:22.257 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:22.257 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[174] at collect at StringIndexer.scala:204), which has no missing parents
25/05/10 20:47:22.258 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 35.9 KiB, free 911.2 MiB)
25/05/10 20:47:22.259 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 911.2 MiB)
25/05/10 20:47:22.260 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:53507 (size: 16.4 KiB, free: 911.4 MiB)
25/05/10 20:47:22.260 dag-scheduler-event-loop INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:22.260 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[174] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:22.260 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0
25/05/10 20:47:22.261 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 55) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 9176 bytes) 
25/05/10 20:47:22.262 Executor task launch worker for task 0.0 in stage 51.0 (TID 55) INFO Executor: Running task 0.0 in stage 51.0 (TID 55)
25/05/10 20:47:22.265 Executor task launch worker for task 0.0 in stage 51.0 (TID 55) INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/10 20:47:22.265 Executor task launch worker for task 0.0 in stage 51.0 (TID 55) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/10 20:47:22.284 Executor task launch worker for task 0.0 in stage 51.0 (TID 55) INFO Executor: Finished task 0.0 in stage 51.0 (TID 55). 4985 bytes result sent to driver
25/05/10 20:47:22.286 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 55) in 25 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:22.286 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
25/05/10 20:47:22.286 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 51 (collect at StringIndexer.scala:204) finished in 0.029 s
25/05/10 20:47:22.287 dag-scheduler-event-loop INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:47:22.287 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
25/05/10 20:47:22.287 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 48 finished: collect at StringIndexer.scala:204, took 0.031143 s
25/05/10 20:47:22.332 nioEventLoopGroup-2-2 INFO Instrumentation: [43467683] training finished
25/05/10 20:47:22.363 nioEventLoopGroup-2-2 INFO Instrumentation: [79e1ce42] training finished
25/05/10 20:47:22.371 nioEventLoopGroup-2-2 INFO Instrumentation: [a68ad349] Stage class: LinearRegression
25/05/10 20:47:22.372 nioEventLoopGroup-2-2 INFO Instrumentation: [a68ad349] Stage uid: linear_regression__8883c859_952b_4281_9887_a11f124b4a1c
25/05/10 20:47:22.407 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 14.6806 ms
25/05/10 20:47:22.416 nioEventLoopGroup-2-2 INFO Instrumentation: [a68ad349] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
25/05/10 20:47:22.417 nioEventLoopGroup-2-2 INFO Instrumentation: [a68ad349] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
25/05/10 20:47:22.418 nioEventLoopGroup-2-2 INFO Instrumentation: [a68ad349] {"numFeatures":6}
25/05/10 20:47:22.465 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 14.6317 ms
25/05/10 20:47:22.476 nioEventLoopGroup-2-2 WARN Instrumentation: [a68ad349] regParam is zero, which might cause numerical instability and overfitting.
25/05/10 20:47:22.484 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
25/05/10 20:47:22.485 dag-scheduler-event-loop INFO DAGScheduler: Got job 49 (treeAggregate at WeightedLeastSquares.scala:107) with 1 output partitions
25/05/10 20:47:22.485 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 52 (treeAggregate at WeightedLeastSquares.scala:107)
25/05/10 20:47:22.485 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:47:22.485 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:22.486 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[190] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
25/05/10 20:47:22.504 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 80.1 KiB, free 911.1 MiB)
25/05/10 20:47:22.507 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 911.0 MiB)
25/05/10 20:47:22.507 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:53507 (size: 31.1 KiB, free: 911.3 MiB)
25/05/10 20:47:22.508 dag-scheduler-event-loop INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:22.508 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[190] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:22.508 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0
25/05/10 20:47:22.510 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 56) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509949 bytes) 
25/05/10 20:47:22.511 Executor task launch worker for task 0.0 in stage 52.0 (TID 56) INFO Executor: Running task 0.0 in stage 52.0 (TID 56)
25/05/10 20:47:22.519 Executor task launch worker for task 0.0 in stage 52.0 (TID 56) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:47:22.541 Executor task launch worker for task 0.0 in stage 52.0 (TID 56) INFO CodeGenerator: Code generated in 20.634 ms
25/05/10 20:47:22.582 Executor task launch worker for task 0.0 in stage 52.0 (TID 56) INFO Executor: Finished task 0.0 in stage 52.0 (TID 56). 2127 bytes result sent to driver
25/05/10 20:47:22.583 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 56) in 74 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:22.583 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
25/05/10 20:47:22.583 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 52 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.097 s
25/05/10 20:47:22.584 dag-scheduler-event-loop INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:47:22.584 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished
25/05/10 20:47:22.584 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 49 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.100038 s
25/05/10 20:47:22.585 nioEventLoopGroup-2-2 INFO Instrumentation: [a68ad349] Number of instances: 5715.
25/05/10 20:47:22.633 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.3358 ms
25/05/10 20:47:22.651 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
25/05/10 20:47:22.651 dag-scheduler-event-loop INFO DAGScheduler: Got job 50 (treeAggregate at Statistics.scala:58) with 1 output partitions
25/05/10 20:47:22.651 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 53 (treeAggregate at Statistics.scala:58)
25/05/10 20:47:22.651 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:47:22.652 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:22.652 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[200] at treeAggregate at Statistics.scala:58), which has no missing parents
25/05/10 20:47:22.660 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 69.7 KiB, free 911.0 MiB)
25/05/10 20:47:22.662 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 29.2 KiB, free 910.9 MiB)
25/05/10 20:47:22.662 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:53507 (size: 29.2 KiB, free: 911.3 MiB)
25/05/10 20:47:22.663 dag-scheduler-event-loop INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:22.663 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[200] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:22.663 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
25/05/10 20:47:22.665 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 57) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509949 bytes) 
25/05/10 20:47:22.666 Executor task launch worker for task 0.0 in stage 53.0 (TID 57) INFO Executor: Running task 0.0 in stage 53.0 (TID 57)
25/05/10 20:47:22.672 Executor task launch worker for task 0.0 in stage 53.0 (TID 57) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:47:22.684 Executor task launch worker for task 0.0 in stage 53.0 (TID 57) INFO CodeGenerator: Code generated in 11.2233 ms
25/05/10 20:47:22.741 Executor task launch worker for task 0.0 in stage 53.0 (TID 57) INFO Executor: Finished task 0.0 in stage 53.0 (TID 57). 2775 bytes result sent to driver
25/05/10 20:47:22.742 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 57) in 79 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:22.742 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
25/05/10 20:47:22.743 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 53 (treeAggregate at Statistics.scala:58) finished in 0.090 s
25/05/10 20:47:22.743 dag-scheduler-event-loop INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:47:22.743 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
25/05/10 20:47:22.743 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 50 finished: treeAggregate at Statistics.scala:58, took 0.092929 s
25/05/10 20:47:22.745 nioEventLoopGroup-2-2 INFO Instrumentation: [f9b49dd8] training finished
25/05/10 20:47:23.020 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:47:23.021 dag-scheduler-event-loop INFO DAGScheduler: Got job 51 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:47:23.021 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 54 (collect at utils.scala:26)
25/05/10 20:47:23.021 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:47:23.021 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:23.021 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[202] at collect at utils.scala:26), which has no missing parents
25/05/10 20:47:23.022 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 7.8 KiB, free 910.9 MiB)
25/05/10 20:47:23.027 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 910.9 MiB)
25/05/10 20:47:23.027 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.3 MiB)
25/05/10 20:47:23.028 dag-scheduler-event-loop INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:23.028 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[202] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:23.028 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0
25/05/10 20:47:23.028 dispatcher-event-loop-9 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 58) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:47:23.029 Executor task launch worker for task 0.0 in stage 54.0 (TID 58) INFO Executor: Running task 0.0 in stage 54.0 (TID 58)
25/05/10 20:47:23.031 Executor task launch worker for task 0.0 in stage 54.0 (TID 58) INFO Executor: Finished task 0.0 in stage 54.0 (TID 58). 1370 bytes result sent to driver
25/05/10 20:47:23.032 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 58) in 4 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:23.032 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
25/05/10 20:47:23.032 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 54 (collect at utils.scala:26) finished in 0.010 s
25/05/10 20:47:23.032 dag-scheduler-event-loop INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:47:23.032 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
25/05/10 20:47:23.032 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 51 finished: collect at utils.scala:26, took 0.011629 s
25/05/10 20:47:23.199 nioEventLoopGroup-2-2 INFO Instrumentation: [2aee8952] training finished
25/05/10 20:47:23.274 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:47:23.275 dag-scheduler-event-loop INFO DAGScheduler: Got job 52 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:47:23.275 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 55 (collect at utils.scala:26)
25/05/10 20:47:23.275 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:47:23.275 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:23.275 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[204] at collect at utils.scala:26), which has no missing parents
25/05/10 20:47:23.276 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 7.8 KiB, free 910.9 MiB)
25/05/10 20:47:23.277 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 910.9 MiB)
25/05/10 20:47:23.278 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.3 MiB)
25/05/10 20:47:23.278 dag-scheduler-event-loop INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:23.279 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[204] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:23.279 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0
25/05/10 20:47:23.279 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 59) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:47:23.279 Executor task launch worker for task 0.0 in stage 55.0 (TID 59) INFO Executor: Running task 0.0 in stage 55.0 (TID 59)
25/05/10 20:47:23.283 Executor task launch worker for task 0.0 in stage 55.0 (TID 59) INFO Executor: Finished task 0.0 in stage 55.0 (TID 59). 1370 bytes result sent to driver
25/05/10 20:47:23.283 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 59) in 4 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:23.283 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
25/05/10 20:47:23.284 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 55 (collect at utils.scala:26) finished in 0.008 s
25/05/10 20:47:23.284 dag-scheduler-event-loop INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:47:23.284 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
25/05/10 20:47:23.284 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 52 finished: collect at utils.scala:26, took 0.009975 s
25/05/10 20:47:23.662 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:47:23.662 dag-scheduler-event-loop INFO DAGScheduler: Got job 53 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:47:23.662 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 56 (collect at utils.scala:26)
25/05/10 20:47:23.662 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:47:23.662 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:23.663 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[206] at collect at utils.scala:26), which has no missing parents
25/05/10 20:47:23.663 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 7.8 KiB, free 910.9 MiB)
25/05/10 20:47:23.664 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 910.9 MiB)
25/05/10 20:47:23.665 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.3 MiB)
25/05/10 20:47:23.665 dag-scheduler-event-loop INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:23.665 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[206] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:23.665 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0
25/05/10 20:47:23.665 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 60) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:47:23.667 Executor task launch worker for task 0.0 in stage 56.0 (TID 60) INFO Executor: Running task 0.0 in stage 56.0 (TID 60)
25/05/10 20:47:23.669 Executor task launch worker for task 0.0 in stage 56.0 (TID 60) INFO Executor: Finished task 0.0 in stage 56.0 (TID 60). 1327 bytes result sent to driver
25/05/10 20:47:23.670 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 60) in 5 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:23.670 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
25/05/10 20:47:23.670 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 56 (collect at utils.scala:26) finished in 0.007 s
25/05/10 20:47:23.670 dag-scheduler-event-loop INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:47:23.670 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished
25/05/10 20:47:23.671 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 53 finished: collect at utils.scala:26, took 0.007793 s
25/05/10 20:47:23.884 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:47:23.885 dag-scheduler-event-loop INFO DAGScheduler: Got job 54 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:47:23.885 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 57 (collect at utils.scala:26)
25/05/10 20:47:23.885 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:47:23.885 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:23.885 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[208] at collect at utils.scala:26), which has no missing parents
25/05/10 20:47:23.886 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 7.4 KiB, free 910.9 MiB)
25/05/10 20:47:23.887 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 910.9 MiB)
25/05/10 20:47:23.887 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.3 MiB)
25/05/10 20:47:23.888 dag-scheduler-event-loop INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:23.888 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[208] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:23.888 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
25/05/10 20:47:23.889 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 61) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:47:23.890 Executor task launch worker for task 0.0 in stage 57.0 (TID 61) INFO Executor: Running task 0.0 in stage 57.0 (TID 61)
25/05/10 20:47:23.893 Executor task launch worker for task 0.0 in stage 57.0 (TID 61) INFO Executor: Finished task 0.0 in stage 57.0 (TID 61). 1369 bytes result sent to driver
25/05/10 20:47:23.894 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 61) in 5 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:23.894 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
25/05/10 20:47:23.895 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 57 (collect at utils.scala:26) finished in 0.009 s
25/05/10 20:47:23.895 dag-scheduler-event-loop INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:47:23.895 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
25/05/10 20:47:23.896 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 54 finished: collect at utils.scala:26, took 0.011131 s
25/05/10 20:47:23.971 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 213 (count at <unknown>:0) as input to shuffle 4
25/05/10 20:47:23.971 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 55 (count at <unknown>:0) with 1 output partitions
25/05/10 20:47:23.971 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 58 (count at <unknown>:0)
25/05/10 20:47:23.971 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:47:23.972 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:23.972 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[213] at count at <unknown>:0), which has no missing parents
25/05/10 20:47:23.976 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 19.5 KiB, free 910.9 MiB)
25/05/10 20:47:23.978 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 8.4 KiB, free 910.9 MiB)
25/05/10 20:47:23.978 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:53507 (size: 8.4 KiB, free: 911.3 MiB)
25/05/10 20:47:23.979 dag-scheduler-event-loop INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:23.979 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[213] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:23.979 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0
25/05/10 20:47:23.982 dispatcher-event-loop-9 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 62) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509938 bytes) 
25/05/10 20:47:23.983 Executor task launch worker for task 0.0 in stage 58.0 (TID 62) INFO Executor: Running task 0.0 in stage 58.0 (TID 62)
25/05/10 20:47:23.989 Executor task launch worker for task 0.0 in stage 58.0 (TID 62) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:47:24.005 Executor task launch worker for task 0.0 in stage 58.0 (TID 62) INFO Executor: Finished task 0.0 in stage 58.0 (TID 62). 2123 bytes result sent to driver
25/05/10 20:47:24.007 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 62) in 26 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:24.007 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
25/05/10 20:47:24.007 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 58 (count at <unknown>:0) finished in 0.034 s
25/05/10 20:47:24.008 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
25/05/10 20:47:24.008 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
25/05/10 20:47:24.008 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
25/05/10 20:47:24.008 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
25/05/10 20:47:24.027 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at <unknown>:0
25/05/10 20:47:24.028 dag-scheduler-event-loop INFO DAGScheduler: Got job 56 (count at <unknown>:0) with 1 output partitions
25/05/10 20:47:24.028 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 60 (count at <unknown>:0)
25/05/10 20:47:24.028 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
25/05/10 20:47:24.028 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:24.029 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[216] at count at <unknown>:0), which has no missing parents
25/05/10 20:47:24.030 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 12.5 KiB, free 910.9 MiB)
25/05/10 20:47:24.031 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 910.9 MiB)
25/05/10 20:47:24.032 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:53507 (size: 5.9 KiB, free: 911.3 MiB)
25/05/10 20:47:24.032 dag-scheduler-event-loop INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:24.033 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[216] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:24.033 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0
25/05/10 20:47:24.033 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 63) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 9176 bytes) 
25/05/10 20:47:24.035 Executor task launch worker for task 0.0 in stage 60.0 (TID 63) INFO Executor: Running task 0.0 in stage 60.0 (TID 63)
25/05/10 20:47:24.039 Executor task launch worker for task 0.0 in stage 60.0 (TID 63) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/10 20:47:24.039 Executor task launch worker for task 0.0 in stage 60.0 (TID 63) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/10 20:47:24.041 Executor task launch worker for task 0.0 in stage 60.0 (TID 63) INFO Executor: Finished task 0.0 in stage 60.0 (TID 63). 3909 bytes result sent to driver
25/05/10 20:47:24.043 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 63) in 10 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:24.043 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
25/05/10 20:47:24.044 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 60 (count at <unknown>:0) finished in 0.015 s
25/05/10 20:47:24.044 dag-scheduler-event-loop INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:47:24.044 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
25/05/10 20:47:24.044 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 56 finished: count at <unknown>:0, took 0.016103 s
25/05/10 20:47:24.100 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.9007 ms
25/05/10 20:47:24.113 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:47:24.115 dag-scheduler-event-loop INFO DAGScheduler: Got job 57 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:47:24.115 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 61 (collect at utils.scala:26)
25/05/10 20:47:24.115 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:47:24.116 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:24.116 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[221] at collect at utils.scala:26), which has no missing parents
25/05/10 20:47:24.119 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 61.6 KiB, free 910.8 MiB)
25/05/10 20:47:24.121 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 24.7 KiB, free 910.8 MiB)
25/05/10 20:47:24.122 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:53507 (size: 24.7 KiB, free: 911.2 MiB)
25/05/10 20:47:24.122 dag-scheduler-event-loop INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:24.122 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[221] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:24.122 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0
25/05/10 20:47:24.125 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 64) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509949 bytes) 
25/05/10 20:47:24.125 Executor task launch worker for task 0.0 in stage 61.0 (TID 64) INFO Executor: Running task 0.0 in stage 61.0 (TID 64)
25/05/10 20:47:24.131 Executor task launch worker for task 0.0 in stage 61.0 (TID 64) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:47:24.142 Executor task launch worker for task 0.0 in stage 61.0 (TID 64) INFO CodeGenerator: Code generated in 9.596 ms
25/05/10 20:47:24.161 Executor task launch worker for task 0.0 in stage 61.0 (TID 64) INFO Executor: Finished task 0.0 in stage 61.0 (TID 64). 53987 bytes result sent to driver
25/05/10 20:47:24.162 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 64) in 39 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:24.162 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 61 (collect at utils.scala:26) finished in 0.045 s
25/05/10 20:47:24.162 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
25/05/10 20:47:24.162 dag-scheduler-event-loop INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:47:24.163 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
25/05/10 20:47:24.163 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 57 finished: collect at utils.scala:26, took 0.048036 s
25/05/10 20:47:51.086 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 226 (collect at StringIndexer.scala:204) as input to shuffle 5
25/05/10 20:47:51.086 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 58 (collect at StringIndexer.scala:204) with 1 output partitions
25/05/10 20:47:51.087 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 62 (collect at StringIndexer.scala:204)
25/05/10 20:47:51.087 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:47:51.087 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:51.088 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[226] at collect at StringIndexer.scala:204), which has no missing parents
25/05/10 20:47:51.096 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 30.6 KiB, free 910.7 MiB)
25/05/10 20:47:51.098 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 910.7 MiB)
25/05/10 20:47:51.100 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:53507 (size: 13.7 KiB, free: 911.2 MiB)
25/05/10 20:47:51.100 dag-scheduler-event-loop INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:51.101 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[226] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:51.101 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0
25/05/10 20:47:51.105 dispatcher-event-loop-9 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 65) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509938 bytes) 
25/05/10 20:47:51.106 Executor task launch worker for task 0.0 in stage 62.0 (TID 65) INFO Executor: Running task 0.0 in stage 62.0 (TID 65)
25/05/10 20:47:51.111 Executor task launch worker for task 0.0 in stage 62.0 (TID 65) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:47:51.131 Executor task launch worker for task 0.0 in stage 62.0 (TID 65) INFO Executor: Finished task 0.0 in stage 62.0 (TID 65). 2226 bytes result sent to driver
25/05/10 20:47:51.132 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 65) in 30 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:51.132 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
25/05/10 20:47:51.133 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 62 (collect at StringIndexer.scala:204) finished in 0.045 s
25/05/10 20:47:51.133 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
25/05/10 20:47:51.133 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
25/05/10 20:47:51.133 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
25/05/10 20:47:51.133 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
25/05/10 20:47:51.143 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
25/05/10 20:47:51.145 dag-scheduler-event-loop INFO DAGScheduler: Got job 59 (collect at StringIndexer.scala:204) with 1 output partitions
25/05/10 20:47:51.145 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 64 (collect at StringIndexer.scala:204)
25/05/10 20:47:51.145 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)
25/05/10 20:47:51.145 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:51.146 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[229] at collect at StringIndexer.scala:204), which has no missing parents
25/05/10 20:47:51.148 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 35.9 KiB, free 910.7 MiB)
25/05/10 20:47:51.149 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 910.7 MiB)
25/05/10 20:47:51.149 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:53507 (size: 16.4 KiB, free: 911.2 MiB)
25/05/10 20:47:51.149 dag-scheduler-event-loop INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:51.150 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[229] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:51.150 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0
25/05/10 20:47:51.150 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 66) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 9176 bytes) 
25/05/10 20:47:51.151 Executor task launch worker for task 0.0 in stage 64.0 (TID 66) INFO Executor: Running task 0.0 in stage 64.0 (TID 66)
25/05/10 20:47:51.153 Executor task launch worker for task 0.0 in stage 64.0 (TID 66) INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/10 20:47:51.153 Executor task launch worker for task 0.0 in stage 64.0 (TID 66) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/10 20:47:51.166 Executor task launch worker for task 0.0 in stage 64.0 (TID 66) INFO Executor: Finished task 0.0 in stage 64.0 (TID 66). 4942 bytes result sent to driver
25/05/10 20:47:51.167 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 66) in 17 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:51.168 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
25/05/10 20:47:51.168 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 64 (collect at StringIndexer.scala:204) finished in 0.022 s
25/05/10 20:47:51.168 dag-scheduler-event-loop INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:47:51.169 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished
25/05/10 20:47:51.169 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 59 finished: collect at StringIndexer.scala:204, took 0.024670 s
25/05/10 20:47:51.185 nioEventLoopGroup-2-2 INFO Instrumentation: [cc7066b9] training finished
25/05/10 20:47:51.208 nioEventLoopGroup-2-2 INFO Instrumentation: [bf396b0b] training finished
25/05/10 20:47:51.214 nioEventLoopGroup-2-2 INFO Instrumentation: [499712f3] Stage class: LinearRegression
25/05/10 20:47:51.214 nioEventLoopGroup-2-2 INFO Instrumentation: [499712f3] Stage uid: linear_regression__feca5e2d_9771_4b94_9092_f4cfb5867f46
25/05/10 20:47:51.240 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.7887 ms
25/05/10 20:47:51.246 nioEventLoopGroup-2-2 INFO Instrumentation: [499712f3] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
25/05/10 20:47:51.247 nioEventLoopGroup-2-2 INFO Instrumentation: [499712f3] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
25/05/10 20:47:51.248 nioEventLoopGroup-2-2 INFO Instrumentation: [499712f3] {"numFeatures":6}
25/05/10 20:47:51.289 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 14.1107 ms
25/05/10 20:47:51.303 nioEventLoopGroup-2-2 WARN Instrumentation: [499712f3] regParam is zero, which might cause numerical instability and overfitting.
25/05/10 20:47:51.311 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
25/05/10 20:47:51.312 dag-scheduler-event-loop INFO DAGScheduler: Got job 60 (treeAggregate at WeightedLeastSquares.scala:107) with 1 output partitions
25/05/10 20:47:51.312 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 65 (treeAggregate at WeightedLeastSquares.scala:107)
25/05/10 20:47:51.312 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:47:51.312 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:51.312 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[245] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
25/05/10 20:47:51.331 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 80.1 KiB, free 910.6 MiB)
25/05/10 20:47:51.332 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 910.6 MiB)
25/05/10 20:47:51.333 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:53507 (size: 31.1 KiB, free: 911.2 MiB)
25/05/10 20:47:51.333 dag-scheduler-event-loop INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:51.333 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[245] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:51.333 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0
25/05/10 20:47:51.335 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 67) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509949 bytes) 
25/05/10 20:47:51.335 Executor task launch worker for task 0.0 in stage 65.0 (TID 67) INFO Executor: Running task 0.0 in stage 65.0 (TID 67)
25/05/10 20:47:51.340 Executor task launch worker for task 0.0 in stage 65.0 (TID 67) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:47:51.368 Executor task launch worker for task 0.0 in stage 65.0 (TID 67) INFO CodeGenerator: Code generated in 26.6344 ms
25/05/10 20:47:51.402 Executor task launch worker for task 0.0 in stage 65.0 (TID 67) INFO Executor: Finished task 0.0 in stage 65.0 (TID 67). 2084 bytes result sent to driver
25/05/10 20:47:51.403 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 67) in 69 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:51.403 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
25/05/10 20:47:51.403 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 65 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.090 s
25/05/10 20:47:51.403 dag-scheduler-event-loop INFO DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:47:51.403 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished
25/05/10 20:47:51.404 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 60 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.092845 s
25/05/10 20:47:51.404 nioEventLoopGroup-2-2 INFO Instrumentation: [499712f3] Number of instances: 5715.
25/05/10 20:47:51.437 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.7873 ms
25/05/10 20:47:51.453 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
25/05/10 20:47:51.453 dag-scheduler-event-loop INFO DAGScheduler: Got job 61 (treeAggregate at Statistics.scala:58) with 1 output partitions
25/05/10 20:47:51.453 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 66 (treeAggregate at Statistics.scala:58)
25/05/10 20:47:51.453 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:47:51.453 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:51.453 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[255] at treeAggregate at Statistics.scala:58), which has no missing parents
25/05/10 20:47:51.462 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 69.7 KiB, free 910.5 MiB)
25/05/10 20:47:51.463 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 29.2 KiB, free 910.5 MiB)
25/05/10 20:47:51.464 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:53507 (size: 29.2 KiB, free: 911.2 MiB)
25/05/10 20:47:51.464 dag-scheduler-event-loop INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:51.465 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[255] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:51.465 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0
25/05/10 20:47:51.466 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 68) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509949 bytes) 
25/05/10 20:47:51.467 Executor task launch worker for task 0.0 in stage 66.0 (TID 68) INFO Executor: Running task 0.0 in stage 66.0 (TID 68)
25/05/10 20:47:51.472 Executor task launch worker for task 0.0 in stage 66.0 (TID 68) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:47:51.487 Executor task launch worker for task 0.0 in stage 66.0 (TID 68) INFO CodeGenerator: Code generated in 14.2572 ms
25/05/10 20:47:51.516 Executor task launch worker for task 0.0 in stage 66.0 (TID 68) INFO Executor: Finished task 0.0 in stage 66.0 (TID 68). 2732 bytes result sent to driver
25/05/10 20:47:51.517 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 68) in 52 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:51.517 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
25/05/10 20:47:51.518 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 66 (treeAggregate at Statistics.scala:58) finished in 0.063 s
25/05/10 20:47:51.518 dag-scheduler-event-loop INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:47:51.518 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished
25/05/10 20:47:51.518 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 61 finished: treeAggregate at Statistics.scala:58, took 0.065163 s
25/05/10 20:47:51.519 nioEventLoopGroup-2-2 INFO Instrumentation: [f6f6c76d] training finished
25/05/10 20:47:51.778 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:47:51.779 dag-scheduler-event-loop INFO DAGScheduler: Got job 62 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:47:51.779 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 67 (collect at utils.scala:26)
25/05/10 20:47:51.779 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:47:51.779 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:51.779 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[257] at collect at utils.scala:26), which has no missing parents
25/05/10 20:47:51.802 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 7.8 KiB, free 910.5 MiB)
25/05/10 20:47:51.806 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 910.6 MiB)
25/05/10 20:47:51.807 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:53507 in memory (size: 31.1 KiB, free: 911.2 MiB)
25/05/10 20:47:51.807 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.2 MiB)
25/05/10 20:47:51.807 dag-scheduler-event-loop INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:51.807 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[257] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:51.807 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks resource profile 0
25/05/10 20:47:51.808 dispatcher-event-loop-9 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 69) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:47:51.809 Executor task launch worker for task 0.0 in stage 67.0 (TID 69) INFO Executor: Running task 0.0 in stage 67.0 (TID 69)
25/05/10 20:47:51.812 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:53507 in memory (size: 5.9 KiB, free: 911.2 MiB)
25/05/10 20:47:51.816 Executor task launch worker for task 0.0 in stage 67.0 (TID 69) INFO Executor: Finished task 0.0 in stage 67.0 (TID 69). 1456 bytes result sent to driver
25/05/10 20:47:51.817 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 69) in 9 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:51.817 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
25/05/10 20:47:51.818 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:53507 in memory (size: 24.7 KiB, free: 911.2 MiB)
25/05/10 20:47:51.818 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 67 (collect at utils.scala:26) finished in 0.039 s
25/05/10 20:47:51.818 dag-scheduler-event-loop INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:47:51.818 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 67: Stage finished
25/05/10 20:47:51.818 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 62 finished: collect at utils.scala:26, took 0.040110 s
25/05/10 20:47:51.823 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:53507 in memory (size: 13.7 KiB, free: 911.2 MiB)
25/05/10 20:47:51.828 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.2 MiB)
25/05/10 20:47:51.834 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.2 MiB)
25/05/10 20:47:51.838 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.2 MiB)
25/05/10 20:47:51.842 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:53507 in memory (size: 13.7 KiB, free: 911.2 MiB)
25/05/10 20:47:51.847 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:53507 in memory (size: 8.4 KiB, free: 911.3 MiB)
25/05/10 20:47:51.851 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:53507 in memory (size: 16.4 KiB, free: 911.3 MiB)
25/05/10 20:47:51.856 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:53507 in memory (size: 29.2 KiB, free: 911.3 MiB)
25/05/10 20:47:51.859 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:53507 in memory (size: 31.1 KiB, free: 911.3 MiB)
25/05/10 20:47:51.862 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.3 MiB)
25/05/10 20:47:51.865 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:53507 in memory (size: 29.2 KiB, free: 911.4 MiB)
25/05/10 20:47:51.868 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:53507 in memory (size: 16.4 KiB, free: 911.4 MiB)
25/05/10 20:47:52.063 nioEventLoopGroup-2-2 INFO Instrumentation: [1887e31b] training finished
25/05/10 20:47:52.158 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:47:52.159 dag-scheduler-event-loop INFO DAGScheduler: Got job 63 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:47:52.159 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 68 (collect at utils.scala:26)
25/05/10 20:47:52.159 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:47:52.159 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:52.159 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[259] at collect at utils.scala:26), which has no missing parents
25/05/10 20:47:52.160 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 7.8 KiB, free 911.2 MiB)
25/05/10 20:47:52.161 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 911.2 MiB)
25/05/10 20:47:52.161 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.4 MiB)
25/05/10 20:47:52.162 dag-scheduler-event-loop INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:52.162 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[259] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:52.162 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0
25/05/10 20:47:52.163 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 70) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:47:52.163 Executor task launch worker for task 0.0 in stage 68.0 (TID 70) INFO Executor: Running task 0.0 in stage 68.0 (TID 70)
25/05/10 20:47:52.166 Executor task launch worker for task 0.0 in stage 68.0 (TID 70) INFO Executor: Finished task 0.0 in stage 68.0 (TID 70). 1327 bytes result sent to driver
25/05/10 20:47:52.166 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 70) in 3 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:52.167 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
25/05/10 20:47:52.167 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 68 (collect at utils.scala:26) finished in 0.008 s
25/05/10 20:47:52.167 dag-scheduler-event-loop INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:47:52.167 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 68: Stage finished
25/05/10 20:47:52.167 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 63 finished: collect at utils.scala:26, took 0.008384 s
25/05/10 20:47:52.517 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:47:52.518 dag-scheduler-event-loop INFO DAGScheduler: Got job 64 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:47:52.518 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 69 (collect at utils.scala:26)
25/05/10 20:47:52.518 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:47:52.518 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:52.518 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[261] at collect at utils.scala:26), which has no missing parents
25/05/10 20:47:52.519 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 7.8 KiB, free 911.2 MiB)
25/05/10 20:47:52.520 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 911.2 MiB)
25/05/10 20:47:52.520 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.4 MiB)
25/05/10 20:47:52.520 dag-scheduler-event-loop INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:52.521 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[261] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:52.521 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0
25/05/10 20:47:52.521 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 71) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:47:52.521 Executor task launch worker for task 0.0 in stage 69.0 (TID 71) INFO Executor: Running task 0.0 in stage 69.0 (TID 71)
25/05/10 20:47:52.524 Executor task launch worker for task 0.0 in stage 69.0 (TID 71) INFO Executor: Finished task 0.0 in stage 69.0 (TID 71). 1327 bytes result sent to driver
25/05/10 20:47:52.525 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 71) in 4 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:52.525 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
25/05/10 20:47:52.525 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 69 (collect at utils.scala:26) finished in 0.007 s
25/05/10 20:47:52.525 dag-scheduler-event-loop INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:47:52.525 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished
25/05/10 20:47:52.526 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 64 finished: collect at utils.scala:26, took 0.007469 s
25/05/10 20:47:52.725 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:47:52.726 dag-scheduler-event-loop INFO DAGScheduler: Got job 65 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:47:52.726 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 70 (collect at utils.scala:26)
25/05/10 20:47:52.726 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:47:52.726 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:52.726 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[263] at collect at utils.scala:26), which has no missing parents
25/05/10 20:47:52.728 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 7.4 KiB, free 911.2 MiB)
25/05/10 20:47:52.729 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 911.2 MiB)
25/05/10 20:47:52.730 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.4 MiB)
25/05/10 20:47:52.731 dag-scheduler-event-loop INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:52.732 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[263] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:52.732 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks resource profile 0
25/05/10 20:47:52.732 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 72) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:47:52.734 Executor task launch worker for task 0.0 in stage 70.0 (TID 72) INFO Executor: Running task 0.0 in stage 70.0 (TID 72)
25/05/10 20:47:52.737 Executor task launch worker for task 0.0 in stage 70.0 (TID 72) INFO Executor: Finished task 0.0 in stage 70.0 (TID 72). 1326 bytes result sent to driver
25/05/10 20:47:52.738 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 72) in 6 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:52.738 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
25/05/10 20:47:52.738 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 70 (collect at utils.scala:26) finished in 0.011 s
25/05/10 20:47:52.739 dag-scheduler-event-loop INFO DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:47:52.739 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 70: Stage finished
25/05/10 20:47:52.739 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 65 finished: collect at utils.scala:26, took 0.013681 s
25/05/10 20:47:52.791 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 268 (count at <unknown>:0) as input to shuffle 6
25/05/10 20:47:52.792 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 66 (count at <unknown>:0) with 1 output partitions
25/05/10 20:47:52.792 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 71 (count at <unknown>:0)
25/05/10 20:47:52.792 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:47:52.792 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:52.792 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 71 (MapPartitionsRDD[268] at count at <unknown>:0), which has no missing parents
25/05/10 20:47:52.796 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 19.5 KiB, free 911.2 MiB)
25/05/10 20:47:52.798 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 8.4 KiB, free 911.2 MiB)
25/05/10 20:47:52.798 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:53507 (size: 8.4 KiB, free: 911.4 MiB)
25/05/10 20:47:52.799 dag-scheduler-event-loop INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:52.801 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 71 (MapPartitionsRDD[268] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:52.801 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks resource profile 0
25/05/10 20:47:52.804 dispatcher-event-loop-9 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 73) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509938 bytes) 
25/05/10 20:47:52.804 Executor task launch worker for task 0.0 in stage 71.0 (TID 73) INFO Executor: Running task 0.0 in stage 71.0 (TID 73)
25/05/10 20:47:52.806 Executor task launch worker for task 0.0 in stage 71.0 (TID 73) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:47:52.819 Executor task launch worker for task 0.0 in stage 71.0 (TID 73) INFO Executor: Finished task 0.0 in stage 71.0 (TID 73). 2123 bytes result sent to driver
25/05/10 20:47:52.820 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 73) in 18 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:52.820 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
25/05/10 20:47:52.821 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 71 (count at <unknown>:0) finished in 0.028 s
25/05/10 20:47:52.821 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
25/05/10 20:47:52.821 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
25/05/10 20:47:52.821 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
25/05/10 20:47:52.821 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
25/05/10 20:47:52.834 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at <unknown>:0
25/05/10 20:47:52.834 dag-scheduler-event-loop INFO DAGScheduler: Got job 67 (count at <unknown>:0) with 1 output partitions
25/05/10 20:47:52.835 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 73 (count at <unknown>:0)
25/05/10 20:47:52.835 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 72)
25/05/10 20:47:52.835 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:52.835 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[271] at count at <unknown>:0), which has no missing parents
25/05/10 20:47:52.835 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 12.5 KiB, free 911.2 MiB)
25/05/10 20:47:52.836 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 911.2 MiB)
25/05/10 20:47:52.837 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:53507 (size: 5.9 KiB, free: 911.4 MiB)
25/05/10 20:47:52.837 dag-scheduler-event-loop INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:52.837 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[271] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:52.837 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks resource profile 0
25/05/10 20:47:52.838 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 74) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 9176 bytes) 
25/05/10 20:47:52.838 Executor task launch worker for task 0.0 in stage 73.0 (TID 74) INFO Executor: Running task 0.0 in stage 73.0 (TID 74)
25/05/10 20:47:52.840 Executor task launch worker for task 0.0 in stage 73.0 (TID 74) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/10 20:47:52.840 Executor task launch worker for task 0.0 in stage 73.0 (TID 74) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/10 20:47:52.841 Executor task launch worker for task 0.0 in stage 73.0 (TID 74) INFO Executor: Finished task 0.0 in stage 73.0 (TID 74). 3866 bytes result sent to driver
25/05/10 20:47:52.842 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 74) in 4 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:52.842 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 73 (count at <unknown>:0) finished in 0.007 s
25/05/10 20:47:52.842 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
25/05/10 20:47:52.842 dag-scheduler-event-loop INFO DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:47:52.842 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 73: Stage finished
25/05/10 20:47:52.843 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 67 finished: count at <unknown>:0, took 0.008881 s
25/05/10 20:47:52.891 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.4966 ms
25/05/10 20:47:52.905 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:47:52.905 dag-scheduler-event-loop INFO DAGScheduler: Got job 68 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:47:52.905 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 74 (collect at utils.scala:26)
25/05/10 20:47:52.905 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:47:52.906 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:47:52.906 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[276] at collect at utils.scala:26), which has no missing parents
25/05/10 20:47:52.909 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 61.6 KiB, free 911.1 MiB)
25/05/10 20:47:52.910 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 24.7 KiB, free 911.1 MiB)
25/05/10 20:47:52.910 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:53507 (size: 24.7 KiB, free: 911.3 MiB)
25/05/10 20:47:52.911 dag-scheduler-event-loop INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1585
25/05/10 20:47:52.911 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[276] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:47:52.911 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0
25/05/10 20:47:52.913 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 75) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509949 bytes) 
25/05/10 20:47:52.913 Executor task launch worker for task 0.0 in stage 74.0 (TID 75) INFO Executor: Running task 0.0 in stage 74.0 (TID 75)
25/05/10 20:47:52.917 Executor task launch worker for task 0.0 in stage 74.0 (TID 75) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:47:52.925 Executor task launch worker for task 0.0 in stage 74.0 (TID 75) INFO CodeGenerator: Code generated in 7.0266 ms
25/05/10 20:47:52.948 Executor task launch worker for task 0.0 in stage 74.0 (TID 75) INFO Executor: Finished task 0.0 in stage 74.0 (TID 75). 53987 bytes result sent to driver
25/05/10 20:47:52.949 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 75) in 38 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:47:52.949 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
25/05/10 20:47:52.949 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 74 (collect at utils.scala:26) finished in 0.042 s
25/05/10 20:47:52.949 dag-scheduler-event-loop INFO DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:47:52.949 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished
25/05/10 20:47:52.949 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 68 finished: collect at utils.scala:26, took 0.044572 s
25/05/10 20:51:12.608 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 281 (collect at StringIndexer.scala:204) as input to shuffle 7
25/05/10 20:51:12.608 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 69 (collect at StringIndexer.scala:204) with 1 output partitions
25/05/10 20:51:12.608 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 75 (collect at StringIndexer.scala:204)
25/05/10 20:51:12.608 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:51:12.608 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:51:12.608 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 75 (MapPartitionsRDD[281] at collect at StringIndexer.scala:204), which has no missing parents
25/05/10 20:51:12.612 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 30.6 KiB, free 911.0 MiB)
25/05/10 20:51:12.613 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 13.6 KiB, free 911.0 MiB)
25/05/10 20:51:12.613 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:53507 (size: 13.6 KiB, free: 911.3 MiB)
25/05/10 20:51:12.613 dag-scheduler-event-loop INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1585
25/05/10 20:51:12.613 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 75 (MapPartitionsRDD[281] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
25/05/10 20:51:12.613 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks resource profile 0
25/05/10 20:51:12.615 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 76) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509938 bytes) 
25/05/10 20:51:12.616 Executor task launch worker for task 0.0 in stage 75.0 (TID 76) INFO Executor: Running task 0.0 in stage 75.0 (TID 76)
25/05/10 20:51:12.620 Executor task launch worker for task 0.0 in stage 75.0 (TID 76) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:51:12.645 Executor task launch worker for task 0.0 in stage 75.0 (TID 76) INFO Executor: Finished task 0.0 in stage 75.0 (TID 76). 2226 bytes result sent to driver
25/05/10 20:51:12.646 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 76) in 31 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:51:12.646 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
25/05/10 20:51:12.646 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 75 (collect at StringIndexer.scala:204) finished in 0.037 s
25/05/10 20:51:12.646 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
25/05/10 20:51:12.646 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
25/05/10 20:51:12.646 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
25/05/10 20:51:12.646 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
25/05/10 20:51:12.656 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
25/05/10 20:51:12.657 dag-scheduler-event-loop INFO DAGScheduler: Got job 70 (collect at StringIndexer.scala:204) with 1 output partitions
25/05/10 20:51:12.657 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 77 (collect at StringIndexer.scala:204)
25/05/10 20:51:12.657 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 76)
25/05/10 20:51:12.657 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:51:12.657 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[284] at collect at StringIndexer.scala:204), which has no missing parents
25/05/10 20:51:12.658 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 35.9 KiB, free 911.0 MiB)
25/05/10 20:51:12.659 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 911.0 MiB)
25/05/10 20:51:12.659 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:53507 (size: 16.4 KiB, free: 911.3 MiB)
25/05/10 20:51:12.660 dag-scheduler-event-loop INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1585
25/05/10 20:51:12.660 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[284] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
25/05/10 20:51:12.660 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks resource profile 0
25/05/10 20:51:12.661 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 77) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 9176 bytes) 
25/05/10 20:51:12.661 Executor task launch worker for task 0.0 in stage 77.0 (TID 77) INFO Executor: Running task 0.0 in stage 77.0 (TID 77)
25/05/10 20:51:12.664 Executor task launch worker for task 0.0 in stage 77.0 (TID 77) INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/10 20:51:12.665 Executor task launch worker for task 0.0 in stage 77.0 (TID 77) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/10 20:51:12.678 Executor task launch worker for task 0.0 in stage 77.0 (TID 77) INFO Executor: Finished task 0.0 in stage 77.0 (TID 77). 4942 bytes result sent to driver
25/05/10 20:51:12.679 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 77) in 18 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:51:12.679 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
25/05/10 20:51:12.679 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 77 (collect at StringIndexer.scala:204) finished in 0.022 s
25/05/10 20:51:12.680 dag-scheduler-event-loop INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:51:12.680 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 77: Stage finished
25/05/10 20:51:12.680 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 70 finished: collect at StringIndexer.scala:204, took 0.023067 s
25/05/10 20:51:12.697 nioEventLoopGroup-2-2 INFO Instrumentation: [94b4f072] training finished
25/05/10 20:51:12.719 nioEventLoopGroup-2-2 INFO Instrumentation: [ae087a41] training finished
25/05/10 20:51:12.723 nioEventLoopGroup-2-2 INFO Instrumentation: [1a88cc14] Stage class: LinearRegression
25/05/10 20:51:12.723 nioEventLoopGroup-2-2 INFO Instrumentation: [1a88cc14] Stage uid: linear_regression__a6db5770_8094_46d1_a400_1821e4409bd6
25/05/10 20:51:12.749 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.4202 ms
25/05/10 20:51:12.759 nioEventLoopGroup-2-2 INFO Instrumentation: [1a88cc14] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
25/05/10 20:51:12.759 nioEventLoopGroup-2-2 INFO Instrumentation: [1a88cc14] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
25/05/10 20:51:12.760 nioEventLoopGroup-2-2 INFO Instrumentation: [1a88cc14] {"numFeatures":6}
25/05/10 20:51:12.807 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 14.073 ms
25/05/10 20:51:12.819 nioEventLoopGroup-2-2 WARN Instrumentation: [1a88cc14] regParam is zero, which might cause numerical instability and overfitting.
25/05/10 20:51:12.827 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
25/05/10 20:51:12.827 dag-scheduler-event-loop INFO DAGScheduler: Got job 71 (treeAggregate at WeightedLeastSquares.scala:107) with 1 output partitions
25/05/10 20:51:12.828 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 78 (treeAggregate at WeightedLeastSquares.scala:107)
25/05/10 20:51:12.828 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:51:12.828 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:51:12.828 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[300] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
25/05/10 20:51:12.847 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 80.1 KiB, free 910.9 MiB)
25/05/10 20:51:12.849 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 910.9 MiB)
25/05/10 20:51:12.849 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:53507 (size: 31.1 KiB, free: 911.3 MiB)
25/05/10 20:51:12.850 dag-scheduler-event-loop INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1585
25/05/10 20:51:12.850 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[300] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0))
25/05/10 20:51:12.850 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks resource profile 0
25/05/10 20:51:12.852 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 78) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509949 bytes) 
25/05/10 20:51:12.852 Executor task launch worker for task 0.0 in stage 78.0 (TID 78) INFO Executor: Running task 0.0 in stage 78.0 (TID 78)
25/05/10 20:51:12.859 Executor task launch worker for task 0.0 in stage 78.0 (TID 78) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:51:12.877 Executor task launch worker for task 0.0 in stage 78.0 (TID 78) INFO CodeGenerator: Code generated in 16.5114 ms
25/05/10 20:51:12.899 Executor task launch worker for task 0.0 in stage 78.0 (TID 78) INFO Executor: Finished task 0.0 in stage 78.0 (TID 78). 2127 bytes result sent to driver
25/05/10 20:51:12.900 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 78) in 49 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:51:12.900 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
25/05/10 20:51:12.900 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 78 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.072 s
25/05/10 20:51:12.900 dag-scheduler-event-loop INFO DAGScheduler: Job 71 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:51:12.900 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 78: Stage finished
25/05/10 20:51:12.900 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 71 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.072900 s
25/05/10 20:51:12.900 nioEventLoopGroup-2-2 INFO Instrumentation: [1a88cc14] Number of instances: 5715.
25/05/10 20:51:12.936 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 12.4875 ms
25/05/10 20:51:12.957 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
25/05/10 20:51:12.958 dag-scheduler-event-loop INFO DAGScheduler: Got job 72 (treeAggregate at Statistics.scala:58) with 1 output partitions
25/05/10 20:51:12.958 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 79 (treeAggregate at Statistics.scala:58)
25/05/10 20:51:12.958 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:51:12.958 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:51:12.959 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[310] at treeAggregate at Statistics.scala:58), which has no missing parents
25/05/10 20:51:12.973 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 69.7 KiB, free 910.8 MiB)
25/05/10 20:51:12.975 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 29.1 KiB, free 910.8 MiB)
25/05/10 20:51:12.976 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:53507 (size: 29.1 KiB, free: 911.2 MiB)
25/05/10 20:51:12.976 dag-scheduler-event-loop INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1585
25/05/10 20:51:12.976 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[310] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0))
25/05/10 20:51:12.976 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks resource profile 0
25/05/10 20:51:12.979 dispatcher-event-loop-10 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 79) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509949 bytes) 
25/05/10 20:51:12.979 Executor task launch worker for task 0.0 in stage 79.0 (TID 79) INFO Executor: Running task 0.0 in stage 79.0 (TID 79)
25/05/10 20:51:12.986 Executor task launch worker for task 0.0 in stage 79.0 (TID 79) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:51:12.995 Executor task launch worker for task 0.0 in stage 79.0 (TID 79) INFO CodeGenerator: Code generated in 8.5899 ms
25/05/10 20:51:13.022 Executor task launch worker for task 0.0 in stage 79.0 (TID 79) INFO Executor: Finished task 0.0 in stage 79.0 (TID 79). 2775 bytes result sent to driver
25/05/10 20:51:13.025 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 79) in 48 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:51:13.025 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
25/05/10 20:51:13.026 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 79 (treeAggregate at Statistics.scala:58) finished in 0.067 s
25/05/10 20:51:13.026 dag-scheduler-event-loop INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:51:13.026 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 79: Stage finished
25/05/10 20:51:13.026 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 72 finished: treeAggregate at Statistics.scala:58, took 0.069311 s
25/05/10 20:51:13.027 nioEventLoopGroup-2-2 INFO Instrumentation: [910b2fbe] training finished
25/05/10 20:51:13.371 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:51:13.371 dag-scheduler-event-loop INFO DAGScheduler: Got job 73 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:51:13.372 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 80 (collect at utils.scala:26)
25/05/10 20:51:13.372 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:51:13.372 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:51:13.372 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[312] at collect at utils.scala:26), which has no missing parents
25/05/10 20:51:13.373 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 7.8 KiB, free 910.8 MiB)
25/05/10 20:51:13.374 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 910.8 MiB)
25/05/10 20:51:13.374 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.2 MiB)
25/05/10 20:51:13.374 dag-scheduler-event-loop INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1585
25/05/10 20:51:13.376 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[312] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:51:13.376 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks resource profile 0
25/05/10 20:51:13.376 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 80) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:51:13.377 Executor task launch worker for task 0.0 in stage 80.0 (TID 80) INFO Executor: Running task 0.0 in stage 80.0 (TID 80)
25/05/10 20:51:13.380 Executor task launch worker for task 0.0 in stage 80.0 (TID 80) INFO Executor: Finished task 0.0 in stage 80.0 (TID 80). 1327 bytes result sent to driver
25/05/10 20:51:13.380 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 80) in 4 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:51:13.380 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
25/05/10 20:51:13.380 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 80 (collect at utils.scala:26) finished in 0.008 s
25/05/10 20:51:13.381 dag-scheduler-event-loop INFO DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:51:13.381 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 80: Stage finished
25/05/10 20:51:13.381 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 73 finished: collect at utils.scala:26, took 0.009083 s
25/05/10 20:51:13.559 nioEventLoopGroup-2-2 INFO Instrumentation: [a647cb40] training finished
25/05/10 20:51:13.639 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:51:13.640 dag-scheduler-event-loop INFO DAGScheduler: Got job 74 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:51:13.640 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 81 (collect at utils.scala:26)
25/05/10 20:51:13.640 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:51:13.640 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:51:13.640 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[314] at collect at utils.scala:26), which has no missing parents
25/05/10 20:51:13.641 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 7.8 KiB, free 910.8 MiB)
25/05/10 20:51:13.641 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 910.7 MiB)
25/05/10 20:51:13.642 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.2 MiB)
25/05/10 20:51:13.642 dag-scheduler-event-loop INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1585
25/05/10 20:51:13.643 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[314] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:51:13.643 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks resource profile 0
25/05/10 20:51:13.643 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 81) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:51:13.644 Executor task launch worker for task 0.0 in stage 81.0 (TID 81) INFO Executor: Running task 0.0 in stage 81.0 (TID 81)
25/05/10 20:51:13.646 Executor task launch worker for task 0.0 in stage 81.0 (TID 81) INFO Executor: Finished task 0.0 in stage 81.0 (TID 81). 1327 bytes result sent to driver
25/05/10 20:51:13.647 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 81) in 4 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:51:13.647 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
25/05/10 20:51:13.647 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 81 (collect at utils.scala:26) finished in 0.007 s
25/05/10 20:51:13.647 dag-scheduler-event-loop INFO DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:51:13.647 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished
25/05/10 20:51:13.648 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 74 finished: collect at utils.scala:26, took 0.008571 s
25/05/10 20:51:14.079 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:51:14.080 dag-scheduler-event-loop INFO DAGScheduler: Got job 75 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:51:14.080 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 82 (collect at utils.scala:26)
25/05/10 20:51:14.080 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:51:14.080 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:51:14.080 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[316] at collect at utils.scala:26), which has no missing parents
25/05/10 20:51:14.082 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 7.8 KiB, free 910.7 MiB)
25/05/10 20:51:14.083 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 910.7 MiB)
25/05/10 20:51:14.084 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.2 MiB)
25/05/10 20:51:14.084 dag-scheduler-event-loop INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1585
25/05/10 20:51:14.085 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[316] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:51:14.085 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks resource profile 0
25/05/10 20:51:14.086 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 82) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:51:14.087 Executor task launch worker for task 0.0 in stage 82.0 (TID 82) INFO Executor: Running task 0.0 in stage 82.0 (TID 82)
25/05/10 20:51:14.091 Executor task launch worker for task 0.0 in stage 82.0 (TID 82) INFO Executor: Finished task 0.0 in stage 82.0 (TID 82). 1370 bytes result sent to driver
25/05/10 20:51:14.092 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 82) in 6 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:51:14.092 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
25/05/10 20:51:14.092 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 82 (collect at utils.scala:26) finished in 0.011 s
25/05/10 20:51:14.094 dag-scheduler-event-loop INFO DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:51:14.094 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 82: Stage finished
25/05/10 20:51:14.094 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 75 finished: collect at utils.scala:26, took 0.014147 s
25/05/10 20:52:10.438 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:52:10.439 dag-scheduler-event-loop INFO DAGScheduler: Got job 76 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:52:10.439 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 83 (collect at utils.scala:26)
25/05/10 20:52:10.439 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:52:10.439 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:52:10.440 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[318] at collect at utils.scala:26), which has no missing parents
25/05/10 20:52:10.441 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 7.4 KiB, free 910.7 MiB)
25/05/10 20:52:10.442 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 910.7 MiB)
25/05/10 20:52:10.442 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.2 MiB)
25/05/10 20:52:10.442 dag-scheduler-event-loop INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1585
25/05/10 20:52:10.444 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[318] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:52:10.444 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks resource profile 0
25/05/10 20:52:10.445 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 83) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:52:10.446 Executor task launch worker for task 0.0 in stage 83.0 (TID 83) INFO Executor: Running task 0.0 in stage 83.0 (TID 83)
25/05/10 20:52:10.450 Executor task launch worker for task 0.0 in stage 83.0 (TID 83) INFO Executor: Finished task 0.0 in stage 83.0 (TID 83). 1369 bytes result sent to driver
25/05/10 20:52:10.451 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 83) in 6 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:52:10.451 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
25/05/10 20:52:10.451 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 83 (collect at utils.scala:26) finished in 0.011 s
25/05/10 20:52:10.451 dag-scheduler-event-loop INFO DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:52:10.451 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 83: Stage finished
25/05/10 20:52:10.452 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 76 finished: collect at utils.scala:26, took 0.012886 s
25/05/10 20:52:10.500 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 323 (count at <unknown>:0) as input to shuffle 8
25/05/10 20:52:10.500 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 77 (count at <unknown>:0) with 1 output partitions
25/05/10 20:52:10.500 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 84 (count at <unknown>:0)
25/05/10 20:52:10.500 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:52:10.500 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:52:10.501 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 84 (MapPartitionsRDD[323] at count at <unknown>:0), which has no missing parents
25/05/10 20:52:10.502 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 19.5 KiB, free 910.7 MiB)
25/05/10 20:52:10.503 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 8.4 KiB, free 910.7 MiB)
25/05/10 20:52:10.503 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:53507 (size: 8.4 KiB, free: 911.2 MiB)
25/05/10 20:52:10.504 dag-scheduler-event-loop INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1585
25/05/10 20:52:10.504 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 84 (MapPartitionsRDD[323] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/05/10 20:52:10.504 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks resource profile 0
25/05/10 20:52:10.507 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 84) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509938 bytes) 
25/05/10 20:52:10.507 Executor task launch worker for task 0.0 in stage 84.0 (TID 84) INFO Executor: Running task 0.0 in stage 84.0 (TID 84)
25/05/10 20:52:10.510 Executor task launch worker for task 0.0 in stage 84.0 (TID 84) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:52:10.518 Executor task launch worker for task 0.0 in stage 84.0 (TID 84) INFO Executor: Finished task 0.0 in stage 84.0 (TID 84). 2123 bytes result sent to driver
25/05/10 20:52:10.518 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 84) in 13 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:52:10.518 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
25/05/10 20:52:10.519 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 84 (count at <unknown>:0) finished in 0.018 s
25/05/10 20:52:10.519 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
25/05/10 20:52:10.519 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
25/05/10 20:52:10.519 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
25/05/10 20:52:10.519 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
25/05/10 20:52:10.530 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at <unknown>:0
25/05/10 20:52:10.531 dag-scheduler-event-loop INFO DAGScheduler: Got job 78 (count at <unknown>:0) with 1 output partitions
25/05/10 20:52:10.531 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 86 (count at <unknown>:0)
25/05/10 20:52:10.531 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 85)
25/05/10 20:52:10.531 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:52:10.531 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[326] at count at <unknown>:0), which has no missing parents
25/05/10 20:52:10.532 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 12.5 KiB, free 910.7 MiB)
25/05/10 20:52:10.534 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 910.7 MiB)
25/05/10 20:52:10.534 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:53507 (size: 5.9 KiB, free: 911.2 MiB)
25/05/10 20:52:10.534 dag-scheduler-event-loop INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1585
25/05/10 20:52:10.535 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[326] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/05/10 20:52:10.535 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks resource profile 0
25/05/10 20:52:10.535 dispatcher-event-loop-10 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 85) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 9176 bytes) 
25/05/10 20:52:10.536 Executor task launch worker for task 0.0 in stage 86.0 (TID 85) INFO Executor: Running task 0.0 in stage 86.0 (TID 85)
25/05/10 20:52:10.537 Executor task launch worker for task 0.0 in stage 86.0 (TID 85) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/10 20:52:10.538 Executor task launch worker for task 0.0 in stage 86.0 (TID 85) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/10 20:52:10.539 Executor task launch worker for task 0.0 in stage 86.0 (TID 85) INFO Executor: Finished task 0.0 in stage 86.0 (TID 85). 3909 bytes result sent to driver
25/05/10 20:52:10.540 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 85) in 5 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:52:10.540 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
25/05/10 20:52:10.540 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 86 (count at <unknown>:0) finished in 0.009 s
25/05/10 20:52:10.541 dag-scheduler-event-loop INFO DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:52:10.541 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 86: Stage finished
25/05/10 20:52:10.541 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 78 finished: count at <unknown>:0, took 0.011074 s
25/05/10 20:52:10.590 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.6619 ms
25/05/10 20:52:10.604 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:52:10.604 dag-scheduler-event-loop INFO DAGScheduler: Got job 79 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:52:10.604 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 87 (collect at utils.scala:26)
25/05/10 20:52:10.604 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:52:10.605 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:52:10.605 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[331] at collect at utils.scala:26), which has no missing parents
25/05/10 20:52:10.607 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 61.6 KiB, free 910.6 MiB)
25/05/10 20:52:10.608 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 24.7 KiB, free 910.6 MiB)
25/05/10 20:52:10.608 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:53507 (size: 24.7 KiB, free: 911.2 MiB)
25/05/10 20:52:10.609 dag-scheduler-event-loop INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1585
25/05/10 20:52:10.609 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[331] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:52:10.609 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks resource profile 0
25/05/10 20:52:10.612 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 86) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509949 bytes) 
25/05/10 20:52:10.612 Executor task launch worker for task 0.0 in stage 87.0 (TID 86) INFO Executor: Running task 0.0 in stage 87.0 (TID 86)
25/05/10 20:52:10.618 Executor task launch worker for task 0.0 in stage 87.0 (TID 86) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:52:10.630 Executor task launch worker for task 0.0 in stage 87.0 (TID 86) INFO CodeGenerator: Code generated in 11.0646 ms
25/05/10 20:52:10.650 Executor task launch worker for task 0.0 in stage 87.0 (TID 86) INFO Executor: Finished task 0.0 in stage 87.0 (TID 86). 53987 bytes result sent to driver
25/05/10 20:52:10.651 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 86) in 42 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:52:10.651 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
25/05/10 20:52:10.652 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 87 (collect at utils.scala:26) finished in 0.046 s
25/05/10 20:52:10.652 dag-scheduler-event-loop INFO DAGScheduler: Job 79 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:52:10.652 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 87: Stage finished
25/05/10 20:52:10.652 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 79 finished: collect at utils.scala:26, took 0.048266 s
25/05/10 20:52:31.678 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:52:31.679 dag-scheduler-event-loop INFO DAGScheduler: Got job 80 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:52:31.679 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 88 (collect at utils.scala:26)
25/05/10 20:52:31.679 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:52:31.679 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:52:31.679 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[333] at collect at utils.scala:26), which has no missing parents
25/05/10 20:52:31.680 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 7.4 KiB, free 910.6 MiB)
25/05/10 20:52:31.681 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 910.6 MiB)
25/05/10 20:52:31.681 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:53507 (size: 3.8 KiB, free: 911.2 MiB)
25/05/10 20:52:31.682 dag-scheduler-event-loop INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1585
25/05/10 20:52:31.682 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[333] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:52:31.682 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks resource profile 0
25/05/10 20:52:31.684 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 87) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 9384 bytes) 
25/05/10 20:52:31.685 Executor task launch worker for task 0.0 in stage 88.0 (TID 87) INFO Executor: Running task 0.0 in stage 88.0 (TID 87)
25/05/10 20:52:31.688 Executor task launch worker for task 0.0 in stage 88.0 (TID 87) INFO Executor: Finished task 0.0 in stage 88.0 (TID 87). 1412 bytes result sent to driver
25/05/10 20:52:31.688 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 87) in 5 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:52:31.689 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
25/05/10 20:52:31.689 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 88 (collect at utils.scala:26) finished in 0.010 s
25/05/10 20:52:31.689 dag-scheduler-event-loop INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:52:31.689 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 88: Stage finished
25/05/10 20:52:31.689 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 80 finished: collect at utils.scala:26, took 0.011053 s
25/05/10 20:52:31.739 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 338 (count at <unknown>:0) as input to shuffle 9
25/05/10 20:52:31.740 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 81 (count at <unknown>:0) with 1 output partitions
25/05/10 20:52:31.740 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 89 (count at <unknown>:0)
25/05/10 20:52:31.740 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:52:31.740 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:52:31.740 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 89 (MapPartitionsRDD[338] at count at <unknown>:0), which has no missing parents
25/05/10 20:52:31.742 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 19.5 KiB, free 910.6 MiB)
25/05/10 20:52:31.742 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 8.4 KiB, free 910.6 MiB)
25/05/10 20:52:31.744 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:53507 (size: 8.4 KiB, free: 911.2 MiB)
25/05/10 20:52:31.744 dag-scheduler-event-loop INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1585
25/05/10 20:52:31.745 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 89 (MapPartitionsRDD[338] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/05/10 20:52:31.745 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks resource profile 0
25/05/10 20:52:31.747 dispatcher-event-loop-11 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 88) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509938 bytes) 
25/05/10 20:52:31.748 Executor task launch worker for task 0.0 in stage 89.0 (TID 88) INFO Executor: Running task 0.0 in stage 89.0 (TID 88)
25/05/10 20:52:31.753 Executor task launch worker for task 0.0 in stage 89.0 (TID 88) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:52:31.758 Executor task launch worker for task 0.0 in stage 89.0 (TID 88) INFO Executor: Finished task 0.0 in stage 89.0 (TID 88). 2123 bytes result sent to driver
25/05/10 20:52:31.759 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 88) in 14 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:52:31.759 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
25/05/10 20:52:31.759 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 89 (count at <unknown>:0) finished in 0.019 s
25/05/10 20:52:31.760 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
25/05/10 20:52:31.760 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
25/05/10 20:52:31.760 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
25/05/10 20:52:31.760 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
25/05/10 20:52:31.774 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at <unknown>:0
25/05/10 20:52:31.774 dag-scheduler-event-loop INFO DAGScheduler: Got job 82 (count at <unknown>:0) with 1 output partitions
25/05/10 20:52:31.774 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 91 (count at <unknown>:0)
25/05/10 20:52:31.774 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)
25/05/10 20:52:31.774 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:52:31.775 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[341] at count at <unknown>:0), which has no missing parents
25/05/10 20:52:31.776 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 12.5 KiB, free 910.5 MiB)
25/05/10 20:52:31.778 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 910.5 MiB)
25/05/10 20:52:31.778 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:53507 (size: 5.9 KiB, free: 911.2 MiB)
25/05/10 20:52:31.779 dag-scheduler-event-loop INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1585
25/05/10 20:52:31.779 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[341] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/05/10 20:52:31.779 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks resource profile 0
25/05/10 20:52:31.780 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 89) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 9176 bytes) 
25/05/10 20:52:31.780 Executor task launch worker for task 0.0 in stage 91.0 (TID 89) INFO Executor: Running task 0.0 in stage 91.0 (TID 89)
25/05/10 20:52:31.783 Executor task launch worker for task 0.0 in stage 91.0 (TID 89) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/10 20:52:31.783 Executor task launch worker for task 0.0 in stage 91.0 (TID 89) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/10 20:52:31.784 Executor task launch worker for task 0.0 in stage 91.0 (TID 89) INFO Executor: Finished task 0.0 in stage 91.0 (TID 89). 3909 bytes result sent to driver
25/05/10 20:52:31.785 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 89) in 5 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:52:31.785 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
25/05/10 20:52:31.786 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 91 (count at <unknown>:0) finished in 0.011 s
25/05/10 20:52:31.786 dag-scheduler-event-loop INFO DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:52:31.786 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 91: Stage finished
25/05/10 20:52:31.786 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 82 finished: count at <unknown>:0, took 0.012759 s
25/05/10 20:52:31.841 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/05/10 20:52:31.842 dag-scheduler-event-loop INFO DAGScheduler: Got job 83 (collect at utils.scala:26) with 1 output partitions
25/05/10 20:52:31.842 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 92 (collect at utils.scala:26)
25/05/10 20:52:31.842 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/05/10 20:52:31.842 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/05/10 20:52:31.842 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[346] at collect at utils.scala:26), which has no missing parents
25/05/10 20:52:31.845 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 61.6 KiB, free 910.5 MiB)
25/05/10 20:52:31.847 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 24.7 KiB, free 910.5 MiB)
25/05/10 20:52:31.847 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:53507 (size: 24.7 KiB, free: 911.1 MiB)
25/05/10 20:52:31.852 dag-scheduler-event-loop INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1585
25/05/10 20:52:31.852 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[346] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/05/10 20:52:31.852 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks resource profile 0
25/05/10 20:52:31.854 dispatcher-event-loop-8 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 90) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 509949 bytes) 
25/05/10 20:52:31.855 Executor task launch worker for task 0.0 in stage 92.0 (TID 90) INFO Executor: Running task 0.0 in stage 92.0 (TID 90)
25/05/10 20:52:31.861 Executor task launch worker for task 0.0 in stage 92.0 (TID 90) INFO BlockManager: Found block rdd_111_0 locally
25/05/10 20:52:31.882 Executor task launch worker for task 0.0 in stage 92.0 (TID 90) INFO Executor: Finished task 0.0 in stage 92.0 (TID 90). 54030 bytes result sent to driver
25/05/10 20:52:31.882 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 90) in 29 ms on 127.0.0.1 (executor driver) (1/1)
25/05/10 20:52:31.882 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
25/05/10 20:52:31.883 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 92 (collect at utils.scala:26) finished in 0.040 s
25/05/10 20:52:31.883 dag-scheduler-event-loop INFO DAGScheduler: Job 83 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/10 20:52:31.883 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 92: Stage finished
25/05/10 20:52:31.883 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 83 finished: collect at utils.scala:26, took 0.041842 s
25/05/10 21:11:51.831 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:53507 in memory (size: 31.1 KiB, free: 911.2 MiB)
25/05/10 21:11:51.840 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:53507 in memory (size: 16.4 KiB, free: 911.2 MiB)
25/05/10 21:11:51.843 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:53507 in memory (size: 8.4 KiB, free: 911.2 MiB)
25/05/10 21:11:51.848 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.2 MiB)
25/05/10 21:11:51.859 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:53507 in memory (size: 8.4 KiB, free: 911.2 MiB)
25/05/10 21:11:51.863 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.2 MiB)
25/05/10 21:11:51.872 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.2 MiB)
25/05/10 21:11:51.876 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:53507 in memory (size: 13.6 KiB, free: 911.2 MiB)
25/05/10 21:11:51.882 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:53507 in memory (size: 29.1 KiB, free: 911.3 MiB)
25/05/10 21:11:51.886 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:53507 in memory (size: 5.9 KiB, free: 911.3 MiB)
25/05/10 21:11:51.890 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.3 MiB)
25/05/10 21:11:51.894 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.3 MiB)
25/05/10 21:11:51.898 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.3 MiB)
25/05/10 21:11:51.904 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:53507 in memory (size: 24.7 KiB, free: 911.3 MiB)
25/05/10 21:11:51.909 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:53507 in memory (size: 5.9 KiB, free: 911.3 MiB)
25/05/10 21:11:51.914 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:53507 in memory (size: 24.7 KiB, free: 911.3 MiB)
25/05/10 21:11:51.921 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:53507 in memory (size: 5.9 KiB, free: 911.3 MiB)
25/05/10 21:11:51.925 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:53507 in memory (size: 24.7 KiB, free: 911.4 MiB)
25/05/10 21:11:51.930 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:53507 in memory (size: 8.4 KiB, free: 911.4 MiB)
25/05/10 21:11:51.937 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.4 MiB)
25/05/10 21:11:51.940 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.4 MiB)
25/05/10 21:11:51.944 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:53507 in memory (size: 3.8 KiB, free: 911.4 MiB)
25/05/10 21:11:51.948 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:53507 in memory (size: 31.1 KiB, free: 911.4 MiB)
25/05/10 21:11:51.952 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:53507 in memory (size: 24.7 KiB, free: 911.4 MiB)
